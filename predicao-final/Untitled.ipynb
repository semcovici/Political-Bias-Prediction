{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f93610a3-4bee-44a2-906f-ee42e56cb398",
   "metadata": {},
   "source": [
    "# Predição Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "416cbd19-30fd-4bf0-a457-4ec0d01ee074",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Downloads2\\Anaconda\\download\\lib\\site-packages\\scipy\\__init__.py:155: UserWarning: A NumPy version >=1.18.5 and <1.25.0 is required for this version of SciPy (detected version 1.26.2\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from datetime import datetime\n",
    "from scipy.stats import uniform\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "#from sklearn.pipeline import Pipeline\n",
    "from imblearn.pipeline import Pipeline\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn import set_config\n",
    "set_config(display='diagram')\n",
    "import datetime\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc199a94-ab1a-4548-8864-36bc2dcd80e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_parquet('../dataset/processed/artigos_tratados/bertimbau/artigos_tratados_bert_lg.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf2cea72-b4d0-4355-911a-1f6cdba34efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remocao de dados nulos\n",
    "data = data[data['Conteudo'] != '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8149efee-1d3c-48af-8e7e-6199d138be02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remocao de colunas desnecessarias\n",
    "rem_cols = ['Conteudo', 'URL']\n",
    "data.drop(rem_cols, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "44ba7dce-5f7d-4508-8514-c9ed4871071d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# conversao dos rotulos categoricos para numericos\n",
    "data['Vies'] = data['Vies'].map({'direita':2,\n",
    "                                'centro': 1,\n",
    "                                'esquerda': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4d1846ff-372f-4a06-af60-ea28d055fd5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Partido</th>\n",
       "      <th>emb_1</th>\n",
       "      <th>emb_2</th>\n",
       "      <th>emb_3</th>\n",
       "      <th>emb_4</th>\n",
       "      <th>emb_5</th>\n",
       "      <th>emb_6</th>\n",
       "      <th>emb_7</th>\n",
       "      <th>emb_8</th>\n",
       "      <th>emb_9</th>\n",
       "      <th>...</th>\n",
       "      <th>emb_1015</th>\n",
       "      <th>emb_1016</th>\n",
       "      <th>emb_1017</th>\n",
       "      <th>emb_1018</th>\n",
       "      <th>emb_1019</th>\n",
       "      <th>emb_1020</th>\n",
       "      <th>emb_1021</th>\n",
       "      <th>emb_1022</th>\n",
       "      <th>emb_1023</th>\n",
       "      <th>emb_1024</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Novo</td>\n",
       "      <td>0.401686</td>\n",
       "      <td>-0.142705</td>\n",
       "      <td>0.023679</td>\n",
       "      <td>0.192193</td>\n",
       "      <td>0.323548</td>\n",
       "      <td>-0.067125</td>\n",
       "      <td>-0.598261</td>\n",
       "      <td>-0.355111</td>\n",
       "      <td>0.149750</td>\n",
       "      <td>...</td>\n",
       "      <td>0.186607</td>\n",
       "      <td>-0.147967</td>\n",
       "      <td>-0.487217</td>\n",
       "      <td>0.110254</td>\n",
       "      <td>-0.125077</td>\n",
       "      <td>-0.159934</td>\n",
       "      <td>0.125114</td>\n",
       "      <td>0.134895</td>\n",
       "      <td>-0.527953</td>\n",
       "      <td>0.196096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Novo</td>\n",
       "      <td>-0.128541</td>\n",
       "      <td>0.215314</td>\n",
       "      <td>-0.069348</td>\n",
       "      <td>0.088915</td>\n",
       "      <td>0.408865</td>\n",
       "      <td>-0.052515</td>\n",
       "      <td>-0.267552</td>\n",
       "      <td>-0.157830</td>\n",
       "      <td>-0.072159</td>\n",
       "      <td>...</td>\n",
       "      <td>0.552647</td>\n",
       "      <td>0.091742</td>\n",
       "      <td>-0.605148</td>\n",
       "      <td>0.112920</td>\n",
       "      <td>0.099640</td>\n",
       "      <td>-0.174978</td>\n",
       "      <td>0.192274</td>\n",
       "      <td>0.250751</td>\n",
       "      <td>-0.157322</td>\n",
       "      <td>0.310022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Novo</td>\n",
       "      <td>0.016604</td>\n",
       "      <td>0.137099</td>\n",
       "      <td>-0.113500</td>\n",
       "      <td>0.109841</td>\n",
       "      <td>0.290769</td>\n",
       "      <td>0.015612</td>\n",
       "      <td>-0.275260</td>\n",
       "      <td>-0.178999</td>\n",
       "      <td>-0.177130</td>\n",
       "      <td>...</td>\n",
       "      <td>0.497988</td>\n",
       "      <td>0.113761</td>\n",
       "      <td>-0.157607</td>\n",
       "      <td>0.001557</td>\n",
       "      <td>0.053836</td>\n",
       "      <td>0.133553</td>\n",
       "      <td>-0.021814</td>\n",
       "      <td>0.095863</td>\n",
       "      <td>-0.137130</td>\n",
       "      <td>0.318082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Novo</td>\n",
       "      <td>-0.032087</td>\n",
       "      <td>-0.067949</td>\n",
       "      <td>-0.036270</td>\n",
       "      <td>0.208884</td>\n",
       "      <td>-0.090851</td>\n",
       "      <td>0.005983</td>\n",
       "      <td>-0.093461</td>\n",
       "      <td>-0.463273</td>\n",
       "      <td>-0.088330</td>\n",
       "      <td>...</td>\n",
       "      <td>0.601618</td>\n",
       "      <td>0.132886</td>\n",
       "      <td>-0.403809</td>\n",
       "      <td>0.213245</td>\n",
       "      <td>-0.007711</td>\n",
       "      <td>-0.157867</td>\n",
       "      <td>-0.053459</td>\n",
       "      <td>0.401732</td>\n",
       "      <td>-0.279196</td>\n",
       "      <td>0.165060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Novo</td>\n",
       "      <td>0.181898</td>\n",
       "      <td>0.011968</td>\n",
       "      <td>-0.062858</td>\n",
       "      <td>0.162305</td>\n",
       "      <td>0.247084</td>\n",
       "      <td>0.055331</td>\n",
       "      <td>-0.518530</td>\n",
       "      <td>-0.171481</td>\n",
       "      <td>0.040109</td>\n",
       "      <td>...</td>\n",
       "      <td>0.447449</td>\n",
       "      <td>-0.020970</td>\n",
       "      <td>-0.419976</td>\n",
       "      <td>0.198067</td>\n",
       "      <td>-0.142836</td>\n",
       "      <td>-0.334448</td>\n",
       "      <td>-0.083704</td>\n",
       "      <td>0.290215</td>\n",
       "      <td>-0.176763</td>\n",
       "      <td>0.452248</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1025 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Partido     emb_1     emb_2     emb_3     emb_4     emb_5     emb_6  \\\n",
       "0    Novo  0.401686 -0.142705  0.023679  0.192193  0.323548 -0.067125   \n",
       "1    Novo -0.128541  0.215314 -0.069348  0.088915  0.408865 -0.052515   \n",
       "2    Novo  0.016604  0.137099 -0.113500  0.109841  0.290769  0.015612   \n",
       "3    Novo -0.032087 -0.067949 -0.036270  0.208884 -0.090851  0.005983   \n",
       "4    Novo  0.181898  0.011968 -0.062858  0.162305  0.247084  0.055331   \n",
       "\n",
       "      emb_7     emb_8     emb_9  ...  emb_1015  emb_1016  emb_1017  emb_1018  \\\n",
       "0 -0.598261 -0.355111  0.149750  ...  0.186607 -0.147967 -0.487217  0.110254   \n",
       "1 -0.267552 -0.157830 -0.072159  ...  0.552647  0.091742 -0.605148  0.112920   \n",
       "2 -0.275260 -0.178999 -0.177130  ...  0.497988  0.113761 -0.157607  0.001557   \n",
       "3 -0.093461 -0.463273 -0.088330  ...  0.601618  0.132886 -0.403809  0.213245   \n",
       "4 -0.518530 -0.171481  0.040109  ...  0.447449 -0.020970 -0.419976  0.198067   \n",
       "\n",
       "   emb_1019  emb_1020  emb_1021  emb_1022  emb_1023  emb_1024  \n",
       "0 -0.125077 -0.159934  0.125114  0.134895 -0.527953  0.196096  \n",
       "1  0.099640 -0.174978  0.192274  0.250751 -0.157322  0.310022  \n",
       "2  0.053836  0.133553 -0.021814  0.095863 -0.137130  0.318082  \n",
       "3 -0.007711 -0.157867 -0.053459  0.401732 -0.279196  0.165060  \n",
       "4 -0.142836 -0.334448 -0.083704  0.290215 -0.176763  0.452248  \n",
       "\n",
       "[5 rows x 1025 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a seguir os dados serão divididos entre features (X) e label (y)\n",
    "\n",
    "X_columns = [column for column in data.columns if column != 'Vies']\n",
    "X = data[X_columns] # features\n",
    "X.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7b2ba84c-21b0-4398-949f-213e0847d40c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2\n",
       "1    2\n",
       "2    2\n",
       "3    2\n",
       "4    2\n",
       "Name: Vies, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = data['Vies'] # label\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f06e60-3781-4297-aa2c-3eb070412d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_strat_vies, X_test_strat_vies, y_train_strat_vies, y_test_strat_vies = train_test_split(X, y,\n",
    "                                                                                                test_size=0.2,\n",
    "                                                                                                random_state=42,\n",
    "                                                                                                stratify=y)\n",
    "\n",
    "X_train_strat_vies.drop('Partido', axis=1, inplace=True) # remocao da coluna partido\n",
    "X_test_strat_vies.drop('Partido', axis=1, inplace=True) # remocao da coluna partido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "360df4ec-e598-4cec-9f29-3a567692cab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_strat_part, X_test_strat_part, y_train_strat_part, y_test_strat_part = train_test_split(X, y,\n",
    "                                                                                                test_size=0.2,\n",
    "                                                                                                random_state=42,\n",
    "                                                                                                stratify=data['Partido'])\n",
    "\n",
    "X_train_strat_part.drop('Partido', axis=1, inplace=True) # remocao da coluna partido\n",
    "X_test_strat_part.drop('Partido', axis=1, inplace=True) # remocao da coluna partido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d117821-a04c-44e9-bad2-29151010b32a",
   "metadata": {},
   "outputs": [],
   "source": [
    "part_teste = ['PSTU', 'PV', 'Novo'] # partidos do conjunto de teste\n",
    "\n",
    "test = data[data['Partido'].isin(part_teste)].copy() # selecao dos dados de teste\n",
    "test.drop('Partido', axis=1, inplace=True) # remocao da coluna partido\n",
    "\n",
    "train = data[~data['Partido'].isin(part_teste)].copy() # selecao dos dados de treino\n",
    "train.drop('Partido', axis=1, inplace=True) # remocao da coluna partido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "680152b8-45a6-427e-b8e1-330b3d39bd60",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_part_novos = train.drop('Vies', axis=1) # X_train\n",
    "y_train_part_novos = train['Vies'] # y_train\n",
    "\n",
    "X_test_part_novos = test.drop('Vies', axis=1) # X_test\n",
    "y_test_part_novos = test['Vies'] # y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3115d9f5-5c21-41c8-8392-196c78ce8ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = {'selection__k': 800,\n",
    "               'estimator__lambda': 0,\n",
    "               'estimator__gamma': 0,\n",
    "               'estimator__colsample_bytree': 1,\n",
    "               'estimator__alpha': 22}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "194334c4-4bef-4522-a4b9-7f6acf82cc21",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "                        ('scaling', MaxAbsScaler()), \n",
    "                        ('selection', SelectKBest()),\n",
    "                        ('ros', RandomOverSampler(random_state=42)),\n",
    "                        ('estimator', XGBClassifier(seed=42, tree_method='gpu_hist', gpu_id=0))\n",
    "                        ])\n",
    "    \n",
    "best_xgb = pipeline.set_params(**best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "430d307f-b0e7-4d81-884f-8855054247ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Pipeline.get_params of Pipeline(steps=[('scaling', MaxAbsScaler()), ('selection', SelectKBest(k=800)),\n",
       "                ('ros', RandomOverSampler(random_state=42)),\n",
       "                ('estimator',\n",
       "                 XGBClassifier(alpha=22, base_score=None, booster=None,\n",
       "                               callbacks=None, colsample_bylevel=None,\n",
       "                               colsample_bynode=None, colsample_bytree=1,\n",
       "                               early_stopping_rounds=None,\n",
       "                               enable_categorical=False, eval_metric=None,\n",
       "                               feature_types=None, gamma=0, gpu_id=0,\n",
       "                               grow_policy=None, importance_type=None,\n",
       "                               interaction_constraints=None, lambda=0,\n",
       "                               learning_rate=None, max_bin=None,\n",
       "                               max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "                               max_delta_step=None, max_depth=None,\n",
       "                               max_leaves=None, min_child_weight=None,\n",
       "                               missing=nan, monotone_constraints=None,\n",
       "                               n_estimators=100, n_jobs=None,\n",
       "                               num_parallel_tree=None, ...))])>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_xgb.get_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "09718113-89c7-478d-9ed8-8bf0d92f108c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Downloads2\\Anaconda\\download\\lib\\site-packages\\sklearn\\utils\\validation.py:623: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n",
      "D:\\Downloads2\\Anaconda\\download\\lib\\site-packages\\sklearn\\utils\\validation.py:623: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n",
      "D:\\Downloads2\\Anaconda\\download\\lib\\site-packages\\xgboost\\data.py:427: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(data):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-c1d861bf-23a1-4c8f-825b-55bc6f502ec5 {color: black;background-color: white;}#sk-c1d861bf-23a1-4c8f-825b-55bc6f502ec5 pre{padding: 0;}#sk-c1d861bf-23a1-4c8f-825b-55bc6f502ec5 div.sk-toggleable {background-color: white;}#sk-c1d861bf-23a1-4c8f-825b-55bc6f502ec5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-c1d861bf-23a1-4c8f-825b-55bc6f502ec5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-c1d861bf-23a1-4c8f-825b-55bc6f502ec5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-c1d861bf-23a1-4c8f-825b-55bc6f502ec5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-c1d861bf-23a1-4c8f-825b-55bc6f502ec5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-c1d861bf-23a1-4c8f-825b-55bc6f502ec5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-c1d861bf-23a1-4c8f-825b-55bc6f502ec5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-c1d861bf-23a1-4c8f-825b-55bc6f502ec5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-c1d861bf-23a1-4c8f-825b-55bc6f502ec5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-c1d861bf-23a1-4c8f-825b-55bc6f502ec5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-c1d861bf-23a1-4c8f-825b-55bc6f502ec5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-c1d861bf-23a1-4c8f-825b-55bc6f502ec5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-c1d861bf-23a1-4c8f-825b-55bc6f502ec5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-c1d861bf-23a1-4c8f-825b-55bc6f502ec5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-c1d861bf-23a1-4c8f-825b-55bc6f502ec5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-c1d861bf-23a1-4c8f-825b-55bc6f502ec5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 2em;bottom: 0;left: 50%;}#sk-c1d861bf-23a1-4c8f-825b-55bc6f502ec5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;}#sk-c1d861bf-23a1-4c8f-825b-55bc6f502ec5 div.sk-item {z-index: 1;}#sk-c1d861bf-23a1-4c8f-825b-55bc6f502ec5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;}#sk-c1d861bf-23a1-4c8f-825b-55bc6f502ec5 div.sk-parallel::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 2em;bottom: 0;left: 50%;}#sk-c1d861bf-23a1-4c8f-825b-55bc6f502ec5 div.sk-parallel-item {display: flex;flex-direction: column;position: relative;background-color: white;}#sk-c1d861bf-23a1-4c8f-825b-55bc6f502ec5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-c1d861bf-23a1-4c8f-825b-55bc6f502ec5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-c1d861bf-23a1-4c8f-825b-55bc6f502ec5 div.sk-parallel-item:only-child::after {width: 0;}#sk-c1d861bf-23a1-4c8f-825b-55bc6f502ec5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;position: relative;}#sk-c1d861bf-23a1-4c8f-825b-55bc6f502ec5 div.sk-label label {font-family: monospace;font-weight: bold;background-color: white;display: inline-block;line-height: 1.2em;}#sk-c1d861bf-23a1-4c8f-825b-55bc6f502ec5 div.sk-label-container {position: relative;z-index: 2;text-align: center;}#sk-c1d861bf-23a1-4c8f-825b-55bc6f502ec5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-c1d861bf-23a1-4c8f-825b-55bc6f502ec5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-c1d861bf-23a1-4c8f-825b-55bc6f502ec5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;scaling&#x27;, MaxAbsScaler()), (&#x27;selection&#x27;, SelectKBest(k=800)),\n",
       "                (&#x27;ros&#x27;, RandomOverSampler(random_state=42)),\n",
       "                (&#x27;estimator&#x27;,\n",
       "                 XGBClassifier(alpha=22, base_score=0.5, booster=&#x27;gbtree&#x27;,\n",
       "                               callbacks=None, colsample_bylevel=1,\n",
       "                               colsample_bynode=1, colsample_bytree=1,\n",
       "                               early_stopping_rounds=None,\n",
       "                               enable_categorical=False, eval_metric=None,\n",
       "                               feature_types=None, gamma=0, gpu_id=0,\n",
       "                               grow_policy=&#x27;depthwise&#x27;, importance_type=None,\n",
       "                               interaction_constraints=&#x27;&#x27;, lambda=0,\n",
       "                               learning_rate=0.300000012, max_bin=256,\n",
       "                               max_cat_threshold=64, max_cat_to_onehot=4,\n",
       "                               max_delta_step=0, max_depth=6, max_leaves=0,\n",
       "                               min_child_weight=1, missing=nan,\n",
       "                               monotone_constraints=&#x27;()&#x27;, n_estimators=100,\n",
       "                               n_jobs=0, num_parallel_tree=1, ...))])</pre><b>Please rerun this cell to show the HTML repr or trust the notebook.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"f32935aa-036b-488b-931a-fcfd31684c62\" type=\"checkbox\" ><label for=\"f32935aa-036b-488b-931a-fcfd31684c62\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;scaling&#x27;, MaxAbsScaler()), (&#x27;selection&#x27;, SelectKBest(k=800)),\n",
       "                (&#x27;ros&#x27;, RandomOverSampler(random_state=42)),\n",
       "                (&#x27;estimator&#x27;,\n",
       "                 XGBClassifier(alpha=22, base_score=0.5, booster=&#x27;gbtree&#x27;,\n",
       "                               callbacks=None, colsample_bylevel=1,\n",
       "                               colsample_bynode=1, colsample_bytree=1,\n",
       "                               early_stopping_rounds=None,\n",
       "                               enable_categorical=False, eval_metric=None,\n",
       "                               feature_types=None, gamma=0, gpu_id=0,\n",
       "                               grow_policy=&#x27;depthwise&#x27;, importance_type=None,\n",
       "                               interaction_constraints=&#x27;&#x27;, lambda=0,\n",
       "                               learning_rate=0.300000012, max_bin=256,\n",
       "                               max_cat_threshold=64, max_cat_to_onehot=4,\n",
       "                               max_delta_step=0, max_depth=6, max_leaves=0,\n",
       "                               min_child_weight=1, missing=nan,\n",
       "                               monotone_constraints=&#x27;()&#x27;, n_estimators=100,\n",
       "                               n_jobs=0, num_parallel_tree=1, ...))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"f5765095-7645-42f4-a5a5-95272c55b46f\" type=\"checkbox\" ><label for=\"f5765095-7645-42f4-a5a5-95272c55b46f\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MaxAbsScaler</label><div class=\"sk-toggleable__content\"><pre>MaxAbsScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"d51b26f3-8731-487d-8640-825c6b098fa7\" type=\"checkbox\" ><label for=\"d51b26f3-8731-487d-8640-825c6b098fa7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SelectKBest</label><div class=\"sk-toggleable__content\"><pre>SelectKBest(k=800)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"a750d25b-4cda-4828-8cb6-44e3fef23a8e\" type=\"checkbox\" ><label for=\"a750d25b-4cda-4828-8cb6-44e3fef23a8e\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomOverSampler</label><div class=\"sk-toggleable__content\"><pre>RandomOverSampler(random_state=42)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"dc079722-4d48-46a7-b5c8-b1726b1e6cbf\" type=\"checkbox\" ><label for=\"dc079722-4d48-46a7-b5c8-b1726b1e6cbf\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(alpha=22, base_score=0.5, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=None, feature_types=None, gamma=0, gpu_id=0,\n",
       "              grow_policy=&#x27;depthwise&#x27;, importance_type=None,\n",
       "              interaction_constraints=&#x27;&#x27;, lambda=0, learning_rate=0.300000012,\n",
       "              max_bin=256, max_cat_threshold=64, max_cat_to_onehot=4,\n",
       "              max_delta_step=0, max_depth=6, max_leaves=0, min_child_weight=1,\n",
       "              missing=nan, monotone_constraints=&#x27;()&#x27;, n_estimators=100,\n",
       "              n_jobs=0, num_parallel_tree=1, ...)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('scaling', MaxAbsScaler()), ('selection', SelectKBest(k=800)),\n",
       "                ('ros', RandomOverSampler(random_state=42)),\n",
       "                ('estimator',\n",
       "                 XGBClassifier(alpha=22, base_score=0.5, booster='gbtree',\n",
       "                               callbacks=None, colsample_bylevel=1,\n",
       "                               colsample_bynode=1, colsample_bytree=1,\n",
       "                               early_stopping_rounds=None,\n",
       "                               enable_categorical=False, eval_metric=None,\n",
       "                               feature_types=None, gamma=0, gpu_id=0,\n",
       "                               grow_policy='depthwise', importance_type=None,\n",
       "                               interaction_constraints='', lambda=0,\n",
       "                               learning_rate=0.300000012, max_bin=256,\n",
       "                               max_cat_threshold=64, max_cat_to_onehot=4,\n",
       "                               max_delta_step=0, max_depth=6, max_leaves=0,\n",
       "                               min_child_weight=1, missing=nan,\n",
       "                               monotone_constraints='()', n_estimators=100,\n",
       "                               n_jobs=0, num_parallel_tree=1, ...))])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_xgb.fit(X.drop('Partido', axis=1), y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b4cbc4-63be-40a3-a6df-1a64cd459283",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "eaa2e497-ab5c-45b0-9217-0fc7b9948e1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emb_1</th>\n",
       "      <th>emb_2</th>\n",
       "      <th>emb_3</th>\n",
       "      <th>emb_4</th>\n",
       "      <th>emb_5</th>\n",
       "      <th>emb_6</th>\n",
       "      <th>emb_7</th>\n",
       "      <th>emb_8</th>\n",
       "      <th>emb_9</th>\n",
       "      <th>emb_10</th>\n",
       "      <th>...</th>\n",
       "      <th>emb_1015</th>\n",
       "      <th>emb_1016</th>\n",
       "      <th>emb_1017</th>\n",
       "      <th>emb_1018</th>\n",
       "      <th>emb_1019</th>\n",
       "      <th>emb_1020</th>\n",
       "      <th>emb_1021</th>\n",
       "      <th>emb_1022</th>\n",
       "      <th>emb_1023</th>\n",
       "      <th>emb_1024</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.177256</td>\n",
       "      <td>-0.246991</td>\n",
       "      <td>0.087106</td>\n",
       "      <td>0.224288</td>\n",
       "      <td>0.162842</td>\n",
       "      <td>-0.261285</td>\n",
       "      <td>-0.354171</td>\n",
       "      <td>-0.329556</td>\n",
       "      <td>-0.042913</td>\n",
       "      <td>0.221940</td>\n",
       "      <td>...</td>\n",
       "      <td>0.237059</td>\n",
       "      <td>0.029648</td>\n",
       "      <td>-0.535245</td>\n",
       "      <td>-0.173133</td>\n",
       "      <td>-0.050813</td>\n",
       "      <td>-0.389454</td>\n",
       "      <td>0.441995</td>\n",
       "      <td>0.096808</td>\n",
       "      <td>-0.216968</td>\n",
       "      <td>0.300969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.188755</td>\n",
       "      <td>-0.236970</td>\n",
       "      <td>0.264890</td>\n",
       "      <td>0.210608</td>\n",
       "      <td>-0.049070</td>\n",
       "      <td>-0.323651</td>\n",
       "      <td>-0.560016</td>\n",
       "      <td>-0.170308</td>\n",
       "      <td>0.030440</td>\n",
       "      <td>0.160717</td>\n",
       "      <td>...</td>\n",
       "      <td>0.165150</td>\n",
       "      <td>0.010903</td>\n",
       "      <td>-0.423455</td>\n",
       "      <td>-0.169438</td>\n",
       "      <td>-0.006396</td>\n",
       "      <td>-0.319956</td>\n",
       "      <td>0.625356</td>\n",
       "      <td>0.090047</td>\n",
       "      <td>-0.179706</td>\n",
       "      <td>0.056563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.339368</td>\n",
       "      <td>-0.105536</td>\n",
       "      <td>0.235968</td>\n",
       "      <td>0.152529</td>\n",
       "      <td>0.164733</td>\n",
       "      <td>-0.254474</td>\n",
       "      <td>-0.333641</td>\n",
       "      <td>-0.317160</td>\n",
       "      <td>0.050852</td>\n",
       "      <td>0.216817</td>\n",
       "      <td>...</td>\n",
       "      <td>0.240040</td>\n",
       "      <td>-0.079102</td>\n",
       "      <td>-0.451281</td>\n",
       "      <td>-0.070833</td>\n",
       "      <td>0.014464</td>\n",
       "      <td>-0.143781</td>\n",
       "      <td>0.436501</td>\n",
       "      <td>-0.048927</td>\n",
       "      <td>0.018316</td>\n",
       "      <td>0.124147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.336466</td>\n",
       "      <td>-0.262542</td>\n",
       "      <td>0.326849</td>\n",
       "      <td>0.218233</td>\n",
       "      <td>-0.019247</td>\n",
       "      <td>-0.266457</td>\n",
       "      <td>-0.444466</td>\n",
       "      <td>-0.092072</td>\n",
       "      <td>0.032738</td>\n",
       "      <td>0.223704</td>\n",
       "      <td>...</td>\n",
       "      <td>0.369901</td>\n",
       "      <td>-0.112040</td>\n",
       "      <td>-0.526602</td>\n",
       "      <td>-0.055398</td>\n",
       "      <td>0.039789</td>\n",
       "      <td>-0.476769</td>\n",
       "      <td>0.351495</td>\n",
       "      <td>0.198413</td>\n",
       "      <td>0.090005</td>\n",
       "      <td>0.069517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.320413</td>\n",
       "      <td>-0.237129</td>\n",
       "      <td>0.442062</td>\n",
       "      <td>0.159104</td>\n",
       "      <td>-0.074181</td>\n",
       "      <td>-0.106775</td>\n",
       "      <td>-0.570315</td>\n",
       "      <td>-0.043499</td>\n",
       "      <td>0.011053</td>\n",
       "      <td>0.187507</td>\n",
       "      <td>...</td>\n",
       "      <td>0.336812</td>\n",
       "      <td>-0.094797</td>\n",
       "      <td>-0.526176</td>\n",
       "      <td>0.075011</td>\n",
       "      <td>-0.158330</td>\n",
       "      <td>-0.192057</td>\n",
       "      <td>0.340394</td>\n",
       "      <td>0.141768</td>\n",
       "      <td>-0.139985</td>\n",
       "      <td>0.312520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.140610</td>\n",
       "      <td>-0.295143</td>\n",
       "      <td>0.277217</td>\n",
       "      <td>0.131121</td>\n",
       "      <td>0.110425</td>\n",
       "      <td>-0.179603</td>\n",
       "      <td>-0.639545</td>\n",
       "      <td>-0.218153</td>\n",
       "      <td>0.016547</td>\n",
       "      <td>0.125998</td>\n",
       "      <td>...</td>\n",
       "      <td>0.357463</td>\n",
       "      <td>-0.365226</td>\n",
       "      <td>-0.441883</td>\n",
       "      <td>0.008965</td>\n",
       "      <td>-0.277259</td>\n",
       "      <td>-0.289251</td>\n",
       "      <td>0.306093</td>\n",
       "      <td>0.002809</td>\n",
       "      <td>-0.019155</td>\n",
       "      <td>0.237498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.190400</td>\n",
       "      <td>-0.210374</td>\n",
       "      <td>0.312346</td>\n",
       "      <td>0.308537</td>\n",
       "      <td>0.177782</td>\n",
       "      <td>-0.179490</td>\n",
       "      <td>-0.458267</td>\n",
       "      <td>-0.100351</td>\n",
       "      <td>0.052892</td>\n",
       "      <td>0.054652</td>\n",
       "      <td>...</td>\n",
       "      <td>0.225507</td>\n",
       "      <td>-0.022758</td>\n",
       "      <td>-0.503361</td>\n",
       "      <td>0.109931</td>\n",
       "      <td>-0.063078</td>\n",
       "      <td>-0.254466</td>\n",
       "      <td>0.205095</td>\n",
       "      <td>0.206967</td>\n",
       "      <td>-0.192988</td>\n",
       "      <td>0.324998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.166542</td>\n",
       "      <td>-0.326735</td>\n",
       "      <td>0.206906</td>\n",
       "      <td>0.286478</td>\n",
       "      <td>0.130018</td>\n",
       "      <td>-0.261664</td>\n",
       "      <td>-0.526148</td>\n",
       "      <td>-0.090842</td>\n",
       "      <td>0.113488</td>\n",
       "      <td>0.046320</td>\n",
       "      <td>...</td>\n",
       "      <td>0.409236</td>\n",
       "      <td>-0.038461</td>\n",
       "      <td>-0.495830</td>\n",
       "      <td>-0.058001</td>\n",
       "      <td>-0.096960</td>\n",
       "      <td>-0.320547</td>\n",
       "      <td>0.273821</td>\n",
       "      <td>0.215213</td>\n",
       "      <td>-0.179342</td>\n",
       "      <td>0.408732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.172165</td>\n",
       "      <td>-0.265606</td>\n",
       "      <td>0.262698</td>\n",
       "      <td>0.111486</td>\n",
       "      <td>0.060641</td>\n",
       "      <td>-0.178284</td>\n",
       "      <td>-0.464203</td>\n",
       "      <td>-0.243654</td>\n",
       "      <td>0.020358</td>\n",
       "      <td>0.341577</td>\n",
       "      <td>...</td>\n",
       "      <td>0.238188</td>\n",
       "      <td>0.053228</td>\n",
       "      <td>-0.653927</td>\n",
       "      <td>0.067177</td>\n",
       "      <td>-0.084639</td>\n",
       "      <td>-0.411395</td>\n",
       "      <td>0.412065</td>\n",
       "      <td>0.210706</td>\n",
       "      <td>-0.168072</td>\n",
       "      <td>0.123498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.175475</td>\n",
       "      <td>-0.161600</td>\n",
       "      <td>0.165423</td>\n",
       "      <td>0.326432</td>\n",
       "      <td>0.035058</td>\n",
       "      <td>-0.228445</td>\n",
       "      <td>-0.537136</td>\n",
       "      <td>-0.082007</td>\n",
       "      <td>0.011754</td>\n",
       "      <td>0.324337</td>\n",
       "      <td>...</td>\n",
       "      <td>0.265662</td>\n",
       "      <td>-0.221337</td>\n",
       "      <td>-0.526943</td>\n",
       "      <td>0.008523</td>\n",
       "      <td>-0.057346</td>\n",
       "      <td>-0.390026</td>\n",
       "      <td>0.413752</td>\n",
       "      <td>0.152417</td>\n",
       "      <td>-0.139329</td>\n",
       "      <td>0.277802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.261241</td>\n",
       "      <td>-0.397871</td>\n",
       "      <td>0.392211</td>\n",
       "      <td>0.268019</td>\n",
       "      <td>-0.126133</td>\n",
       "      <td>-0.308014</td>\n",
       "      <td>-0.607071</td>\n",
       "      <td>-0.248587</td>\n",
       "      <td>0.125661</td>\n",
       "      <td>0.171796</td>\n",
       "      <td>...</td>\n",
       "      <td>0.416282</td>\n",
       "      <td>0.152969</td>\n",
       "      <td>-0.463592</td>\n",
       "      <td>-0.092736</td>\n",
       "      <td>-0.160093</td>\n",
       "      <td>-0.498820</td>\n",
       "      <td>0.592530</td>\n",
       "      <td>0.004972</td>\n",
       "      <td>0.048803</td>\n",
       "      <td>0.213021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.274680</td>\n",
       "      <td>-0.189342</td>\n",
       "      <td>0.296749</td>\n",
       "      <td>0.220278</td>\n",
       "      <td>0.067130</td>\n",
       "      <td>-0.240698</td>\n",
       "      <td>-0.309007</td>\n",
       "      <td>-0.352314</td>\n",
       "      <td>0.165745</td>\n",
       "      <td>0.377318</td>\n",
       "      <td>...</td>\n",
       "      <td>0.440740</td>\n",
       "      <td>-0.171464</td>\n",
       "      <td>-0.460113</td>\n",
       "      <td>0.035471</td>\n",
       "      <td>-0.104581</td>\n",
       "      <td>-0.189615</td>\n",
       "      <td>0.516179</td>\n",
       "      <td>0.167349</td>\n",
       "      <td>0.003736</td>\n",
       "      <td>0.165195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.307200</td>\n",
       "      <td>-0.418797</td>\n",
       "      <td>0.212683</td>\n",
       "      <td>0.236015</td>\n",
       "      <td>0.010768</td>\n",
       "      <td>-0.190354</td>\n",
       "      <td>-0.473384</td>\n",
       "      <td>-0.098731</td>\n",
       "      <td>-0.101692</td>\n",
       "      <td>0.242352</td>\n",
       "      <td>...</td>\n",
       "      <td>0.252975</td>\n",
       "      <td>-0.107735</td>\n",
       "      <td>-0.547219</td>\n",
       "      <td>-0.226634</td>\n",
       "      <td>-0.007532</td>\n",
       "      <td>-0.343869</td>\n",
       "      <td>0.348907</td>\n",
       "      <td>0.008038</td>\n",
       "      <td>-0.109442</td>\n",
       "      <td>0.343865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.128241</td>\n",
       "      <td>-0.152810</td>\n",
       "      <td>0.304071</td>\n",
       "      <td>0.217418</td>\n",
       "      <td>0.092318</td>\n",
       "      <td>-0.221885</td>\n",
       "      <td>-0.294086</td>\n",
       "      <td>-0.177040</td>\n",
       "      <td>0.041401</td>\n",
       "      <td>0.670127</td>\n",
       "      <td>...</td>\n",
       "      <td>0.359956</td>\n",
       "      <td>0.071648</td>\n",
       "      <td>-0.438616</td>\n",
       "      <td>-0.004626</td>\n",
       "      <td>-0.118038</td>\n",
       "      <td>-0.248384</td>\n",
       "      <td>0.397212</td>\n",
       "      <td>0.121461</td>\n",
       "      <td>0.035120</td>\n",
       "      <td>0.200990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.226462</td>\n",
       "      <td>-0.130256</td>\n",
       "      <td>0.331638</td>\n",
       "      <td>0.204889</td>\n",
       "      <td>0.119883</td>\n",
       "      <td>-0.203830</td>\n",
       "      <td>-0.359940</td>\n",
       "      <td>-0.400634</td>\n",
       "      <td>0.081033</td>\n",
       "      <td>0.426497</td>\n",
       "      <td>...</td>\n",
       "      <td>0.252933</td>\n",
       "      <td>-0.254213</td>\n",
       "      <td>-0.468719</td>\n",
       "      <td>-0.155129</td>\n",
       "      <td>-0.151718</td>\n",
       "      <td>-0.325068</td>\n",
       "      <td>0.373071</td>\n",
       "      <td>0.181258</td>\n",
       "      <td>-0.143559</td>\n",
       "      <td>0.111558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.307803</td>\n",
       "      <td>-0.341285</td>\n",
       "      <td>0.190799</td>\n",
       "      <td>0.286929</td>\n",
       "      <td>0.271408</td>\n",
       "      <td>-0.268892</td>\n",
       "      <td>-0.448902</td>\n",
       "      <td>-0.230180</td>\n",
       "      <td>0.148367</td>\n",
       "      <td>0.334898</td>\n",
       "      <td>...</td>\n",
       "      <td>0.435246</td>\n",
       "      <td>-0.080614</td>\n",
       "      <td>-0.541853</td>\n",
       "      <td>0.027023</td>\n",
       "      <td>-0.108160</td>\n",
       "      <td>-0.287847</td>\n",
       "      <td>0.442786</td>\n",
       "      <td>0.112160</td>\n",
       "      <td>-0.085022</td>\n",
       "      <td>0.410355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.176134</td>\n",
       "      <td>-0.192714</td>\n",
       "      <td>0.314688</td>\n",
       "      <td>0.156542</td>\n",
       "      <td>0.030271</td>\n",
       "      <td>-0.095977</td>\n",
       "      <td>-0.341334</td>\n",
       "      <td>-0.144412</td>\n",
       "      <td>0.000497</td>\n",
       "      <td>0.185316</td>\n",
       "      <td>...</td>\n",
       "      <td>0.151417</td>\n",
       "      <td>0.042679</td>\n",
       "      <td>-0.496944</td>\n",
       "      <td>0.004829</td>\n",
       "      <td>-0.210404</td>\n",
       "      <td>-0.326477</td>\n",
       "      <td>0.263101</td>\n",
       "      <td>-0.167758</td>\n",
       "      <td>-0.222273</td>\n",
       "      <td>0.135592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.193940</td>\n",
       "      <td>-0.306464</td>\n",
       "      <td>0.241176</td>\n",
       "      <td>0.355878</td>\n",
       "      <td>0.017510</td>\n",
       "      <td>-0.223934</td>\n",
       "      <td>-0.357897</td>\n",
       "      <td>-0.178597</td>\n",
       "      <td>0.028561</td>\n",
       "      <td>0.373258</td>\n",
       "      <td>...</td>\n",
       "      <td>0.468521</td>\n",
       "      <td>-0.036599</td>\n",
       "      <td>-0.577710</td>\n",
       "      <td>0.010504</td>\n",
       "      <td>-0.092081</td>\n",
       "      <td>-0.260597</td>\n",
       "      <td>0.345440</td>\n",
       "      <td>-0.002929</td>\n",
       "      <td>0.101899</td>\n",
       "      <td>0.240018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.132888</td>\n",
       "      <td>-0.308393</td>\n",
       "      <td>0.315664</td>\n",
       "      <td>0.234603</td>\n",
       "      <td>-0.076008</td>\n",
       "      <td>-0.133397</td>\n",
       "      <td>-0.427871</td>\n",
       "      <td>-0.201913</td>\n",
       "      <td>0.035450</td>\n",
       "      <td>0.481822</td>\n",
       "      <td>...</td>\n",
       "      <td>0.269101</td>\n",
       "      <td>-0.034571</td>\n",
       "      <td>-0.461713</td>\n",
       "      <td>-0.017827</td>\n",
       "      <td>-0.135077</td>\n",
       "      <td>-0.462612</td>\n",
       "      <td>0.339474</td>\n",
       "      <td>-0.111406</td>\n",
       "      <td>-0.201322</td>\n",
       "      <td>0.149645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.275480</td>\n",
       "      <td>-0.337775</td>\n",
       "      <td>0.337466</td>\n",
       "      <td>0.306029</td>\n",
       "      <td>0.111629</td>\n",
       "      <td>-0.309052</td>\n",
       "      <td>-0.678666</td>\n",
       "      <td>-0.182828</td>\n",
       "      <td>0.104656</td>\n",
       "      <td>0.185328</td>\n",
       "      <td>...</td>\n",
       "      <td>0.346161</td>\n",
       "      <td>-0.114152</td>\n",
       "      <td>-0.548150</td>\n",
       "      <td>-0.127501</td>\n",
       "      <td>0.001728</td>\n",
       "      <td>-0.374939</td>\n",
       "      <td>0.593082</td>\n",
       "      <td>0.234021</td>\n",
       "      <td>0.002007</td>\n",
       "      <td>-0.013616</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20 rows × 1024 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       emb_1     emb_2     emb_3     emb_4     emb_5     emb_6     emb_7  \\\n",
       "0   0.177256 -0.246991  0.087106  0.224288  0.162842 -0.261285 -0.354171   \n",
       "1   0.188755 -0.236970  0.264890  0.210608 -0.049070 -0.323651 -0.560016   \n",
       "2   0.339368 -0.105536  0.235968  0.152529  0.164733 -0.254474 -0.333641   \n",
       "3   0.336466 -0.262542  0.326849  0.218233 -0.019247 -0.266457 -0.444466   \n",
       "4   0.320413 -0.237129  0.442062  0.159104 -0.074181 -0.106775 -0.570315   \n",
       "5   0.140610 -0.295143  0.277217  0.131121  0.110425 -0.179603 -0.639545   \n",
       "6   0.190400 -0.210374  0.312346  0.308537  0.177782 -0.179490 -0.458267   \n",
       "7   0.166542 -0.326735  0.206906  0.286478  0.130018 -0.261664 -0.526148   \n",
       "8   0.172165 -0.265606  0.262698  0.111486  0.060641 -0.178284 -0.464203   \n",
       "9   0.175475 -0.161600  0.165423  0.326432  0.035058 -0.228445 -0.537136   \n",
       "10  0.261241 -0.397871  0.392211  0.268019 -0.126133 -0.308014 -0.607071   \n",
       "11  0.274680 -0.189342  0.296749  0.220278  0.067130 -0.240698 -0.309007   \n",
       "12  0.307200 -0.418797  0.212683  0.236015  0.010768 -0.190354 -0.473384   \n",
       "13  0.128241 -0.152810  0.304071  0.217418  0.092318 -0.221885 -0.294086   \n",
       "14  0.226462 -0.130256  0.331638  0.204889  0.119883 -0.203830 -0.359940   \n",
       "15  0.307803 -0.341285  0.190799  0.286929  0.271408 -0.268892 -0.448902   \n",
       "16  0.176134 -0.192714  0.314688  0.156542  0.030271 -0.095977 -0.341334   \n",
       "17  0.193940 -0.306464  0.241176  0.355878  0.017510 -0.223934 -0.357897   \n",
       "18  0.132888 -0.308393  0.315664  0.234603 -0.076008 -0.133397 -0.427871   \n",
       "19  0.275480 -0.337775  0.337466  0.306029  0.111629 -0.309052 -0.678666   \n",
       "\n",
       "       emb_8     emb_9    emb_10  ...  emb_1015  emb_1016  emb_1017  emb_1018  \\\n",
       "0  -0.329556 -0.042913  0.221940  ...  0.237059  0.029648 -0.535245 -0.173133   \n",
       "1  -0.170308  0.030440  0.160717  ...  0.165150  0.010903 -0.423455 -0.169438   \n",
       "2  -0.317160  0.050852  0.216817  ...  0.240040 -0.079102 -0.451281 -0.070833   \n",
       "3  -0.092072  0.032738  0.223704  ...  0.369901 -0.112040 -0.526602 -0.055398   \n",
       "4  -0.043499  0.011053  0.187507  ...  0.336812 -0.094797 -0.526176  0.075011   \n",
       "5  -0.218153  0.016547  0.125998  ...  0.357463 -0.365226 -0.441883  0.008965   \n",
       "6  -0.100351  0.052892  0.054652  ...  0.225507 -0.022758 -0.503361  0.109931   \n",
       "7  -0.090842  0.113488  0.046320  ...  0.409236 -0.038461 -0.495830 -0.058001   \n",
       "8  -0.243654  0.020358  0.341577  ...  0.238188  0.053228 -0.653927  0.067177   \n",
       "9  -0.082007  0.011754  0.324337  ...  0.265662 -0.221337 -0.526943  0.008523   \n",
       "10 -0.248587  0.125661  0.171796  ...  0.416282  0.152969 -0.463592 -0.092736   \n",
       "11 -0.352314  0.165745  0.377318  ...  0.440740 -0.171464 -0.460113  0.035471   \n",
       "12 -0.098731 -0.101692  0.242352  ...  0.252975 -0.107735 -0.547219 -0.226634   \n",
       "13 -0.177040  0.041401  0.670127  ...  0.359956  0.071648 -0.438616 -0.004626   \n",
       "14 -0.400634  0.081033  0.426497  ...  0.252933 -0.254213 -0.468719 -0.155129   \n",
       "15 -0.230180  0.148367  0.334898  ...  0.435246 -0.080614 -0.541853  0.027023   \n",
       "16 -0.144412  0.000497  0.185316  ...  0.151417  0.042679 -0.496944  0.004829   \n",
       "17 -0.178597  0.028561  0.373258  ...  0.468521 -0.036599 -0.577710  0.010504   \n",
       "18 -0.201913  0.035450  0.481822  ...  0.269101 -0.034571 -0.461713 -0.017827   \n",
       "19 -0.182828  0.104656  0.185328  ...  0.346161 -0.114152 -0.548150 -0.127501   \n",
       "\n",
       "    emb_1019  emb_1020  emb_1021  emb_1022  emb_1023  emb_1024  \n",
       "0  -0.050813 -0.389454  0.441995  0.096808 -0.216968  0.300969  \n",
       "1  -0.006396 -0.319956  0.625356  0.090047 -0.179706  0.056563  \n",
       "2   0.014464 -0.143781  0.436501 -0.048927  0.018316  0.124147  \n",
       "3   0.039789 -0.476769  0.351495  0.198413  0.090005  0.069517  \n",
       "4  -0.158330 -0.192057  0.340394  0.141768 -0.139985  0.312520  \n",
       "5  -0.277259 -0.289251  0.306093  0.002809 -0.019155  0.237498  \n",
       "6  -0.063078 -0.254466  0.205095  0.206967 -0.192988  0.324998  \n",
       "7  -0.096960 -0.320547  0.273821  0.215213 -0.179342  0.408732  \n",
       "8  -0.084639 -0.411395  0.412065  0.210706 -0.168072  0.123498  \n",
       "9  -0.057346 -0.390026  0.413752  0.152417 -0.139329  0.277802  \n",
       "10 -0.160093 -0.498820  0.592530  0.004972  0.048803  0.213021  \n",
       "11 -0.104581 -0.189615  0.516179  0.167349  0.003736  0.165195  \n",
       "12 -0.007532 -0.343869  0.348907  0.008038 -0.109442  0.343865  \n",
       "13 -0.118038 -0.248384  0.397212  0.121461  0.035120  0.200990  \n",
       "14 -0.151718 -0.325068  0.373071  0.181258 -0.143559  0.111558  \n",
       "15 -0.108160 -0.287847  0.442786  0.112160 -0.085022  0.410355  \n",
       "16 -0.210404 -0.326477  0.263101 -0.167758 -0.222273  0.135592  \n",
       "17 -0.092081 -0.260597  0.345440 -0.002929  0.101899  0.240018  \n",
       "18 -0.135077 -0.462612  0.339474 -0.111406 -0.201322  0.149645  \n",
       "19  0.001728 -0.374939  0.593082  0.234021  0.002007 -0.013616  \n",
       "\n",
       "[20 rows x 1024 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "novas_noticias = pd.read_csv('noticias-teste-embedding.csv')\n",
    "novas_noticias.drop(['Unnamed: 0', 'Conteudo'], axis=1, inplace=True)\n",
    "novas_noticias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "55bead73-dcd5-4498-af2c-24e567317b4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Downloads2\\Anaconda\\download\\lib\\site-packages\\sklearn\\utils\\validation.py:623: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = best_xgb.predict(novas_noticias)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d572b271-6c41-486f-a4c6-044451a11766",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Vies'] = data['Vies'].map({'direita':2,\n",
    "                                'centro': 1,\n",
    "                                'esquerda': 0})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
