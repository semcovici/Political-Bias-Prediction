


import pandas as pd 

from sklearn.preprocessing import MaxAbsScaler
from sklearn.preprocessing import MinMaxScaler

from sklearn.naive_bayes import MultinomialNB
from sklearn.svm import SVC
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import CountVectorizer
#from sklearn.pipeline import Pipeline
from imblearn.pipeline import Pipeline
from imblearn.over_sampling import RandomOverSampler
from sklearn.feature_selection import SelectKBest
from sklearn.model_selection import cross_val_score
from sklearn.metrics import classification_report
from sklearn.preprocessing import StandardScaler


from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier

from xgboost import XGBClassifier
from sklearn.model_selection import StratifiedKFold
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.compose import ColumnTransformer
from sklearn.metrics import accuracy_score
import numpy as np
from sklearn.model_selection import RandomizedSearchCV
from sklearn import set_config
set_config(display='diagram')
import datetime





data = pd.read_parquet('../dataset/processed/artigos_tratados/bertimbau/artigos_tratados_bert_lg.parquet')
rem_cols = ['Conteudo', 'Partido', 'URL']
data.drop(rem_cols, axis=1, inplace=True)


data.head() # visualização das primeiras 5 linhas do dataframe


# conversao dos rotulos categoricos para numericos
data['Vies'] = data['Vies'].map({
                                    'direita':2,
                                    'centro': 1,
                                    'esquerda': 0})


data.head()





# a seguir os dados serão divididos entre features (X) e label (y)
X_columns = [column for column in data.columns if column != 'Vies']
X = data[X_columns]
X.head() # features


y = data['Vies'] # label
y.head()


X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42,
                                                   stratify=y)





def compara(iteracoes, modelos, sampler):
    
    # Escrita no arquivo
    nome_arquivo = 'compara-nb-svc-bert.txt'
    with open(nome_arquivo, "w") as arquivo:
        pass

    samplers = [RandomOverSampler(random_state=42), None]

    selection = SelectKBest() # printar kbest
    
    for model in modelos:

        for sampler in samplers:
    
            param_grid = None
            scaler = None

            if isinstance(model, MultinomialNB):
                scaler = MinMaxScaler() # valores nao negativos
            else:
                scaler = MaxAbsScaler()
            
            pipeline = Pipeline([
                    ('scaling', scaler), 
                    ('selection', selection),
                    ('ros', sampler), # printar sampler
                    ('estimator', model)
                    ])
    
            if isinstance(model, MultinomialNB):
                    param_grid = {
                    "selection__k": [200,400,600,800,1024],
                    "estimator__alpha": [50, 15, 10, 5, 1, 0.5, 0.3, 0.1, 0.05, 0.03, 0.02, 0.01,  0.001],
                    "estimator__fit_prior": [True, False],
                    }
    
            if isinstance(model, SVC):
                    param_grid = {
                    "selection__k": [200,400,600,800,1024],
                    "estimator__gamma": [1, 0.1, 0.01, 0.001],
                    "estimator__kernel": ['linear', 'sigmoid'],
                    "estimator__C": [0.1, 1, 10, 100]
                    }
    
    
            if isinstance(model, RandomForestClassifier):
                param_grid = {
                "selection__k": [200,400,600,800,1024],
                "estimator__n_estimators": np.arange(20,150), 
                "estimator__max_features": ['log2', 'sqrt'],
                "estimator__max_depth": np.arange(10,110),
                "estimator__min_samples_split": np.arange(2,11),
                "estimator__min_samples_leaf": np.arange(1,5),
                "estimator__bootstrap": [True, False]
                }
                
            if isinstance(model, XGBClassifier):
                param_grid = {
                "selection__k": [200,400,600,800,1024],
                "estimator__gamma": np.linspace(0,9,100, dtype=np.int64),
                "estimator__alpha": np.linspace(0,40,100, dtype=np.int64),
                "estimator__lambda": np.linspace(0,3,10, dtype=np.int64),
                "estimator__colsample_bytree": np.linspace(0.2,1,10, dtype=np.int64)
                }
    
            
            # Prints do modelo e da vetorização
            print(f'Modelo: {model}')
                
            
            # Random Search
            comeco_random_search = datetime.datetime.now()
            print(f'Começo da Random Search: {comeco_random_search}')
                
            random_search = RandomizedSearchCV(pipeline, param_distributions=param_grid,cv=StratifiedKFold(n_splits=5),
                                                n_iter=iteracoes, n_jobs=2, random_state=42)
            
            model_trained = random_search.fit(X_train, y_train)
            
            final_random_search = datetime.datetime.now()
            print(f'Final da Random Search: {final_random_search}')
            
            score_random_search = model_trained.best_score_
            score_random_search *= 100
            score_random_search = round(score_random_search,2)
            print(f'Melhor resultado na Random Search: {score_random_search}%')
            
            print('Melhores parâmetros encontrados:')
            print(model_trained.best_params_)
            
            # Predição
            y_pred = model_trained.predict(X_test)
            acc_pred = accuracy_score(y_test, y_pred)
            acc_pred *= 100
            acc_pred = round(acc_pred,2)
            print(f'Acurácia predita = {acc_pred}%')
    
            report = classification_report(y_test, y_pred)
            print(report)
                    
            
            print('----------------------------------------------')
            
            # Escrita no arquivo
            with open(nome_arquivo, "a") as arquivo:
                
                arquivo.write(f'Modelo: {model}\n')
                arquivo.write(f'Começo da Random Search: {comeco_random_search}\n')
                arquivo.write(f'Final da Random Search: {final_random_search}\n')
                arquivo.write(f'Melhor resultado na Random Search: {score_random_search}\n')
                arquivo.write('Melhores parâmetros encontrados:\n')
                arquivo.write(str(model_trained.best_params_))
                arquivo.write('\n')
                arquivo.write(f'Acurácia predita = {acc_pred}%\n')
                arquivo.write(f'Classification report: \n')
                arquivo.write(report)
                arquivo.write('----------------------------------------------\n')


modelos = [MultinomialNB(), SVC(random_state=42)]

compara(1, modelos)
