


import pandas as pd 

from sklearn.preprocessing import MaxAbsScaler

from sklearn.naive_bayes import MultinomialNB
from sklearn.svm import SVC
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import CountVectorizer
#from sklearn.pipeline import Pipeline
from imblearn.pipeline import Pipeline
from imblearn.over_sampling import RandomOverSampler
from sklearn.feature_selection import SelectKBest
from sklearn.model_selection import cross_val_score
from sklearn.metrics import classification_report


from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier

from xgboost import XGBClassifier
from sklearn.model_selection import StratifiedKFold
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.compose import ColumnTransformer
from sklearn.metrics import accuracy_score
import numpy as np
from sklearn.model_selection import RandomizedSearchCV
from sklearn import set_config
set_config(display='diagram')
import datetime





data = pd.read_parquet('../dataset/processed/artigos_tratados/bertimbau/artigos_tratados_bert_lg.parquet')
rem_cols = ['Conteudo', 'URL']
data.drop(rem_cols, axis=1, inplace=True)


data.head() # visualização das primeiras 5 linhas do dataframe


# conversao dos rotulos categoricos para numericos
data['Vies'] = data['Vies'].map({'direita':2,
                                'centro': 1,
                                'esquerda': 0})


data.head()





# a seguir os dados serão divididos entre features (X) e label (y)
X_columns = [column for column in data.columns if column != 'Vies' and column != 'Partido']
X = data[X_columns]
X.head() # features


y = data['Vies'] # label
y.head()


X_train_strat_label, X_test_strat_label,
y_train_strat_label, y_test_strat_label = train_test_split(X, y, test_size=0.2, random_state=42,
                                                   stratify=y)


X_train_strat_part, X_test_strat_part,
y_train_strat_part, y_test_strat_part = train_test_split(X, y, test_size=0.2, random_state=42,
                                                   stratify=data['Partido'])





def seleciona_grid(model):

    param_grid = None

    if isinstance(model, MultinomialNB):
            param_grid = {
            "selection__k": [200,400,600,800,1024],
            "estimator__alpha": [50, 15, 10, 5, 1, 0.5, 0.3, 0.1, 0.05, 0.03, 0.02, 0.01,  0.001],
            "estimator__fit_prior": [True, False],
            }

    if isinstance(model, SVC):
            param_grid = {
            "selection__k": [200,400,600,800,1024],
            "estimator__gamma": [1, 0.1, 0.01, 0.001],
            "estimator__kernel": ['linear', 'sigmoid'],
            "estimator__C": [0.1, 1, 10, 100]
            }


    if isinstance(model, RandomForestClassifier):
        param_grid = {
        "selection__k": [200,400,600,800,1024],
        "estimator__n_estimators": np.arange(20,150), 
        "estimator__max_features": ['log2', 'sqrt'],
        "estimator__max_depth": np.arange(10,110),
        "estimator__min_samples_split": np.arange(2,11),
        "estimator__min_samples_leaf": np.arange(1,5),
        "estimator__bootstrap": [True, False]
        }
        
    if isinstance(model, XGBClassifier):
        param_grid = {
        "selection__k": [200,400,600,800,1024],
        "estimator__gamma": np.linspace(0,9,100, dtype=np.int64),
        "estimator__alpha": np.linspace(0,40,100, dtype=np.int64),
        "estimator__lambda": np.linspace(0,3,10, dtype=np.int64),
        "estimator__colsample_bytree": np.linspace(0.2,1,10, dtype=np.int64)
        }

    return param_grid


def compara(iteracoes, modelos):
    
    # Escrita no arquivo
    nome_arquivo = 'compara-xg-rf-bert.txt'
    with open(nome_arquivo, "w") as arquivo:
        pass

    selection = SelectKBest() # pritnar kbest

    samplers = [RandomOverSampler(random_state=42), None]

    splits = ['strat_label', 'strat_partido', 'pred_partido_novo'] # adicionar a logica de separacao para o pred_part

    # dataframe em que sera inserido os dados do modelo testado
    df_resultados = pd.DataFrame(columns=['modelo', 'split', 'comeco_random_search',
                                          'final_random_search', 'qnt_iteracoes',
                                          'melhor_result_randsearch',
                                          'melhores_parametros', 'acuracia',
                                         'class_report'])
    
    for model in modelos:

        for sampler in samplers:

            for split in splits:
    
                param_grid = seleciona_grid(model)
                
                scaler = MaxAbsScaler()
        
                pipeline = Pipeline([
                        ('scaling', scaler), 
                        ('selection', selection),
                        ('ros', sampler),
                        ('estimator', model)
                        ])
        
                
                #  --- Prints das configurações ---
                print(f'Modelo: {model}')
                    
        
                # definicao da randomized search
                random_search = RandomizedSearchCV(pipeline, param_distributions=param_grid,cv=StratifiedKFold(n_splits=5),
                                                    n_iter=iteracoes, n_jobs=2, random_state=42)


                # Random Search
                comeco_random_search = datetime.datetime.now()
                print(f'Começo da Random Search: {comeco_random_search}')
                
                if split == 'strat_label': # estratificacao pela label
                    model_trained = random_search.fit(X_train_strat_label, y_train_strat_label) 
                    
                    final_random_search = datetime.datetime.now()
                    print(f'Final da Random Search: {final_random_search}')
                    
                    y_pred = model_trained.predict(X_test_strat_label) # predicao
                    acc_pred = accuracy_score(y_test_strat_label, y_pred) # acuracia
                    report = classification_report(y_test_strat_label, y_pred) # class report
                    
                elif split == 'strat_partido': # estratificacao pelos partidos 
                    model_trained = random_search.fit(X_train_strat_part, y_train_strat_part)

                    final_random_search = datetime.datetime.now()
                    print(f'Final da Random Search: {final_random_search}')
                    
                    y_pred = model_trained.predict(X_test_strat_part) # predicao
                    acc_pred = accuracy_score(y_test_strat_part, y_pred) # acuracia
                    report = classification_report(y_test_strat_part, y_pred) # class report
                    
                elif split == 'pred_partido_novo': # predicao de partidos nao vistos no teste
                    model_trained = random_search.fit(, )
                    
                    final_random_search = datetime.datetime.now()
                    print(f'Final da Random Search: {final_random_search}')
                    
                    y_pred = model_trained.predict() # predicao
                    acc_pred = accuracy_score(, y_pred) # acuracia
                    report = classification_report(, y_pred) # class report
                    
                
                
                
                score_random_search = model_trained.best_score_
                score_random_search *= 100
                score_random_search = round(score_random_search,2)
                print(f'Melhor resultado na Random Search: {score_random_search}%')
                
                print('Melhores parâmetros encontrados:')
                print(model_trained.best_params_)
                
                    
                acc_pred *= 100
                acc_pred = round(acc_pred,2)
                print(f'Acurácia predita = {acc_pred}%')
        
                print(report)
                        
                
                print('----------------------------------------------')
                
                # Escrita em memória secundária


                # Nova linha que se deseja adicionar
                nova_linha = {'modelo': model, 'split': split,
                              'comeco_random_search': comeco_random_search,
                              'final_random_search': final_random_search, 'qnt_iteracoes': iteracoes,
                              'melhor_result_randsearch': score_random_search,
                              'melhores_parametros': str(model_trained.best_params_),
                              'acuracia': acc_pred, 'class_report': report}
            
                # Cria um novo DataFrame com a nova linha
                nova_linha_resultados = pd.DataFrame([nova_linha])
            
                # Concatena o novo DataFrame com o DataFrame existente
                df_resultados = pd.concat([df_resultados, nova_linha_resultados], ignore_index=True)
    
    df_resultados.to_csv('compara-xg-rf-bert.csv', index=False)
                
                
                

                with open(nome_arquivo, "a") as arquivo:
                    
                    arquivo.write(f'Modelo: {model}\n')
                    #arquivo.write(f'Vetorizador utilizado: {vectorizer}\n')
                    arquivo.write(f'Começo da Random Search: {comeco_random_search}\n')
                    arquivo.write(f'Final da Random Search: {final_random_search}\n')
                    arquivo.write(f'Melhor resultado na Random Search: {score_random_search}\n')
                    arquivo.write('Melhores parâmetros encontrados:\n')
                    arquivo.write(str(model_trained.best_params_))
                    arquivo.write('\n')
                    arquivo.write(f'Acurácia predita = {acc_pred}%\n')
                    arquivo.write(f'Classification report: \n')
                    arquivo.write(report)
                    arquivo.write('----------------------------------------------\n')


df = pd.read_csv('compara-xg-rf-bert.csv')

for index, row in df.iterrows():
    print(f"{row['modelo']}:")
    print(row['parametros'])
    print('\n')


modelos = [XGBClassifier(seed=42),RandomForestClassifier(random_state=42)]

compara(1, modelos)


print(None)
