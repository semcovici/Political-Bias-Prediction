{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce62debc-bf37-4d18-85a9-dbd1069ebb20",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Importação das bibliotecas necessárias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "22df3ca1-3dbe-4119-a257-9e8412799283",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "from sklearn.preprocessing import MinMaxScaler, QuantileTransformer\n",
    "from datetime import datetime\n",
    "from sklearn.feature_selection import SelectPercentile\n",
    "from scipy.stats import uniform\n",
    "\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "#from sklearn.pipeline import Pipeline\n",
    "from imblearn.pipeline import Pipeline\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn import set_config\n",
    "set_config(display='diagram')\n",
    "import datetime\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "726dd049-2914-4e15-aa97-41f875bc5e6d",
   "metadata": {},
   "source": [
    "# Importação dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f094c27-9803-45b7-927f-418b6a45133e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('../dataset/processed/artigos_de_partidos/artigos_partidos.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b4c4834-86cc-42e5-8497-7bd087bf7a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remocao de dados nulos\n",
    "data = data[data['Conteudo'] != '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "48ac9c91-3c32-4064-bb78-d6c6f81324c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remocao de colunas desnecessarias\n",
    "rem_cols = ['URL']\n",
    "data.drop(rem_cols, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0b506f40-5b6f-47c4-9ed9-5def04c2904b",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Partido</th>\n",
       "      <th>Conteudo</th>\n",
       "      <th>Vies</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Novo</td>\n",
       "      <td>Multa imposta ao candidato na condenação foi...</td>\n",
       "      <td>direita</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Novo</td>\n",
       "      <td>Cadastro será usado como identificação junt...</td>\n",
       "      <td>direita</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Novo</td>\n",
       "      <td>A Bancada do NOVO na Câmara considera temerá...</td>\n",
       "      <td>direita</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Novo</td>\n",
       "      <td>Um ambiente com ausência de segurança juríd...</td>\n",
       "      <td>direita</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Novo</td>\n",
       "      <td>Segundo o MP, o estado do RJ sequer utiliza os...</td>\n",
       "      <td>direita</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Partido                                           Conteudo     Vies\n",
       "0    Novo  Multa imposta ao candidato na condenação foi...  direita\n",
       "1    Novo  Cadastro será usado como identificação junt...  direita\n",
       "2    Novo  A Bancada do NOVO na Câmara considera temerá...  direita\n",
       "3    Novo  Um ambiente com ausência de segurança juríd...  direita\n",
       "4    Novo  Segundo o MP, o estado do RJ sequer utiliza os...  direita"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head() # visualização das primeiras 5 linhas do dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f2ef30cb-c985-4221-b0fb-48e617b6732c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# conversao dos rotulos categoricos para numericos\n",
    "data['Vies'] = data['Vies'].map({'direita':2,\n",
    "                                'centro': 1,\n",
    "                                'esquerda': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4910bc1c-f52a-4bae-985f-a5282c1729a3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Partido</th>\n",
       "      <th>Conteudo</th>\n",
       "      <th>Vies</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Novo</td>\n",
       "      <td>Multa imposta ao candidato na condenação foi...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Novo</td>\n",
       "      <td>Cadastro será usado como identificação junt...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Novo</td>\n",
       "      <td>A Bancada do NOVO na Câmara considera temerá...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Novo</td>\n",
       "      <td>Um ambiente com ausência de segurança juríd...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Novo</td>\n",
       "      <td>Segundo o MP, o estado do RJ sequer utiliza os...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Partido                                           Conteudo  Vies\n",
       "0    Novo  Multa imposta ao candidato na condenação foi...     2\n",
       "1    Novo  Cadastro será usado como identificação junt...     2\n",
       "2    Novo  A Bancada do NOVO na Câmara considera temerá...     2\n",
       "3    Novo  Um ambiente com ausência de segurança juríd...     2\n",
       "4    Novo  Segundo o MP, o estado do RJ sequer utiliza os...     2"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "defb5652-63fb-4fb7-b59f-16c9fbe8699a",
   "metadata": {},
   "source": [
    "# Splits que serão avaliados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8c659419-4e04-45cc-88c3-dbbeec61d993",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Partido</th>\n",
       "      <th>Conteudo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Novo</td>\n",
       "      <td>Multa imposta ao candidato na condenação foi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Novo</td>\n",
       "      <td>Cadastro será usado como identificação junt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Novo</td>\n",
       "      <td>A Bancada do NOVO na Câmara considera temerá...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Novo</td>\n",
       "      <td>Um ambiente com ausência de segurança juríd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Novo</td>\n",
       "      <td>Segundo o MP, o estado do RJ sequer utiliza os...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Partido                                           Conteudo\n",
       "0    Novo  Multa imposta ao candidato na condenação foi...\n",
       "1    Novo  Cadastro será usado como identificação junt...\n",
       "2    Novo  A Bancada do NOVO na Câmara considera temerá...\n",
       "3    Novo  Um ambiente com ausência de segurança juríd...\n",
       "4    Novo  Segundo o MP, o estado do RJ sequer utiliza os..."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a seguir os dados serão divididos entre features (X) e label (y)\n",
    "\n",
    "X_columns = [column for column in data.columns if column != 'Vies']\n",
    "X = data[X_columns] # features\n",
    "X.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "56174d98-ac9b-4e9c-a9e1-784e917e8897",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2\n",
       "1    2\n",
       "2    2\n",
       "3    2\n",
       "4    2\n",
       "Name: Vies, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = data['Vies'] # label\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69274658-1e14-4b8c-956f-7ef25ca2e965",
   "metadata": {},
   "source": [
    "## Estratificação por viés"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2843a037-0eae-458f-bca9-296fb683a646",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train_strat_vies, X_test_strat_vies, y_train_strat_vies, y_test_strat_vies = train_test_split(X, y.to_numpy(),\n",
    "                                                                                                test_size=0.2,\n",
    "                                                                                                random_state=42,\n",
    "                                                                                                stratify=y)\n",
    "\n",
    "X_train_strat_vies = X_train_strat_vies.drop('Partido', axis=1).Conteudo # remocao da coluna partido\n",
    "X_test_strat_vies = X_test_strat_vies.drop('Partido', axis=1).Conteudo # remocao da coluna partido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "74c27026-47f0-438f-8457-933e7ab1ec05",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3285     Alagoas – O prefeito de Maceió, JHC (PL-AL), ...\n",
       "5772     Após Indicação e Ofício apresentados pelo ...\n",
       "2306     Brasília – “Você importa. Escolha a vida!”. ...\n",
       "1757     Nota do PCB Santa Catarina sobre a conquista d...\n",
       "690      O NOVO foi fundado em 2011 por pessoas comuns ...\n",
       "                               ...                        \n",
       "3568     Amazonas – A deputada estadual Therezinha Ruiz...\n",
       "4852     Brasília – O Ministério da Educação (MEC) ...\n",
       "6461     O povo paraguaio está se insurgindo contra um...\n",
       "10634    Na CCJ, governistas pedem vista e atrasam apre...\n",
       "10822    PV Pernambuco repudia as ofertas do governo fe...\n",
       "Name: Conteudo, Length: 9370, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_strat_vies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64baa7c6-aa90-4515-be5f-073b56c38f91",
   "metadata": {},
   "source": [
    "## Estratificação por partido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "89e506b6-8cff-4c9d-ab40-a54e75f4e1e6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train_strat_part, X_test_strat_part, y_train_strat_part, y_test_strat_part = train_test_split(X, y.to_numpy(),\n",
    "                                                                                                test_size=0.2,\n",
    "                                                                                                random_state=42,\n",
    "                                                                                                stratify=X['Partido'])\n",
    "\n",
    "X_train_strat_part = X_train_strat_part.drop('Partido', axis=1).Conteudo # remocao da coluna partido\n",
    "X_test_strat_part = X_test_strat_part.drop('Partido', axis=1).Conteudo # remocao da coluna partido"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaac8f73-05b1-4a09-9280-d682f2ef844c",
   "metadata": {},
   "source": [
    "## Teste com partidos fora do treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "16793304-1778-4e45-a7fb-6f4bfdd653c3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "direita = data[data['Vies'] == 2] # selecao apenas dos partidos de direita\n",
    "centro = data[data['Vies'] == 1] # selecao apenas dos partidos de centro\n",
    "esquerda = data[data['Vies'] == 0] # selecao apenas dos partidos de esquerda\n",
    "total = data.shape[0] # quantidade total de linhas no dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b63978e1-b919-46b3-a969-babca8e4226d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Porcentagem dos partidos de direita em relação ao dataset:\n",
      "porcentagem do partido Novo: 10.22%\n",
      "porcentagem do partido PL: 28.90%\n",
      "porcentagem do partido PP: 5.01%\n",
      "porcentagem do partido União Brasil: 2.42%\n"
     ]
    }
   ],
   "source": [
    "print('Porcentagem dos partidos de direita em relação ao dataset:')\n",
    "for part in direita['Partido'].unique():\n",
    "    \n",
    "    qnt_part = direita[direita['Partido'] == part].shape[0]\n",
    "    porc = qnt_part / total * 100\n",
    "    print(f'porcentagem do partido {part}: {porc:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3f81d5fc-5876-4ffc-b570-3d0d1c82ab2a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Porcentagem dos partidos de centro em relação ao dataset:\n",
      "porcentagem do partido PDT: 3.82%\n",
      "porcentagem do partido MDB: 5.13%\n",
      "porcentagem do partido PSB: 15.04%\n",
      "porcentagem do partido PV: 7.41%\n"
     ]
    }
   ],
   "source": [
    "print('Porcentagem dos partidos de centro em relação ao dataset:')\n",
    "for part in centro['Partido'].unique():\n",
    "    \n",
    "    qnt_part = centro[centro['Partido'] == part].shape[0]\n",
    "    porc = qnt_part / total * 100\n",
    "    print(f'porcentagem do partido {part}: {porc:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "56090a2e-c117-46f7-9c7f-cd58dc12c6d8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Porcentagem dos partidos de esquerda em relação ao dataset:\n",
      "porcentagem do partido PCB: 5.27%\n",
      "porcentagem do partido PSOL: 0.13%\n",
      "porcentagem do partido PSTU: 5.35%\n",
      "porcentagem do partido PCDoB: 5.14%\n",
      "porcentagem do partido PT: 5.10%\n",
      "porcentagem do partido Rede: 1.06%\n"
     ]
    }
   ],
   "source": [
    "print('Porcentagem dos partidos de esquerda em relação ao dataset:')\n",
    "for part in esquerda['Partido'].unique():\n",
    "    \n",
    "    qnt_part = esquerda[esquerda['Partido'] == part].shape[0]\n",
    "    porc = qnt_part / total * 100\n",
    "    print(f'porcentagem do partido {part}: {porc:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fd7f7c1-6170-43fb-bf4a-a10a94a9c198",
   "metadata": {},
   "source": [
    "Baseado nas porcentagens acima, o partido de esquerda, centro e direita que foram escolhidos para o conjunto de teste representam, respectivamente 5.53%, 7.35% e 10.34% do dataset. Dessa forma, o conjunto de teste será constituído por 5.53 + 7.35 + 10.34 = 23.22% do dataset original."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "25c3daf4-d8b4-4501-8c71-2a3f03da09ea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "part_teste = ['PSTU', 'PV', 'Novo'] # partidos do conjunto de teste\n",
    "\n",
    "test = data[data['Partido'].isin(part_teste)].copy() # selecao dos dados de teste\n",
    "test.drop('Partido', axis=1, inplace=True) # remocao da coluna partido\n",
    "\n",
    "train = data[~data['Partido'].isin(part_teste)].copy() # selecao dos dados de treino\n",
    "train.drop('Partido', axis=1, inplace=True) # remocao da coluna partido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bb6fe31d-ab8a-4564-8fb0-4a82df55852a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train_part_novos = train.drop('Vies', axis=1).Conteudo # X_train\n",
    "y_train_part_novos = train['Vies'].to_numpy() # y_train\n",
    "\n",
    "X_test_part_novos = test.drop('Vies', axis=1).Conteudo # X_test\n",
    "y_test_part_novos = test['Vies'].to_numpy() # y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "324d4728-aaa3-4fed-8495-6a2feacba516",
   "metadata": {},
   "source": [
    "# Seleção do modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "64ad7bae-85b7-4626-9b4c-6ca6c59cf22b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Defina a função para calcular a porcentagem com base no número total de features\n",
    "def percentage_features(percentage, total_features):\n",
    "    return int(np.ceil(percentage * total_features / 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "90e350f1-7b3f-45ac-a098-58be22ede652",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seleciona_grid_tfidf(model, split):\n",
    "\n",
    "    param_grid = None\n",
    "    \n",
    "    if split == 'strat_vies':\n",
    "        X_train = X_train_strat_vies.copy()\n",
    "        \n",
    "    elif split == 'strat_partido':\n",
    "        X_train = X_train_strat_part.copy()\n",
    "        \n",
    "    elif split == 'pred_partido_novo':\n",
    "        X_train = X_train_part_novos.copy()\n",
    "        \n",
    "\n",
    "    if isinstance(model, MultinomialNB):\n",
    "            param_grid = {\n",
    "            \"vect__ngram_range\": [(1,2), (1,3), (1,4), (2,3), (2,4), (3,4)],\n",
    "            \"vect__analyzer\": ['word','char'],\n",
    "            \"selection__percentile\": [33, 66, 100],\n",
    "            \"estimator__alpha\": [50, 15, 10, 5, 1, 0.5, 0.3, 0.1, 0.05, 0.03, 0.02, 0.01,  0.001],\n",
    "            \"estimator__fit_prior\": [True, False],\n",
    "            }\n",
    "\n",
    "    if isinstance(model, SVC):\n",
    "            param_grid = {\n",
    "            \"vect__ngram_range\": [(1,2), (1,3), (1,4), (2,3), (2,4), (3,4)],\n",
    "            \"vect__analyzer\": ['word','char'],\n",
    "            \"selection__k\": [200,400,600,800,1024],\n",
    "            \"estimator__gamma\": [1, 0.1, 0.01, 0.001],\n",
    "            \"estimator__kernel\": ['linear', 'sigmoid'],\n",
    "            \"estimator__C\": [0.1, 1, 10, 100]\n",
    "            }\n",
    "            \n",
    "    if isinstance(model, LinearSVC):\n",
    "        \n",
    "            param_grid = {\n",
    "            \"vect__ngram_range\": [(1,2), (1,3), (1,4), (2,3), (2,4), (3,4)],\n",
    "            \"vect__analyzer\": ['word','char'],\n",
    "            \"selection__percentile\": [33, 66, 100],\n",
    "            \"estimator__dual\": [True, False],\n",
    "            \"estimator__penalty\": ['l1', 'l2'],\n",
    "            \"estimator__fit_intercept\": [True, False],\n",
    "            \"estimator__C\": uniform(loc=0, scale=4)\n",
    "            }\n",
    "\n",
    "\n",
    "    if isinstance(model, RandomForestClassifier):\n",
    "        param_grid = {\n",
    "        \"vect__ngram_range\": [(1,2), (1,3), (1,4), (2,3), (2,4), (3,4)],\n",
    "        \"vect__analyzer\": ['word','char'],\n",
    "        \"selection__k\": [200,400,600,800,1024],\n",
    "        \"estimator__n_estimators\": np.arange(20,150), \n",
    "        \"estimator__max_features\": ['log2', 'sqrt'],\n",
    "        \"estimator__max_depth\": np.arange(10,110),\n",
    "        \"estimator__min_samples_split\": np.arange(2,11),\n",
    "        \"estimator__min_samples_leaf\": np.arange(1,5),\n",
    "        \"estimator__bootstrap\": [True, False]\n",
    "        }\n",
    "        \n",
    "    if isinstance(model, XGBClassifier):\n",
    "        param_grid = {\n",
    "        \"vect__ngram_range\": [(1,2), (1,3), (1,4), (2,3), (2,4), (3,4)],\n",
    "        \"vect__analyzer\": ['word','char'],\n",
    "        \"selection__percentile\": [33, 66, 100],\n",
    "        \"estimator__gamma\": np.linspace(0,9,100, dtype=np.int64),\n",
    "        \"estimator__alpha\": np.linspace(0,40,100, dtype=np.int64),\n",
    "        \"estimator__lambda\": np.linspace(0,3,10, dtype=np.int64),\n",
    "        \"estimator__colsample_bytree\": np.linspace(0.2,1,10, dtype=np.int64)\n",
    "        }\n",
    "\n",
    "    return param_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f7bf1992-6267-4e40-a4f6-2c352d7e90ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_e_avalia(split, random_search):\n",
    "    \n",
    "    inicio_random_search = datetime.datetime.now()\n",
    "    \n",
    "    if split == 'strat_vies': # estratificacao pela label\n",
    "        model_trained = random_search.fit(X_train_strat_vies, y_train_strat_vies) # fit\n",
    "\n",
    "        fim_random_search = datetime.datetime.now()\n",
    "        tempo_total = fim_random_search - inicio_random_search\n",
    "        print(f'Duração da Random Search: {tempo_total}')\n",
    "\n",
    "        y_pred = model_trained.predict(X_test_strat_vies) # predicao\n",
    "        f1 = f1_score(y_test_strat_vies, y_pred, average= 'macro') # f1\n",
    "        report = classification_report(y_test_strat_vies, y_pred, output_dict=True) # class report\n",
    "\n",
    "    elif split == 'strat_partido': # estratificacao pelos partidos \n",
    "        model_trained = random_search.fit(X_train_strat_part, y_train_strat_part) # fit\n",
    "\n",
    "        fim_random_search = datetime.datetime.now()\n",
    "        tempo_total = fim_random_search - inicio_random_search\n",
    "        print(f'Duração da Random Search: {tempo_total}')\n",
    "\n",
    "        y_pred = model_trained.predict(X_test_strat_part) # predicao\n",
    "        f1 = f1_score(y_test_strat_part, y_pred, average= 'macro') # f1\n",
    "        report = classification_report(y_test_strat_part, y_pred, output_dict=True) # class report\n",
    "\n",
    "    elif split == 'pred_partido_novo': # predicao de partidos nao vistos no teste\n",
    "        model_trained = random_search.fit(X_train_part_novos, y_train_part_novos) # fit\n",
    "\n",
    "        fim_random_search = datetime.datetime.now()\n",
    "        tempo_total = fim_random_search - inicio_random_search\n",
    "        print(f'Duração da Random Search: {tempo_total}')\n",
    "\n",
    "        y_pred = model_trained.predict(X_test_part_novos) # predicao\n",
    "        f1 = f1_score(y_test_part_novos, y_pred, average= 'macro') # f1\n",
    "        report = classification_report(y_test_part_novos, y_pred, output_dict=True) # class report\n",
    "    \n",
    "    return model_trained, tempo_total, f1, report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "31550b8e-4684-401b-b4ac-e1cb5f04ce1b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compara_tfidf(iteracoes, modelos, nome_arquivo):\n",
    "\n",
    "    # seletor de features\n",
    "    selection = SelectPercentile()\n",
    "\n",
    "    # possibilidades de oversampling ou nao\n",
    "    samplers = [RandomOverSampler(random_state=42), None]\n",
    "\n",
    "    # diferentes splits que serao avaliador\n",
    "    splits = ['strat_vies', 'strat_partido', 'pred_partido_novo'] \n",
    "    \n",
    "    # vetorizador do texto\n",
    "    vectorizer = TfidfVectorizer()\n",
    "\n",
    "    # dataframe em que sera inserido os dados do modelo testado \n",
    "    df_resultados = pd.DataFrame(columns=['modelo', 'split', 'sampler', 'scaling',\n",
    "                                          'duracao_random_search','qnt_iteracoes',\n",
    "                                          'f1_randsearch',\n",
    "                                          'melhores_parametros', 'f1_pred',\n",
    "                                          'class_report'])\n",
    "    \n",
    "    for model in modelos:\n",
    "\n",
    "        for sampler in samplers:\n",
    "\n",
    "            for split in splits:\n",
    "                \n",
    "                # seleciona grid de parametros\n",
    "                param_grid = seleciona_grid_tfidf(model, split)\n",
    "                \n",
    "                # seleciona scaler\n",
    "                if isinstance(model, MultinomialNB):\n",
    "                    scaler = MinMaxScaler() # normaliza e garante valores nao negativos\n",
    "                else:\n",
    "                    scaler = MaxAbsScaler()\n",
    "        \n",
    "                # define o pipeline\n",
    "                pipeline = Pipeline([\n",
    "                        ('vect', vectorizer), \n",
    "                        ('scaling', scaler), \n",
    "                        ('selection', selection),\n",
    "                        ('ros', sampler),\n",
    "                        ('estimator', model)\n",
    "                        ])\n",
    "        \n",
    "                \n",
    "                #  --- Prints das configurações dessa iteracao ---\n",
    "                print(f'Modelo: {model}')\n",
    "                print(f'Split: {split}')\n",
    "                print(f'Scaler: {scaler}')\n",
    "                print(f'Sampler: {sampler}')\n",
    "                    \n",
    "        \n",
    "                # definicao da randomized search\n",
    "                random_search = RandomizedSearchCV(pipeline, param_distributions=param_grid,cv=StratifiedKFold(n_splits=5),\n",
    "                                                    n_iter=iteracoes, n_jobs=1, random_state=42, scoring='f1_macro')\n",
    "\n",
    "\n",
    "                # fit e avaliacao pela randomized search\n",
    "                model_trained, tempo_total, f1, report = fit_e_avalia(split, random_search)\n",
    "                \n",
    "                print('---')\n",
    "                resultados = model_trained.cv_results_\n",
    "\n",
    "                for params, score in zip(resultados['params'], resultados['mean_test_score']):\n",
    "                    print(f\"Parâmetros: {params}, Score: {score}\")\n",
    "                print('---')\n",
    "                    \n",
    "                # melhor metrica na random search\n",
    "                score_random_search = model_trained.best_score_\n",
    "                score_random_search *= 100\n",
    "                score_random_search = round(score_random_search,2)\n",
    "                print(f'Melhor F1 na Random Search: {score_random_search}%')\n",
    "                \n",
    "                # melhores parametros encontrados\n",
    "                print('Melhores parâmetros encontrados:')\n",
    "                print(model_trained.best_params_)\n",
    "\n",
    "                \n",
    "                # acuracia da predicao\n",
    "                f1 *= 100\n",
    "                f1 = round(f1,2)\n",
    "                print(f'F1 macro = {f1}%')\n",
    "        \n",
    "                # classification report\n",
    "                print(report)\n",
    "                        \n",
    "                \n",
    "                print('----------------------------------------------')\n",
    "                \n",
    "                # --- Escrita em memória secundária ---\n",
    "\n",
    "                # Nova linha que sera adicionada\n",
    "                nova_linha = {'modelo': model, 'split': split,\n",
    "                              'sampler': str(sampler), 'scaling': scaler,\n",
    "                              'duracao_random_search': tempo_total,\n",
    "                              'qnt_iteracoes': iteracoes,\n",
    "                              'f1_randsearch': f'{score_random_search}%',\n",
    "                              'melhores_parametros': str(model_trained.best_params_),\n",
    "                              'f1_pred': f'{f1}%', 'class_report': report}\n",
    "            \n",
    "                # Cria um novo DataFrame com a nova linha\n",
    "                nova_linha_resultados = pd.DataFrame([nova_linha])\n",
    "            \n",
    "                # Concatena o novo DataFrame com o DataFrame existente\n",
    "                df_resultados = pd.concat([df_resultados, nova_linha_resultados], ignore_index=True)\n",
    "    \n",
    "    \n",
    "    print('Fim dos testes')\n",
    "    \n",
    "    # salvamento do dataframe de resultados apos os testes terem terminado\n",
    "    df_resultados.to_csv(nome_arquivo, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "88c646da-ded2-42f1-91b6-6ecf392bddbf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo: MultinomialNB()\n",
      "Split: strat_vies\n",
      "Scaler: MinMaxScaler()\n",
      "Sampler: RandomOverSampler(random_state=42)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "\nAll the 5 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n5 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/home/yagoth/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/home/yagoth/anaconda3/lib/python3.11/site-packages/imblearn/pipeline.py\", line 293, in fit\n    Xt, yt = self._fit(X, y, **fit_params_steps)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/yagoth/anaconda3/lib/python3.11/site-packages/imblearn/pipeline.py\", line 240, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n                            ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/yagoth/anaconda3/lib/python3.11/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/yagoth/anaconda3/lib/python3.11/site-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n    res = transformer.fit_transform(X, y, **fit_params)\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/yagoth/anaconda3/lib/python3.11/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/yagoth/anaconda3/lib/python3.11/site-packages/sklearn/base.py\", line 881, in fit_transform\n    return self.fit(X, y, **fit_params).transform(X)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/yagoth/anaconda3/lib/python3.11/site-packages/sklearn/preprocessing/_data.py\", line 427, in fit\n    return self.partial_fit(X, y)\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/yagoth/anaconda3/lib/python3.11/site-packages/sklearn/preprocessing/_data.py\", line 460, in partial_fit\n    raise TypeError(\nTypeError: MinMaxScaler does not support sparse input. Consider using MaxAbsScaler instead.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m modelos \u001b[38;5;241m=\u001b[39m [MultinomialNB()]\n\u001b[0;32m----> 3\u001b[0m compara_tfidf(\u001b[38;5;241m1\u001b[39m, modelos, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcompara-nb-tfidf-222.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[22], line 60\u001b[0m, in \u001b[0;36mcompara_tfidf\u001b[0;34m(iteracoes, modelos, nome_arquivo)\u001b[0m\n\u001b[1;32m     55\u001b[0m random_search \u001b[38;5;241m=\u001b[39m RandomizedSearchCV(pipeline, param_distributions\u001b[38;5;241m=\u001b[39mparam_grid,cv\u001b[38;5;241m=\u001b[39mStratifiedKFold(n_splits\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m),\n\u001b[1;32m     56\u001b[0m                                     n_iter\u001b[38;5;241m=\u001b[39miteracoes, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m, scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mf1_macro\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     59\u001b[0m \u001b[38;5;66;03m# fit e avaliacao pela randomized search\u001b[39;00m\n\u001b[0;32m---> 60\u001b[0m model_trained, tempo_total, f1, report \u001b[38;5;241m=\u001b[39m fit_e_avalia(split, random_search)\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m---\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     63\u001b[0m resultados \u001b[38;5;241m=\u001b[39m model_trained\u001b[38;5;241m.\u001b[39mcv_results_\n",
      "Cell \u001b[0;32mIn[21], line 6\u001b[0m, in \u001b[0;36mfit_e_avalia\u001b[0;34m(split, random_search)\u001b[0m\n\u001b[1;32m      3\u001b[0m inicio_random_search \u001b[38;5;241m=\u001b[39m datetime\u001b[38;5;241m.\u001b[39mdatetime\u001b[38;5;241m.\u001b[39mnow()\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m split \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstrat_vies\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;66;03m# estratificacao pela label\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m     model_trained \u001b[38;5;241m=\u001b[39m random_search\u001b[38;5;241m.\u001b[39mfit(X_train_strat_vies, y_train_strat_vies) \u001b[38;5;66;03m# fit\u001b[39;00m\n\u001b[1;32m      8\u001b[0m     fim_random_search \u001b[38;5;241m=\u001b[39m datetime\u001b[38;5;241m.\u001b[39mdatetime\u001b[38;5;241m.\u001b[39mnow()\n\u001b[1;32m      9\u001b[0m     tempo_total \u001b[38;5;241m=\u001b[39m fim_random_search \u001b[38;5;241m-\u001b[39m inicio_random_search\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_search.py:874\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    868\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[1;32m    869\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m    870\u001b[0m     )\n\u001b[1;32m    872\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[0;32m--> 874\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_search(evaluate_candidates)\n\u001b[1;32m    876\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m    877\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m    878\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_search.py:1768\u001b[0m, in \u001b[0;36mRandomizedSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1766\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1767\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search n_iter candidates from param_distributions\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1768\u001b[0m     evaluate_candidates(\n\u001b[1;32m   1769\u001b[0m         ParameterSampler(\n\u001b[1;32m   1770\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparam_distributions, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_iter, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrandom_state\n\u001b[1;32m   1771\u001b[0m         )\n\u001b[1;32m   1772\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_search.py:851\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    844\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m!=\u001b[39m n_candidates \u001b[38;5;241m*\u001b[39m n_splits:\n\u001b[1;32m    845\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    846\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcv.split and cv.get_n_splits returned \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    847\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minconsistent results. Expected \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    848\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msplits, got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(n_splits, \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m n_candidates)\n\u001b[1;32m    849\u001b[0m     )\n\u001b[0;32m--> 851\u001b[0m _warn_or_raise_about_fit_failures(out, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39merror_score)\n\u001b[1;32m    853\u001b[0m \u001b[38;5;66;03m# For callable self.scoring, the return type is only know after\u001b[39;00m\n\u001b[1;32m    854\u001b[0m \u001b[38;5;66;03m# calling. If the return type is a dictionary, the error scores\u001b[39;00m\n\u001b[1;32m    855\u001b[0m \u001b[38;5;66;03m# can now be inserted with the correct key. The type checking\u001b[39;00m\n\u001b[1;32m    856\u001b[0m \u001b[38;5;66;03m# of out will be done in `_insert_error_scores`.\u001b[39;00m\n\u001b[1;32m    857\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscoring):\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:367\u001b[0m, in \u001b[0;36m_warn_or_raise_about_fit_failures\u001b[0;34m(results, error_score)\u001b[0m\n\u001b[1;32m    360\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m num_failed_fits \u001b[38;5;241m==\u001b[39m num_fits:\n\u001b[1;32m    361\u001b[0m     all_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    362\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mAll the \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    363\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIt is very likely that your model is misconfigured.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    364\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou can try to debug the error by setting error_score=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    365\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    366\u001b[0m     )\n\u001b[0;32m--> 367\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(all_fits_failed_message)\n\u001b[1;32m    369\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    370\u001b[0m     some_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    371\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mnum_failed_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed out of a total of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    372\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe score on these train-test partitions for these parameters\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    376\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    377\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: \nAll the 5 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n5 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/home/yagoth/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/home/yagoth/anaconda3/lib/python3.11/site-packages/imblearn/pipeline.py\", line 293, in fit\n    Xt, yt = self._fit(X, y, **fit_params_steps)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/yagoth/anaconda3/lib/python3.11/site-packages/imblearn/pipeline.py\", line 240, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n                            ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/yagoth/anaconda3/lib/python3.11/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/yagoth/anaconda3/lib/python3.11/site-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n    res = transformer.fit_transform(X, y, **fit_params)\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/yagoth/anaconda3/lib/python3.11/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/yagoth/anaconda3/lib/python3.11/site-packages/sklearn/base.py\", line 881, in fit_transform\n    return self.fit(X, y, **fit_params).transform(X)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/yagoth/anaconda3/lib/python3.11/site-packages/sklearn/preprocessing/_data.py\", line 427, in fit\n    return self.partial_fit(X, y)\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/yagoth/anaconda3/lib/python3.11/site-packages/sklearn/preprocessing/_data.py\", line 460, in partial_fit\n    raise TypeError(\nTypeError: MinMaxScaler does not support sparse input. Consider using MaxAbsScaler instead.\n"
     ]
    }
   ],
   "source": [
    "modelos = [MultinomialNB()]\n",
    "\n",
    "compara_tfidf(1, modelos, 'compara-nb-tfidf-222.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baaeef94-87bc-4056-b02a-99b2e264989e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
