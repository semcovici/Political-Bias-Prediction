{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERT Embeddings on SMS Spam Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-30 02:08:59.109618: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-11-30 02:08:59.109652: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-11-30 02:08:59.110571: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-11-30 02:08:59.116434: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-30 02:09:00.022442: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import tensorflow_text as text\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF version:  2.15.0\n",
      "Hub version:  0.15.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow_hub as hub\n",
    "import tensorflow as tf\n",
    "from bert.tokenization import FullTokenizer\n",
    "from tensorflow.keras.models import Model\n",
    "print(\"TF version: \", tf.__version__)\n",
    "print(\"Hub version: \", hub.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "max_seq_length = 256  # Your choice here.\n",
    "\n",
    "input_word_ids = tf.keras.layers.Input(shape=(max_seq_length,), dtype=tf.int32, name=\"input_word_ids\")\n",
    "input_mask = tf.keras.layers.Input(shape=(max_seq_length,), dtype=tf.int32, name=\"input_mask\")\n",
    "segment_ids = tf.keras.layers.Input(shape=(max_seq_length,), dtype=tf.int32, name=\"segment_ids\")\n",
    "\n",
    "# Load BERT model with the correct input signature\n",
    "bert_url = \"https://www.kaggle.com/models/tensorflow/bert/frameworks/TensorFlow2/variations/multi-cased-preprocess/versions/3\"  # Adjust the URL to the specific BERT model you want\n",
    "bert_layer = hub.KerasLayer(bert_url, trainable=True)\n",
    "\n",
    "# Ensure the BERT layer has the correct input signature\n",
    "bert_layer_resized = hub.KerasLayer(\n",
    "    \"https://www.kaggle.com/models/tensorflow/bert/frameworks/TensorFlow2/variations/multi-cased-preprocess/versions/3\",\n",
    "    trainable=True,\n",
    "    input_shape=[max_seq_length],\n",
    "    dtype=tf.int32,\n",
    ")\n",
    "\n",
    "pooled_output, sequence_output = bert_layer_resized([input_word_ids, input_mask, segment_ids])\n",
    "\n",
    "model = Model(inputs=[input_word_ids, input_mask, segment_ids], outputs=[pooled_output, sequence_output])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "You are passing KerasTensor(type_spec=TensorSpec(shape=(None, 256), dtype=tf.int32, name='input_word_ids'), name='input_word_ids', description=\"created by layer 'input_word_ids'\"), an intermediate Keras symbolic input/output, to a TF API that does not allow registering custom dispatchers, such as `tf.cond`, `tf.function`, gradient tapes, or `tf.map_fn`. Keras Functional model construction only supports TF API calls that *do* support dispatching, such as `tf.math.add` or `tf.reshape`. Other APIs cannot be called directly on symbolic Kerasinputs/outputs. You can work around this limitation by putting the operation in a custom Keras layer `call` and calling that layer on this symbolic input/output.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/semcovici/projetos_pesquisa/Political-Bias-Prediction/src/classificacao/bert-lstm.ipynb Cell 4\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/semcovici/projetos_pesquisa/Political-Bias-Prediction/src/classificacao/bert-lstm.ipynb#X41sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39m#bert_layer = hub.KerasLayer(\"https://www.kaggle.com/models/tensorflow/bert/frameworks/TensorFlow2/variations/multi-cased-preprocess/versions/3\",trainable=True)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/semcovici/projetos_pesquisa/Political-Bias-Prediction/src/classificacao/bert-lstm.ipynb#X41sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m bert_layer \u001b[39m=\u001b[39m hub\u001b[39m.\u001b[39mload(\u001b[39m\"\u001b[39m\u001b[39mhttps://www.kaggle.com/models/tensorflow/bert/frameworks/TensorFlow2/variations/multi-cased-preprocess/versions/3\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/semcovici/projetos_pesquisa/Political-Bias-Prediction/src/classificacao/bert-lstm.ipynb#X41sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m pooled_output, sequence_output \u001b[39m=\u001b[39m bert_layer(input_word_ids, input_mask, segment_ids)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/semcovici/projetos_pesquisa/Political-Bias-Prediction/src/classificacao/bert-lstm.ipynb#X41sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m model \u001b[39m=\u001b[39m Model(inputs\u001b[39m=\u001b[39m[input_word_ids, input_mask, segment_ids], outputs\u001b[39m=\u001b[39m[pooled_output, sequence_output])\n",
      "File \u001b[0;32m~/projetos_pesquisa/Political-Bias-Prediction/.venv/lib/python3.10/site-packages/tensorflow/python/saved_model/load.py:816\u001b[0m, in \u001b[0;36m_call_attribute\u001b[0;34m(instance, *args, **kwargs)\u001b[0m\n\u001b[1;32m    815\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_call_attribute\u001b[39m(instance, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 816\u001b[0m   \u001b[39mreturn\u001b[39;00m instance\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/projetos_pesquisa/Political-Bias-Prediction/.venv/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m--> 153\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    154\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/projetos_pesquisa/Political-Bias-Prediction/.venv/lib/python3.10/site-packages/tensorflow/core/function/polymorphism/function_type.py:583\u001b[0m, in \u001b[0;36mcanonicalize_to_monomorphic\u001b[0;34m(args, kwargs, default_values, capture_types, polymorphic_type)\u001b[0m\n\u001b[1;32m    577\u001b[0m       parameters\u001b[39m.\u001b[39mappend(\n\u001b[1;32m    578\u001b[0m           _make_validated_mono_param(kwarg_name, arg[kwarg_name],\n\u001b[1;32m    579\u001b[0m                                      Parameter\u001b[39m.\u001b[39mKEYWORD_ONLY, type_context,\n\u001b[1;32m    580\u001b[0m                                      poly_parameter\u001b[39m.\u001b[39mtype_constraint))\n\u001b[1;32m    581\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    582\u001b[0m     parameters\u001b[39m.\u001b[39mappend(\n\u001b[0;32m--> 583\u001b[0m         _make_validated_mono_param(name, arg, poly_parameter\u001b[39m.\u001b[39;49mkind,\n\u001b[1;32m    584\u001b[0m                                    type_context,\n\u001b[1;32m    585\u001b[0m                                    poly_parameter\u001b[39m.\u001b[39;49mtype_constraint))\n\u001b[1;32m    587\u001b[0m \u001b[39mreturn\u001b[39;00m FunctionType(parameters, capture_types), type_context\n",
      "File \u001b[0;32m~/projetos_pesquisa/Political-Bias-Prediction/.venv/lib/python3.10/site-packages/tensorflow/core/function/polymorphism/function_type.py:522\u001b[0m, in \u001b[0;36m_make_validated_mono_param\u001b[0;34m(name, value, kind, type_context, poly_type)\u001b[0m\n\u001b[1;32m    518\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_make_validated_mono_param\u001b[39m(\n\u001b[1;32m    519\u001b[0m     name, value, kind, type_context, poly_type\n\u001b[1;32m    520\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Parameter:\n\u001b[1;32m    521\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"Generates and validates a parameter for Monomorphic FunctionType.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 522\u001b[0m   mono_type \u001b[39m=\u001b[39m trace_type\u001b[39m.\u001b[39;49mfrom_value(value, type_context)\n\u001b[1;32m    524\u001b[0m   \u001b[39mif\u001b[39;00m poly_type \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m mono_type\u001b[39m.\u001b[39mis_subtype_of(poly_type):\n\u001b[1;32m    525\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mParameter `\u001b[39m\u001b[39m{\u001b[39;00mname\u001b[39m}\u001b[39;00m\u001b[39m` was expected to be of type \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    526\u001b[0m                     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mpoly_type\u001b[39m}\u001b[39;00m\u001b[39m but is \u001b[39m\u001b[39m{\u001b[39;00mmono_type\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/projetos_pesquisa/Political-Bias-Prediction/.venv/lib/python3.10/site-packages/tensorflow/core/function/trace_type/trace_type_builder.py:185\u001b[0m, in \u001b[0;36mfrom_value\u001b[0;34m(value, context)\u001b[0m\n\u001b[1;32m    178\u001b[0m   \u001b[39mreturn\u001b[39;00m default_types\u001b[39m.\u001b[39mAttrs\u001b[39m.\u001b[39mfrom_type_and_attributes(\n\u001b[1;32m    179\u001b[0m       \u001b[39mtype\u001b[39m(value),\n\u001b[1;32m    180\u001b[0m       \u001b[39mtuple\u001b[39m(\n\u001b[1;32m    181\u001b[0m           from_value(\u001b[39mgetattr\u001b[39m(value, a\u001b[39m.\u001b[39mname), context)\n\u001b[1;32m    182\u001b[0m           \u001b[39mfor\u001b[39;00m a \u001b[39min\u001b[39;00m value\u001b[39m.\u001b[39m__attrs_attrs__))\n\u001b[1;32m    184\u001b[0m \u001b[39mif\u001b[39;00m util\u001b[39m.\u001b[39mis_np_ndarray(value):\n\u001b[0;32m--> 185\u001b[0m   ndarray \u001b[39m=\u001b[39m value\u001b[39m.\u001b[39;49m__array__()\n\u001b[1;32m    186\u001b[0m   \u001b[39mreturn\u001b[39;00m default_types\u001b[39m.\u001b[39mTENSOR(ndarray\u001b[39m.\u001b[39mshape, ndarray\u001b[39m.\u001b[39mdtype)\n\u001b[1;32m    188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(value, custom_nest_protocol\u001b[39m.\u001b[39mCustomNestProtocol):\n",
      "File \u001b[0;32m~/projetos_pesquisa/Political-Bias-Prediction/.venv/lib/python3.10/site-packages/keras/src/engine/keras_tensor.py:285\u001b[0m, in \u001b[0;36mKerasTensor.__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__array__\u001b[39m(\u001b[39mself\u001b[39m, dtype\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m--> 285\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[1;32m    286\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mYou are passing \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m, an intermediate Keras symbolic \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    287\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39minput/output, to a TF API that does not allow registering custom \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    288\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mdispatchers, such as `tf.cond`, `tf.function`, gradient tapes, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    289\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mor `tf.map_fn`. Keras Functional model construction only supports \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    290\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mTF API calls that *do* support dispatching, such as `tf.math.add` \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    291\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mor `tf.reshape`. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    292\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mOther APIs cannot be called directly on symbolic Keras\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    293\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39minputs/outputs. You can work around \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    294\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mthis limitation by putting the operation in a custom Keras layer \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    295\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m`call` and calling that layer \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    296\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mon this symbolic input/output.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    297\u001b[0m     )\n",
      "\u001b[0;31mTypeError\u001b[0m: You are passing KerasTensor(type_spec=TensorSpec(shape=(None, 256), dtype=tf.int32, name='input_word_ids'), name='input_word_ids', description=\"created by layer 'input_word_ids'\"), an intermediate Keras symbolic input/output, to a TF API that does not allow registering custom dispatchers, such as `tf.cond`, `tf.function`, gradient tapes, or `tf.map_fn`. Keras Functional model construction only supports TF API calls that *do* support dispatching, such as `tf.math.add` or `tf.reshape`. Other APIs cannot be called directly on symbolic Kerasinputs/outputs. You can work around this limitation by putting the operation in a custom Keras layer `call` and calling that layer on this symbolic input/output."
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "max_seq_length = 256  # Your choice here.\n",
    "input_word_ids = tf.keras.layers.Input(shape=(max_seq_length,), dtype=tf.int32,\n",
    "                                       name=\"input_word_ids\")\n",
    "input_mask = tf.keras.layers.Input(shape=(max_seq_length,), dtype=tf.int32,\n",
    "                                   name=\"input_mask\")\n",
    "segment_ids = tf.keras.layers.Input(shape=(max_seq_length,), dtype=tf.int32,\n",
    "                                    name=\"segment_ids\")\n",
    "bert_layer = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/1\",\n",
    "                            trainable=True)\n",
    "pooled_output, sequence_output = bert_layer([input_word_ids, input_mask, segment_ids])\n",
    "\n",
    "model = Model(inputs=[input_word_ids, input_mask, segment_ids], outputs=[pooled_output, sequence_output])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_masks(tokens, max_seq_length):\n",
    "    \"\"\"Mask for padding\"\"\"\n",
    "    if len(tokens)>max_seq_length:\n",
    "        raise IndexError(\"Token length more than max seq length!\")\n",
    "    return [1]*len(tokens) + [0] * (max_seq_length - len(tokens))\n",
    "\n",
    "\n",
    "def get_segments(tokens, max_seq_length):\n",
    "    \"\"\"Segments: 0 for the first sequence, 1 for the second\"\"\"\n",
    "    if len(tokens)>max_seq_length:\n",
    "        raise IndexError(\"Token length more than max seq length!\")\n",
    "    segments = []\n",
    "    current_segment_id = 0\n",
    "    for token in tokens:\n",
    "        segments.append(current_segment_id)\n",
    "        if token == \"[SEP]\":\n",
    "            current_segment_id = 1\n",
    "    return segments + [0] * (max_seq_length - len(tokens))\n",
    "\n",
    "\n",
    "def get_ids(tokens, tokenizer, max_seq_length):\n",
    "    \"\"\"Token ids from Tokenizer vocab\"\"\"\n",
    "    token_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "    input_ids = token_ids + [0] * (max_seq_length-len(token_ids))\n",
    "    return input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_file = bert_layer.resolved_object.vocab_file.asset_path.numpy()\n",
    "do_lower_case = bert_layer.resolved_object.do_lower_case.numpy()\n",
    "tokenizer = FullTokenizer(vocab_file, do_lower_case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ids_masks_segmenets(sentence):\n",
    "    stokens = tokenizer.tokenize(sentence)\n",
    "    stokens = [\"[CLS]\"] + stokens + [\"[SEP]\"]\n",
    "    input_ids = get_ids(stokens, tokenizer, max_seq_length)\n",
    "    input_masks = get_masks(stokens, max_seq_length)\n",
    "    input_segments = get_segments(stokens, max_seq_length)\n",
    "    return input_ids, input_masks, input_segments\n",
    "\n",
    "\n",
    "def build_ids_masks_segments(sentences):\n",
    "    input_ids_ = []\n",
    "    input_masks_ = []\n",
    "    input_segments_ = []\n",
    "    for s in sentences:\n",
    "        input_ids, input_masks, input_segments = get_ids_masks_segmenets(s)\n",
    "        input_ids_.append(input_ids)\n",
    "        input_masks_.append(input_masks)\n",
    "        input_segments_.append(input_segments)\n",
    "    return input_ids_, input_masks_, input_segments_\n",
    "\n",
    "def get_embeddings(sentences):\n",
    "    input_ids, input_masks, input_segments = build_ids_masks_segments(sentences)\n",
    "    pool_embs, all_embs = model.predict([input_ids,input_masks,input_segments])\n",
    "    return all_embs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(get_embeddings([\"hey\", \"yay\"]).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/SMSSpamCollection', sep='\\t', names=['label', 'data'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['data']\n",
    "X_train = X[0:int(X.shape[0]*.6)]\n",
    "X_val = X[int(X.shape[0]*.6):int(X.shape[0]*.75)]\n",
    "X_test = X[int(X.shape[0]*.75):]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = get_embeddings(X_train.values)\n",
    "X_val = get_embeddings(X_val.values)\n",
    "X_test = get_embeddings(X_test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['label']\n",
    "y_train = y[0:int(y.shape[0]*.6)]\n",
    "y_val = y[int(y.shape[0]*.6):int(y.shape[0]*.75)]\n",
    "y_test = y[int(y.shape[0]*.75):]\n",
    "\n",
    "print(y_train.value_counts())\n",
    "print(y_val.value_counts())\n",
    "print(y_test.value_counts())\n",
    "\n",
    "HAM = 0\n",
    "SPAM = 1\n",
    "\n",
    "y_train = np.array(list(map(lambda x: HAM if x == 'ham' else SPAM, y_train)))\n",
    "y_val = np.array(list(map(lambda x: HAM if x == 'ham' else SPAM, y_val)))\n",
    "y_test = np.array(list(map(lambda x: HAM if x == 'ham' else SPAM, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(X_test.shape)\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.LSTM(256, input_shape=(X_test.shape[1], X_test.shape[2])),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=tf.keras.optimizers.Adam(2e-5),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(x=X_train, y=y_train, epochs=10,\n",
    "                    validation_data=(X_val, y_val),\n",
    "                    shuffle=True,\n",
    "                    validation_steps=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "training_loss = history.history['loss']\n",
    "test_loss = history.history['val_loss']\n",
    "epoch_count = range(1, len(training_loss) + 1)\n",
    "\n",
    "plt.plot(epoch_count, training_loss, 'r--')\n",
    "plt.plot(epoch_count, test_loss, 'b-')\n",
    "plt.legend(['Training Loss', 'Test Loss'])\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results = model.test_on_batch(\n",
    "    X_test,\n",
    "    y=y_test,\n",
    "    sample_weight=None,\n",
    "    reset_metrics=True\n",
    ")\n",
    "print(list(zip(model.metrics_names, test_results)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test).round()\n",
    "y_pred = list(map(lambda x: int(x[0]), y_pred))\n",
    "confusion = tf.math.confusion_matrix(labels=y_test, predictions=y_pred, num_classes=2)\n",
    "confusion = confusion.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp = confusion[0][1]\n",
    "tn = confusion[0][0]\n",
    "fp_rate = float(fp / (fp+tn))\n",
    "print(f\"False Positive Rate: {round(fp_rate*100,3)}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "df_cm = pd.DataFrame(confusion, index = [\"HAM\", \"SPAM\"],\n",
    "                  columns = [\"HAM\", \"SPAM\"])\n",
    "plt.figure(figsize = (12,8))\n",
    "sns.set(font_scale=1.5)\n",
    "annot_kws = {\"ha\": 'left',\"va\": 'bottom'}\n",
    "hm = sns.heatmap(df_cm, cmap=\"Pastel1\", fmt=\"d\", annot=True, annot_kws=annot_kws)\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
