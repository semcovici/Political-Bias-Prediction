{"cells":[{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["2023-11-26 20:35:22.433957: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2023-11-26 20:35:22.433993: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2023-11-26 20:35:22.435682: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2023-11-26 20:35:22.446514: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2023-11-26 20:35:23.985414: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"]}],"source":["\n","# !pip install keras==2.3.1\n","# !pip install git+https://www.github.com/keras-team/keras-contrib.git\n","\n","# !pip install patchify    #To install and import other mentioned libraries  in code\n","# !pip install segmentation_models\n","\n","from tensorflow import keras\n","from tensorflow.keras.datasets import mnist\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, Dropout, Flatten\n","from tensorflow.keras.layers import Conv2D\n","from tensorflow.keras.layers import MaxPooling2D, Reshape\n","from tensorflow.keras import backend as k\n","from keras.layers import BatchNormalization"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2021-09-21T09:01:33.918307Z","iopub.status.busy":"2021-09-21T09:01:33.917389Z","iopub.status.idle":"2021-09-21T09:01:51.558963Z","shell.execute_reply":"2021-09-21T09:01:51.557932Z","shell.execute_reply.started":"2021-09-21T09:01:33.918249Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/home/semcovici/projetos_pesquisa/Political-Bias-Prediction/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n","  from .autonotebook import tqdm as notebook_tqdm\n"]}],"source":["import tensorflow as tf\n","from tensorflow import keras \n","from tensorflow.keras.layers import Embedding, LSTM, Dense, Bidirectional, Dense, Activation, Dropout\n","from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.optimizers import Adam\n","from transformers import BertTokenizer, TFBertModel\n","import numpy as np\n","import os\n","import pandas as pd\n","from sklearn.model_selection import train_test_split"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2021-09-21T09:01:51.563835Z","iopub.status.busy":"2021-09-21T09:01:51.56354Z","iopub.status.idle":"2021-09-21T09:01:51.570324Z","shell.execute_reply":"2021-09-21T09:01:51.569282Z","shell.execute_reply.started":"2021-09-21T09:01:51.563804Z"},"trusted":true},"outputs":[],"source":["os.environ[\"WANDB_API_KEY\"] = \"0\" ## to silence warning"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2021-09-21T09:01:51.572242Z","iopub.status.busy":"2021-09-21T09:01:51.571987Z","iopub.status.idle":"2021-09-21T09:01:57.24496Z","shell.execute_reply":"2021-09-21T09:01:57.244029Z","shell.execute_reply.started":"2021-09-21T09:01:51.572216Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Number of replicas: 1\n"]}],"source":["try:\n","    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n","    tf.config.experimental_connect_to_cluster(tpu)\n","    tf.tpu.experimental.initialize_tpu_system(tpu)\n","    strategy = tf.distribute.experimental.TPUStrategy(tpu)\n","except ValueError:\n","    strategy = tf.distribute.get_strategy() # for CPU and single GPU\n","    print('Number of replicas:', strategy.num_replicas_in_sync)"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2021-09-21T09:01:57.247152Z","iopub.status.busy":"2021-09-21T09:01:57.246907Z","iopub.status.idle":"2021-09-21T09:01:57.251881Z","shell.execute_reply":"2021-09-21T09:01:57.250859Z","shell.execute_reply.started":"2021-09-21T09:01:57.247123Z"},"trusted":true},"outputs":[],"source":["# hyperparameters\n","max_length = 512\n","batch_size = 128"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2021-09-21T09:01:57.253994Z","iopub.status.busy":"2021-09-21T09:01:57.253603Z","iopub.status.idle":"2021-09-21T09:01:58.83569Z","shell.execute_reply":"2021-09-21T09:01:58.834551Z","shell.execute_reply.started":"2021-09-21T09:01:57.253948Z"},"trusted":true},"outputs":[],"source":["# Bert Tokenizer\n","model_multingual = \"bert-base-multilingual-uncased\"\n","model_bertimbau_lg = \"neuralmind/bert-large-portuguese-cased\"\n","model_bertimbau = \"neuralmind/bert-base-portuguese-cased\"\n","\n","model_name = model_bertimbau\n","\n","tokenizer = BertTokenizer.from_pretrained(model_name)"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["data_raw = pd.read_parquet('../../dataset/processed/artigos_tratados/artigos_tratados.parquet')"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["# tira as linhas sem conteudo\n","data_raw = data_raw[data_raw['Conteudo'] != '']\n","\n","X = data_raw.drop(['URL', 'Vies'], axis = 1)\n","y = data_raw['Vies']\n","\n","y = pd.get_dummies(y).values\n","\n","X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=0.20, random_state=42, stratify=X['Partido'])\n","X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.10, random_state=42, stratify=X_train_val['Partido'])"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":["X_train = X_train.drop(['Partido'],axis=1).values\n","\n","X_test = X_test.drop(['Partido'],axis=1).values\n","\n","X_val = X_val.drop(['Partido'],axis=1).values\n","\n","# transforma em uma lista\n","X_train = X_train.reshape(X_train.shape[0])\n","X_test = X_test.reshape(X_test.shape[0])\n","X_val = X_val.reshape(X_val.shape[0])"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2021-09-21T09:01:59.353065Z","iopub.status.busy":"2021-09-21T09:01:59.352747Z","iopub.status.idle":"2021-09-21T09:01:59.359538Z","shell.execute_reply":"2021-09-21T09:01:59.358182Z","shell.execute_reply.started":"2021-09-21T09:01:59.353024Z"},"trusted":true},"outputs":[],"source":["def bert_encode(data):\n","    tokens = tokenizer.batch_encode_plus(data, max_length=max_length, padding='max_length', truncation=True)\n","    \n","    return tf.constant(tokens['input_ids'])"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["2023-11-26 20:36:13.057120: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2023-11-26 20:36:13.110399: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2023-11-26 20:36:13.110703: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2023-11-26 20:36:13.112315: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2023-11-26 20:36:13.112949: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2023-11-26 20:36:13.113261: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2023-11-26 20:36:13.190203: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2023-11-26 20:36:13.190885: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2023-11-26 20:36:13.191131: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2023-11-26 20:36:13.191257: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4759 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1660 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5\n"]}],"source":["train_encoded = bert_encode(X_train)"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[],"source":["dev_encoded = bert_encode(X_val)"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2021-09-21T09:01:59.361779Z","iopub.status.busy":"2021-09-21T09:01:59.361443Z","iopub.status.idle":"2021-09-21T09:03:23.674855Z","shell.execute_reply":"2021-09-21T09:03:23.674057Z","shell.execute_reply.started":"2021-09-21T09:01:59.361739Z"},"trusted":true},"outputs":[],"source":["train_dataset = (\n","    tf.data.Dataset\n","    .from_tensor_slices((train_encoded, y_train))\n","    .shuffle(100)\n","    .batch(batch_size)\n",")\n","\n","dev_dataset = (\n","    tf.data.Dataset\n","    .from_tensor_slices((dev_encoded, y_val))\n","    .shuffle(100)\n","    .batch(batch_size)\n",")"]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2021-09-21T09:03:29.758033Z","iopub.status.busy":"2021-09-21T09:03:29.757798Z","iopub.status.idle":"2021-09-21T09:03:29.769256Z","shell.execute_reply":"2021-09-21T09:03:29.768198Z","shell.execute_reply.started":"2021-09-21T09:03:29.758008Z"},"trusted":true},"outputs":[],"source":["def nn_model():\n","    model= Sequential()\n","\n","   \n","    model.add(Dense(20,input_dim=500, activation='relu'))\n","    model.add(Dropout(0.2))\n","    model.add(BatchNormalization())\n","\n","\n","    model.add(Dense(100, activation='relu'))\n","    model.add(Dropout(0.2))\n","    model.add(BatchNormalization())\n","\n","    model.add(Dense(100, activation='relu'))\n","    model.add(Dropout(0.2))\n","    model.add(BatchNormalization())\n","    \n","    model.add(Dense(100, activation='relu'))\n","    model.add(Dropout(0.2))\n","    model.add(BatchNormalization())\n","\n","    model.add(Dense(100, activation='relu'))\n","    model.add(Dropout(0.2))\n","    model.add(BatchNormalization())\n","\n","    model.add(Dense(100, activation='relu'))\n","    model.add(Dropout(0.2))\n","    model.add(BatchNormalization())\n","    \n","    model.add(Dense(3))\n","    model.add(Activation('softmax'))\n","\n","    # compile the model\n","    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=[\"accuracy\"])\n","    \n","    return model\n"]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","Epoch 1/100\n"]},{"name":"stderr","output_type":"stream","text":["2023-11-26 20:37:26.147128: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8906\n","2023-11-26 20:37:27.412845: I external/local_xla/xla/service/service.cc:168] XLA service 0x7fc730bdd250 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n","2023-11-26 20:37:27.412861: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce GTX 1660 Ti, Compute Capability 7.5\n","2023-11-26 20:37:27.417826: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n","WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n","I0000 00:00:1701041847.508236   17712 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"]},{"name":"stdout","output_type":"stream","text":["63/63 [==============================] - 49s 653ms/step - loss: 5.7991 - accuracy: 0.3435 - val_loss: 5.3984 - val_accuracy: 0.2305 - lr: 1.0000e-04\n","Epoch 2/100\n","63/63 [==============================] - 43s 686ms/step - loss: 5.5761 - accuracy: 0.4133 - val_loss: 5.3870 - val_accuracy: 0.2305 - lr: 1.0000e-04\n","Epoch 3/100\n","63/63 [==============================] - 42s 669ms/step - loss: 5.4890 - accuracy: 0.4598 - val_loss: 5.3639 - val_accuracy: 0.2463 - lr: 1.0000e-04\n","Epoch 4/100\n","63/63 [==============================] - 49s 784ms/step - loss: 5.4201 - accuracy: 0.4802 - val_loss: 5.3064 - val_accuracy: 0.5458 - lr: 1.0000e-04\n","Epoch 5/100\n","63/63 [==============================] - 48s 767ms/step - loss: 5.3775 - accuracy: 0.5003 - val_loss: 5.2475 - val_accuracy: 0.5424 - lr: 1.0000e-04\n","Epoch 6/100\n","63/63 [==============================] - 51s 804ms/step - loss: 5.3410 - accuracy: 0.5060 - val_loss: 5.2113 - val_accuracy: 0.5638 - lr: 1.0000e-04\n","Epoch 7/100\n","63/63 [==============================] - 49s 774ms/step - loss: 5.2917 - accuracy: 0.5136 - val_loss: 5.1941 - val_accuracy: 0.5661 - lr: 1.0000e-04\n","Epoch 8/100\n","63/63 [==============================] - 40s 642ms/step - loss: 5.2905 - accuracy: 0.5145 - val_loss: 5.1796 - val_accuracy: 0.5672 - lr: 1.0000e-04\n","Epoch 9/100\n","63/63 [==============================] - 41s 644ms/step - loss: 5.2534 - accuracy: 0.5218 - val_loss: 5.1437 - val_accuracy: 0.5706 - lr: 1.0000e-04\n","Epoch 10/100\n","63/63 [==============================] - 41s 656ms/step - loss: 5.2180 - accuracy: 0.5233 - val_loss: 5.1236 - val_accuracy: 0.5582 - lr: 1.0000e-04\n","Epoch 11/100\n","63/63 [==============================] - 45s 711ms/step - loss: 5.2020 - accuracy: 0.5286 - val_loss: 5.0947 - val_accuracy: 0.5582 - lr: 1.0000e-04\n","Epoch 12/100\n","63/63 [==============================] - 47s 743ms/step - loss: 5.1909 - accuracy: 0.5360 - val_loss: 5.0806 - val_accuracy: 0.5661 - lr: 1.0000e-04\n","Epoch 13/100\n","63/63 [==============================] - 48s 756ms/step - loss: 5.1553 - accuracy: 0.5389 - val_loss: 5.0761 - val_accuracy: 0.5650 - lr: 1.0000e-04\n","Epoch 14/100\n","63/63 [==============================] - 48s 762ms/step - loss: 5.1540 - accuracy: 0.5305 - val_loss: 5.0260 - val_accuracy: 0.5706 - lr: 1.0000e-04\n","Epoch 15/100\n","63/63 [==============================] - 47s 754ms/step - loss: 5.1273 - accuracy: 0.5303 - val_loss: 5.0394 - val_accuracy: 0.5718 - lr: 1.0000e-04\n","Epoch 16/100\n","63/63 [==============================] - 48s 765ms/step - loss: 5.1106 - accuracy: 0.5414 - val_loss: 5.0269 - val_accuracy: 0.5729 - lr: 1.0000e-04\n","Epoch 17/100\n","63/63 [==============================] - 49s 778ms/step - loss: 5.0946 - accuracy: 0.5379 - val_loss: 5.0126 - val_accuracy: 0.5740 - lr: 1.0000e-04\n","Epoch 18/100\n","63/63 [==============================] - 42s 662ms/step - loss: 5.0770 - accuracy: 0.5366 - val_loss: 4.9964 - val_accuracy: 0.5684 - lr: 1.0000e-04\n","Epoch 19/100\n","63/63 [==============================] - 41s 650ms/step - loss: 5.0607 - accuracy: 0.5387 - val_loss: 4.9813 - val_accuracy: 0.5740 - lr: 1.0000e-04\n","Epoch 20/100\n","63/63 [==============================] - 41s 658ms/step - loss: 5.0478 - accuracy: 0.5338 - val_loss: 4.9596 - val_accuracy: 0.5797 - lr: 1.0000e-04\n","Epoch 21/100\n","63/63 [==============================] - 41s 656ms/step - loss: 5.0307 - accuracy: 0.5409 - val_loss: 4.9449 - val_accuracy: 0.5853 - lr: 1.0000e-04\n","Epoch 22/100\n","63/63 [==============================] - 47s 754ms/step - loss: 5.0071 - accuracy: 0.5464 - val_loss: 4.9340 - val_accuracy: 0.5819 - lr: 1.0000e-04\n","Epoch 23/100\n","33/63 [==============>...............] - ETA: 25s - loss: 5.0019 - accuracy: 0.5471"]}],"source":["from keras.models import Sequential\n","from keras.layers import Dense, Dropout, Reshape, Activation, BatchNormalization, Conv1D, MaxPooling1D\n","from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n","import tensorflow as tf\n","import keras\n","import numpy as np\n","\n","def build_lstm_model_2(input_shape, output_shape=1):\n","    keras.backend.clear_session()\n","    \n","    model = Sequential()\n","\n","    # Adicione uma camada de remodelagem para transformar a entrada em 3D\n","    model.add(Reshape((input_shape, 1), input_shape=(input_shape,)))\n","\n","    model.add(Conv1D(filters=32, kernel_size=3, activation='relu'))\n","    model.add(MaxPooling1D(pool_size=2))\n","    model.add(BatchNormalization())\n","\n","    model.add(Dense(20, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01)))\n","    model.add(Dropout(0.2))\n","    model.add(BatchNormalization())\n","    \n","    model.add(tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64, return_sequences=True, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01))))\n","    model.add(Dropout(0.2))\n","    model.add(BatchNormalization())    \n","    \n","    model.add(tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01))))\n","    model.add(Dropout(0.2))\n","    model.add(BatchNormalization())\n","\n","    model.add(Dense(100, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01)))\n","    model.add(Dropout(0.2))\n","    model.add(BatchNormalization())\n","    \n","    model.add(Dense(output_shape, activation='softmax'))\n","    \n","    model.compile(loss='categorical_crossentropy',\n","                  optimizer=tf.keras.optimizers.Adam(1e-4),\n","                  metrics=['accuracy'])\n","    \n","    return model\n","\n","# Supondo que você tenha um conjunto de treinamento (train_dataset) e um conjunto de validação (dev_dataset)\n","\n","model = build_lstm_model_2(input_shape=512, output_shape=3)\n","\n","# Adicionando callbacks\n","early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n","reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=1e-6)\n","\n","# Treinamento do modelo\n","history = model.fit(\n","    train_dataset,\n","    epochs=100,\n","    callbacks=[early_stopping, reduce_lr],\n","    validation_data=dev_dataset,\n","    batch_size=batch_size,\n","    shuffle=True,\n",")\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","Epoch 1/1000\n"," 34/249 [===>..........................] - ETA: 7:09 - loss: nan - accuracy: 0.3208"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[1;32m/home/semcovici/projetos_pesquisa/Political-Bias-Prediction/src/classificacao/products-bert-embeddings-and-lstm.ipynb Cell 19\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/semcovici/projetos_pesquisa/Political-Bias-Prediction/src/classificacao/products-bert-embeddings-and-lstm.ipynb#X45sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m model \u001b[39m=\u001b[39m build_lstm_model_2(input_shape\u001b[39m=\u001b[39m\u001b[39m512\u001b[39m, output_shape\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/semcovici/projetos_pesquisa/Political-Bias-Prediction/src/classificacao/products-bert-embeddings-and-lstm.ipynb#X45sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m callback \u001b[39m=\u001b[39m keras\u001b[39m.\u001b[39mcallbacks\u001b[39m.\u001b[39mEarlyStopping(monitor\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mval_loss\u001b[39m\u001b[39m'\u001b[39m, patience\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m, restore_best_weights\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/semcovici/projetos_pesquisa/Political-Bias-Prediction/src/classificacao/products-bert-embeddings-and-lstm.ipynb#X45sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/semcovici/projetos_pesquisa/Political-Bias-Prediction/src/classificacao/products-bert-embeddings-and-lstm.ipynb#X45sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m                     train_dataset,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/semcovici/projetos_pesquisa/Political-Bias-Prediction/src/classificacao/products-bert-embeddings-and-lstm.ipynb#X45sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m                     epochs\u001b[39m=\u001b[39;49m\u001b[39m1000\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/semcovici/projetos_pesquisa/Political-Bias-Prediction/src/classificacao/products-bert-embeddings-and-lstm.ipynb#X45sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m                     callbacks\u001b[39m=\u001b[39;49m[callback],\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/semcovici/projetos_pesquisa/Political-Bias-Prediction/src/classificacao/products-bert-embeddings-and-lstm.ipynb#X45sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m                     validation_data\u001b[39m=\u001b[39;49mdev_dataset,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/semcovici/projetos_pesquisa/Political-Bias-Prediction/src/classificacao/products-bert-embeddings-and-lstm.ipynb#X45sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m                     batch_size\u001b[39m=\u001b[39;49m\u001b[39m32\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/semcovici/projetos_pesquisa/Political-Bias-Prediction/src/classificacao/products-bert-embeddings-and-lstm.ipynb#X45sZmlsZQ%3D%3D?line=42'>43</a>\u001b[0m                     shuffle \u001b[39m=\u001b[39;49m \u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/semcovici/projetos_pesquisa/Political-Bias-Prediction/src/classificacao/products-bert-embeddings-and-lstm.ipynb#X45sZmlsZQ%3D%3D?line=43'>44</a>\u001b[0m                     ) \n","File \u001b[0;32m~/projetos_pesquisa/Political-Bias-Prediction/.venv/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n","File \u001b[0;32m~/projetos_pesquisa/Political-Bias-Prediction/.venv/lib/python3.10/site-packages/keras/src/engine/training.py:1807\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1799\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[1;32m   1800\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1801\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1804\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[1;32m   1805\u001b[0m ):\n\u001b[1;32m   1806\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1807\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[1;32m   1808\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[1;32m   1809\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n","File \u001b[0;32m~/projetos_pesquisa/Political-Bias-Prediction/.venv/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n","File \u001b[0;32m~/projetos_pesquisa/Political-Bias-Prediction/.venv/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:832\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    829\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    831\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 832\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    834\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    835\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n","File \u001b[0;32m~/projetos_pesquisa/Political-Bias-Prediction/.venv/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:868\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    865\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m    866\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    867\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 868\u001b[0m   \u001b[39mreturn\u001b[39;00m tracing_compilation\u001b[39m.\u001b[39;49mcall_function(\n\u001b[1;32m    869\u001b[0m       args, kwds, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_no_variable_creation_config\n\u001b[1;32m    870\u001b[0m   )\n\u001b[1;32m    871\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_variable_creation_config \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    872\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    873\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[1;32m    874\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n","File \u001b[0;32m~/projetos_pesquisa/Political-Bias-Prediction/.venv/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[39m=\u001b[39m function\u001b[39m.\u001b[39mfunction_type\u001b[39m.\u001b[39mbind(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[39m=\u001b[39m function\u001b[39m.\u001b[39mfunction_type\u001b[39m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[39mreturn\u001b[39;00m function\u001b[39m.\u001b[39;49m_call_flat(  \u001b[39m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    140\u001b[0m     flat_inputs, captured_inputs\u001b[39m=\u001b[39;49mfunction\u001b[39m.\u001b[39;49mcaptured_inputs\n\u001b[1;32m    141\u001b[0m )\n","File \u001b[0;32m~/projetos_pesquisa/Political-Bias-Prediction/.venv/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1323\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1319\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1320\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1321\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1322\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1323\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall_preflattened(args)\n\u001b[1;32m   1324\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1325\u001b[0m     args,\n\u001b[1;32m   1326\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1327\u001b[0m     executing_eagerly)\n\u001b[1;32m   1328\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n","File \u001b[0;32m~/projetos_pesquisa/Political-Bias-Prediction/.venv/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcall_preflattened\u001b[39m(\u001b[39mself\u001b[39m, args: Sequence[core\u001b[39m.\u001b[39mTensor]) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n\u001b[1;32m    215\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m   flat_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcall_flat(\u001b[39m*\u001b[39;49margs)\n\u001b[1;32m    217\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunction_type\u001b[39m.\u001b[39mpack_output(flat_outputs)\n","File \u001b[0;32m~/projetos_pesquisa/Political-Bias-Prediction/.venv/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[39mwith\u001b[39;00m record\u001b[39m.\u001b[39mstop_recording():\n\u001b[1;32m    250\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_bound_context\u001b[39m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 251\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_bound_context\u001b[39m.\u001b[39;49mcall_function(\n\u001b[1;32m    252\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname,\n\u001b[1;32m    253\u001b[0m         \u001b[39mlist\u001b[39;49m(args),\n\u001b[1;32m    254\u001b[0m         \u001b[39mlen\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction_type\u001b[39m.\u001b[39;49mflat_outputs),\n\u001b[1;32m    255\u001b[0m     )\n\u001b[1;32m    256\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m     outputs \u001b[39m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    258\u001b[0m         \u001b[39mself\u001b[39m,\n\u001b[1;32m    259\u001b[0m         \u001b[39mlist\u001b[39m(args),\n\u001b[1;32m    260\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_bound_context\u001b[39m.\u001b[39mfunction_call_options\u001b[39m.\u001b[39mas_attrs(),\n\u001b[1;32m    261\u001b[0m     )\n","File \u001b[0;32m~/projetos_pesquisa/Political-Bias-Prediction/.venv/lib/python3.10/site-packages/tensorflow/python/eager/context.py:1486\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1484\u001b[0m cancellation_context \u001b[39m=\u001b[39m cancellation\u001b[39m.\u001b[39mcontext()\n\u001b[1;32m   1485\u001b[0m \u001b[39mif\u001b[39;00m cancellation_context \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1486\u001b[0m   outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[1;32m   1487\u001b[0m       name\u001b[39m.\u001b[39;49mdecode(\u001b[39m\"\u001b[39;49m\u001b[39mutf-8\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m   1488\u001b[0m       num_outputs\u001b[39m=\u001b[39;49mnum_outputs,\n\u001b[1;32m   1489\u001b[0m       inputs\u001b[39m=\u001b[39;49mtensor_inputs,\n\u001b[1;32m   1490\u001b[0m       attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[1;32m   1491\u001b[0m       ctx\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[1;32m   1492\u001b[0m   )\n\u001b[1;32m   1493\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1494\u001b[0m   outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1495\u001b[0m       name\u001b[39m.\u001b[39mdecode(\u001b[39m\"\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[1;32m   1496\u001b[0m       num_outputs\u001b[39m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1500\u001b[0m       cancellation_manager\u001b[39m=\u001b[39mcancellation_context,\n\u001b[1;32m   1501\u001b[0m   )\n","File \u001b[0;32m~/projetos_pesquisa/Political-Bias-Prediction/.venv/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[1;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["\n","\n","# def build_lstm_model_2(input_shape, output_shape=1):\n","#     keras.backend.clear_session()\n","    \n","#     model = Sequential()\n","\n","#     # Adicione uma camada de remodelagem para transformar a entrada em 3D\n","#     model.add(Reshape((input_shape, 1), input_shape=(input_shape,)))\n","\n","#     model.add(Dense(20, activation='relu'))\n","#     model.add(Dropout(0.2))\n","#     #model.add(BatchNormalization())\n","    \n","#     model.add(tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64, return_sequences=True, activation='relu')))\n","#     model.add(Dropout(0.2))\n","#     #model.add(BatchNormalization())    \n","    \n","#     model.add(tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32, activation='relu')))\n","#     model.add(Dropout(0.2))\n","#     #model.add(BatchNormalization())\n","\n","#     model.add(Dense(100, activation='relu'))\n","#     model.add(Dropout(0.2))\n","#     #model.add(BatchNormalization())\n","    \n","#     model.add(Dense(output_shape))\n","#     model.add(Activation('softmax'))\n","    \n","#     model.compile(loss='categorical_crossentropy',\n","#                   optimizer=tf.keras.optimizers.Adam(1e-4),\n","#                   metrics=['accuracy'])\n","    \n","#     return model\n","\n","# model = build_lstm_model_2(input_shape=512, output_shape=3)\n","# callback = keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n","\n","# history = model.fit(\n","#                     train_dataset,\n","#                     epochs=100,\n","#                     callbacks=[callback],\n","#                     validation_data=dev_dataset,\n","#                     batch_size=32,\n","#                     shuffle = True,\n","#                     ) "]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2021-09-21T09:05:24.870388Z","iopub.status.idle":"2021-09-21T09:05:24.870746Z","shell.execute_reply":"2021-09-21T09:05:24.870572Z","shell.execute_reply.started":"2021-09-21T09:05:24.870551Z"},"trusted":true},"outputs":[],"source":["import matplotlib.pyplot as plt\n","\n","def plot_graphs(history, string):\n","  plt.plot(history.history[string])\n","  plt.plot(history.history['val_'+string])\n","  plt.xlabel(\"Epochs\")\n","  plt.ylabel(string)\n","  plt.legend([string, 'val_'+string])\n","  plt.show()\n","  \n","plot_graphs(history, \"accuracy\")\n","plot_graphs(history, \"loss\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2021-09-21T09:05:24.871971Z","iopub.status.idle":"2021-09-21T09:05:24.872319Z","shell.execute_reply":"2021-09-21T09:05:24.872148Z","shell.execute_reply.started":"2021-09-21T09:05:24.872127Z"},"trusted":true},"outputs":[],"source":["test = pd.read_csv('/kaggle/input/nlp-getting-started/test.csv')\n","test_encoded = bert_encode(test.text)\n","\n","test_dataset = (\n","    tf.data.Dataset\n","    .from_tensor_slices(test_encoded)\n","    .batch(batch_size)\n",")\n","\n","predicted_tweets = model.predict(test_dataset, batch_size=batch_size)\n","predicted_tweets_binary = tf.cast(tf.round(predicted_tweets), tf.int32).numpy().flatten()\n","\n","my_submission = pd.DataFrame({'id': test.id, 'target': predicted_tweets_binary})\n","my_submission.to_csv('/kaggle/working/my_submission.csv', index=False)"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":4}
