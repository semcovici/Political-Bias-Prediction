{"cells":[{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["2023-12-03 16:28:46.962513: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2023-12-03 16:28:46.962737: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2023-12-03 16:28:46.987371: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2023-12-03 16:28:47.039844: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2023-12-03 16:28:47.913610: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","/home/semcovici/projetos_pesquisa/Political-Bias-Prediction/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n","  from .autonotebook import tqdm as notebook_tqdm\n"]}],"source":["\n","# !pip install keras==2.3.1\n","# !pip install git+https://www.github.com/keras-team/keras-contrib.git\n","# !pip install patchify    #To install and import other mentioned libraries  in code\n","# !pip install segmentation_models\n","from tensorflow import keras\n","from tensorflow.keras.datasets import mnist\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, Dropout, Flatten\n","from tensorflow.keras.layers import Conv2D, Conv1D\n","from tensorflow.keras.layers import MaxPooling2D, MaxPooling1D, Reshape\n","from tensorflow.keras import backend as k\n","from keras.layers import BatchNormalization\n","import torch\n","from sklearn.metrics import classification_report\n","\n","import optuna\n","from keras.models import Sequential\n","from keras.layers import Reshape, Conv1D, MaxPooling1D, BatchNormalization, Dense, Dropout, Bidirectional, LSTM\n","import tensorflow as tf\n","from optuna.integration import TFKerasPruningCallback\n","from keras.callbacks import EarlyStopping, ReduceLROnPlateau"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["from tensorflow.compat.v1.keras.layers import CuDNNLSTM\n"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2021-09-21T09:01:33.918307Z","iopub.status.busy":"2021-09-21T09:01:33.917389Z","iopub.status.idle":"2021-09-21T09:01:51.558963Z","shell.execute_reply":"2021-09-21T09:01:51.557932Z","shell.execute_reply.started":"2021-09-21T09:01:33.918249Z"},"trusted":true},"outputs":[],"source":["import tensorflow as tf\n","from tensorflow import keras \n","from tensorflow.keras.layers import Embedding, LSTM, Dense, Bidirectional, Dense, Activation, Dropout\n","from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.optimizers import Adam\n","from transformers import BertTokenizer, TFBertModel\n","import numpy as np\n","import os\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","\n","from tensorflow.compat.v1.keras.layers import CuDNNLSTM"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2021-09-21T09:01:51.563835Z","iopub.status.busy":"2021-09-21T09:01:51.56354Z","iopub.status.idle":"2021-09-21T09:01:51.570324Z","shell.execute_reply":"2021-09-21T09:01:51.569282Z","shell.execute_reply.started":"2021-09-21T09:01:51.563804Z"},"trusted":true},"outputs":[],"source":["os.environ[\"WANDB_API_KEY\"] = \"0\" ## to silence warning"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2021-09-21T09:01:51.572242Z","iopub.status.busy":"2021-09-21T09:01:51.571987Z","iopub.status.idle":"2021-09-21T09:01:57.24496Z","shell.execute_reply":"2021-09-21T09:01:57.244029Z","shell.execute_reply.started":"2021-09-21T09:01:51.572216Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Number of replicas: 1\n"]}],"source":["try:\n","    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n","    tf.config.experimental_connect_to_cluster(tpu)\n","    tf.tpu.experimental.initialize_tpu_system(tpu)\n","    strategy = tf.distribute.experimental.TPUStrategy(tpu)\n","except ValueError:\n","    strategy = tf.distribute.get_strategy() # for CPU and single GPU\n","    print('Number of replicas:', strategy.num_replicas_in_sync)"]},{"cell_type":"markdown","metadata":{},"source":["## Formatando o Dataset"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["max_lenght = 100\n","X = np.load(f'../../dataset/processed/artigos_tratados/bertimbau/bertimbau_full__max_lenght={max_lenght}.npy')\n","data_raw = pd.read_parquet('../../dataset/processed/artigos_tratados/artigos_tratados.parquet')"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["indexes = pd.read_csv('../../dataset/index_splits.csv', index_col = 0)"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>name</th>\n","      <th>value</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>linhas_sem_texto</td>\n","      <td>[1140, 1165, 1188, 1314, 1320, 1339, 1361, 200...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>strat_vies</td>\n","      <td>[[2596, 1763, 6620, 10805, 3029, 2637, 744, 41...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>strat_part</td>\n","      <td>[[4465, 2218, 972, 580, 1957, 5448, 6819, 8621...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>part_novos</td>\n","      <td>[[5497, 6570, 4197, 1214, 5300, 2491, 5284, 38...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["               name                                              value\n","0  linhas_sem_texto  [1140, 1165, 1188, 1314, 1320, 1339, 1361, 200...\n","1        strat_vies  [[2596, 1763, 6620, 10805, 3029, 2637, 744, 41...\n","2        strat_part  [[4465, 2218, 972, 580, 1957, 5448, 6819, 8621...\n","3        part_novos  [[5497, 6570, 4197, 1214, 5300, 2491, 5284, 38..."]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["indexes"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":["y = data_raw['Vies']\n","\n","y = y.map({\n","    'direita':2,\n","    'centro':1,\n","    'esquerda': 0})\n","\n","y = pd.get_dummies(y).values"]},{"cell_type":"markdown","metadata":{},"source":["## Criando Classificador"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["unique, counts = np.unique(y.argmax(axis=1), return_counts=True)\n","esquerda_count, centro_count, direita_count  = counts\n","total_count = sum(counts)"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[],"source":["num_classes = 3\n","class_weight = {0: (1 / esquerda_count) * (total_count / num_classes),\n","                1: (1 / centro_count) * (total_count / num_classes),\n","                2: (1 / direita_count) * (total_count / num_classes)}"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["2023-12-03 16:28:56.424161: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2023-12-03 16:28:56.428015: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2023-12-03 16:28:56.428196: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2023-12-03 16:28:56.429381: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2023-12-03 16:28:56.429568: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2023-12-03 16:28:56.429690: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2023-12-03 16:28:56.512450: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2023-12-03 16:28:56.512671: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2023-12-03 16:28:56.512827: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2023-12-03 16:28:56.512940: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4759 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1660 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5\n"]}],"source":["METRICS = [\n","      # keras.metrics.TruePositives(name='tp'),\n","      # keras.metrics.FalsePositives(name='fp'),\n","      # keras.metrics.TrueNegatives(name='tn'),\n","      # keras.metrics.FalseNegatives(name='fn'), \n","      keras.metrics.Precision(name='precision'),\n","      keras.metrics.Recall(name='recall'),\n","      keras.metrics.AUC(name='auc'),\n","      keras.metrics.AUC(name='prc', curve='PR'), # precision-recall curve\n","      ]"]},{"cell_type":"markdown","metadata":{},"source":["### Teste inicial "]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[],"source":["def build_lstm_model(input_shape, output_shape, metrics):\n","    tf.keras.backend.clear_session()\n","\n","    model = tf.keras.Sequential([\n","        Conv1D(filters=32, kernel_size=3, activation='relu', input_shape=input_shape),\n","        MaxPooling1D(pool_size=3),\n","        tf.keras.layers.Dropout(0.5),\n","        Bidirectional(CuDNNLSTM(100, kernel_regularizer=tf.keras.regularizers.l2(0.01), return_sequences=True)),\n","        tf.keras.layers.Dropout(0.5),\n","        Bidirectional(CuDNNLSTM(50, kernel_regularizer=tf.keras.regularizers.l2(0.01), return_sequences=True)),\n","        tf.keras.layers.Dropout(0.5),\n","        MaxPooling1D(pool_size=3),\n","        Flatten(),\n","        tf.keras.layers.Dense(64, activation='relu'),\n","        tf.keras.layers.Dropout(0.5),\n","        tf.keras.layers.Dense(output_shape, activation='softmax')\n","    ])\n","\n","    model.compile(loss='categorical_crossentropy',\n","                optimizer=tf.keras.optimizers.Adam(2e-5),\n","                metrics=METRICS)\n","    \n","    return model"]},{"cell_type":"markdown","metadata":{},"source":["#### Strat Vies "]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[],"source":["index_strat_vies = eval(indexes.loc[1,'value'])\n","train_strat_vies_index, val_strat_vies_index, test_strat_vies_index = index_strat_vies"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[],"source":["X_train_strat_vies = X[train_strat_vies_index]\n","y_train_strat_vies = y[train_strat_vies_index]\n","\n","X_val_strat_vies = X[val_strat_vies_index]\n","y_val_strat_vies = y[val_strat_vies_index]\n","\n","X_test_strat_vies = X[test_strat_vies_index]\n","y_test_strat_vies = y[test_strat_vies_index]"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["2023-12-03 15:14:05.176653: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 2446233600 exceeds 10% of free system memory.\n","2023-12-03 15:14:24.098228: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 2446233600 exceeds 10% of free system memory.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 1/100\n"]},{"name":"stderr","output_type":"stream","text":["2023-12-03 15:14:28.350195: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n","2023-12-03 15:14:28.622120: W external/local_tsl/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.82GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n","2023-12-03 15:14:28.646892: W external/local_tsl/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.82GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n","2023-12-03 15:14:30.059630: I external/local_xla/xla/service/service.cc:168] XLA service 0x7f7aa008a9d0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n","2023-12-03 15:14:30.059649: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce GTX 1660 Ti, Compute Capability 7.5\n","2023-12-03 15:14:30.080476: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n","WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n","I0000 00:00:1701627270.229132    4213 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"]},{"name":"stdout","output_type":"stream","text":["  6/996 [..............................] - ETA: 10s - loss: 6.2129 - precision: 0.6667 - recall: 0.1250 - auc: 0.6089 - prc: 0.5021    "]},{"name":"stderr","output_type":"stream","text":["2023-12-03 15:14:31.617309: W external/local_tsl/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.06GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n","2023-12-03 15:14:31.617354: W external/local_tsl/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.06GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n","2023-12-03 15:14:31.630261: W external/local_tsl/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.06GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n","2023-12-03 15:14:31.630300: W external/local_tsl/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.06GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n"]},{"name":"stdout","output_type":"stream","text":["996/996 [==============================] - ETA: 0s - loss: 5.3770 - precision: 0.7931 - recall: 0.3313 - auc: 0.7960 - prc: 0.6868"]},{"name":"stderr","output_type":"stream","text":["2023-12-03 15:14:41.641796: W external/local_tsl/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.35GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n","2023-12-03 15:14:41.657818: W external/local_tsl/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.35GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n","2023-12-03 15:14:41.675852: W external/local_tsl/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.06GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n","2023-12-03 15:14:41.683432: W external/local_tsl/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.06GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n","2023-12-03 15:14:43.883406: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 271872000 exceeds 10% of free system memory.\n","2023-12-03 15:14:44.089699: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 271872000 exceeds 10% of free system memory.\n"]},{"name":"stdout","output_type":"stream","text":["996/996 [==============================] - 20s 14ms/step - loss: 5.3770 - precision: 0.7931 - recall: 0.3313 - auc: 0.7960 - prc: 0.6868 - val_loss: 4.4247 - val_precision: 0.8438 - val_recall: 0.7627 - val_auc: 0.9328 - val_prc: 0.8946\n","Epoch 2/100\n","996/996 [==============================] - 10s 10ms/step - loss: 3.9000 - precision: 0.8346 - recall: 0.7752 - auc: 0.9308 - prc: 0.8831 - val_loss: 3.3498 - val_precision: 0.8631 - val_recall: 0.8124 - val_auc: 0.9526 - val_prc: 0.9205\n","Epoch 3/100\n","996/996 [==============================] - 10s 10ms/step - loss: 3.0195 - precision: 0.8561 - recall: 0.8194 - auc: 0.9482 - prc: 0.9122 - val_loss: 2.5956 - val_precision: 0.8756 - val_recall: 0.8429 - val_auc: 0.9652 - val_prc: 0.9403\n","Epoch 4/100\n","996/996 [==============================] - 10s 10ms/step - loss: 2.3971 - precision: 0.8640 - recall: 0.8331 - auc: 0.9552 - prc: 0.9246 - val_loss: 2.0927 - val_precision: 0.8817 - val_recall: 0.8588 - val_auc: 0.9656 - val_prc: 0.9416\n","Epoch 5/100\n","996/996 [==============================] - 11s 11ms/step - loss: 1.9360 - precision: 0.8788 - recall: 0.8502 - auc: 0.9615 - prc: 0.9344 - val_loss: 1.7073 - val_precision: 0.8919 - val_recall: 0.8667 - val_auc: 0.9704 - val_prc: 0.9494\n","Epoch 6/100\n","996/996 [==============================] - 10s 10ms/step - loss: 1.6094 - precision: 0.8844 - recall: 0.8570 - auc: 0.9664 - prc: 0.9428 - val_loss: 1.4286 - val_precision: 0.9048 - val_recall: 0.8802 - val_auc: 0.9749 - val_prc: 0.9563\n","Epoch 7/100\n","996/996 [==============================] - 10s 10ms/step - loss: 1.3795 - precision: 0.8947 - recall: 0.8686 - auc: 0.9692 - prc: 0.9473 - val_loss: 1.2591 - val_precision: 0.8980 - val_recall: 0.8757 - val_auc: 0.9747 - val_prc: 0.9558\n","Epoch 8/100\n","996/996 [==============================] - 10s 11ms/step - loss: 1.2163 - precision: 0.9006 - recall: 0.8784 - auc: 0.9724 - prc: 0.9526 - val_loss: 1.1404 - val_precision: 0.8960 - val_recall: 0.8757 - val_auc: 0.9726 - val_prc: 0.9519\n","Epoch 9/100\n","996/996 [==============================] - 11s 11ms/step - loss: 1.1004 - precision: 0.9004 - recall: 0.8779 - auc: 0.9741 - prc: 0.9548 - val_loss: 1.0216 - val_precision: 0.9095 - val_recall: 0.8859 - val_auc: 0.9775 - val_prc: 0.9605\n","Epoch 10/100\n","996/996 [==============================] - 10s 10ms/step - loss: 0.9960 - precision: 0.9093 - recall: 0.8877 - auc: 0.9775 - prc: 0.9613 - val_loss: 0.9416 - val_precision: 0.9062 - val_recall: 0.8949 - val_auc: 0.9790 - val_prc: 0.9631\n","Epoch 11/100\n","996/996 [==============================] - 12s 12ms/step - loss: 0.9253 - precision: 0.9140 - recall: 0.8926 - auc: 0.9779 - prc: 0.9613 - val_loss: 0.8683 - val_precision: 0.9134 - val_recall: 0.8938 - val_auc: 0.9809 - val_prc: 0.9663\n","Epoch 12/100\n","996/996 [==============================] - 11s 11ms/step - loss: 0.8588 - precision: 0.9114 - recall: 0.8941 - auc: 0.9801 - prc: 0.9655 - val_loss: 0.8312 - val_precision: 0.9078 - val_recall: 0.8904 - val_auc: 0.9792 - val_prc: 0.9630\n","Epoch 13/100\n","996/996 [==============================] - 10s 11ms/step - loss: 0.8047 - precision: 0.9180 - recall: 0.8994 - auc: 0.9810 - prc: 0.9671 - val_loss: 0.7898 - val_precision: 0.9128 - val_recall: 0.8994 - val_auc: 0.9781 - val_prc: 0.9614\n","Epoch 14/100\n","996/996 [==============================] - 10s 10ms/step - loss: 0.7518 - precision: 0.9218 - recall: 0.9044 - auc: 0.9827 - prc: 0.9694 - val_loss: 0.7288 - val_precision: 0.9133 - val_recall: 0.8927 - val_auc: 0.9822 - val_prc: 0.9682\n","Epoch 15/100\n","996/996 [==============================] - 10s 10ms/step - loss: 0.7074 - precision: 0.9244 - recall: 0.9085 - auc: 0.9841 - prc: 0.9719 - val_loss: 0.7104 - val_precision: 0.9125 - val_recall: 0.8960 - val_auc: 0.9796 - val_prc: 0.9637\n","Epoch 16/100\n","996/996 [==============================] - 10s 10ms/step - loss: 0.6582 - precision: 0.9289 - recall: 0.9135 - auc: 0.9857 - prc: 0.9746 - val_loss: 0.6681 - val_precision: 0.9160 - val_recall: 0.8994 - val_auc: 0.9811 - val_prc: 0.9662\n","Epoch 17/100\n","996/996 [==============================] - 10s 10ms/step - loss: 0.6303 - precision: 0.9289 - recall: 0.9150 - auc: 0.9853 - prc: 0.9736 - val_loss: 0.6168 - val_precision: 0.9239 - val_recall: 0.9051 - val_auc: 0.9847 - val_prc: 0.9724\n","Epoch 18/100\n","996/996 [==============================] - 11s 11ms/step - loss: 0.5963 - precision: 0.9359 - recall: 0.9200 - auc: 0.9866 - prc: 0.9760 - val_loss: 0.6062 - val_precision: 0.9231 - val_recall: 0.9085 - val_auc: 0.9824 - val_prc: 0.9688\n","Epoch 19/100\n","996/996 [==============================] - 10s 10ms/step - loss: 0.5550 - precision: 0.9385 - recall: 0.9236 - auc: 0.9884 - prc: 0.9794 - val_loss: 0.5876 - val_precision: 0.9166 - val_recall: 0.9062 - val_auc: 0.9822 - val_prc: 0.9687\n","Epoch 20/100\n","996/996 [==============================] - 9s 9ms/step - loss: 0.5244 - precision: 0.9377 - recall: 0.9265 - auc: 0.9891 - prc: 0.9808 - val_loss: 0.5518 - val_precision: 0.9236 - val_recall: 0.9153 - val_auc: 0.9840 - val_prc: 0.9719\n","Epoch 21/100\n","996/996 [==============================] - 9s 9ms/step - loss: 0.5077 - precision: 0.9426 - recall: 0.9293 - auc: 0.9890 - prc: 0.9806 - val_loss: 0.5467 - val_precision: 0.9087 - val_recall: 0.8994 - val_auc: 0.9827 - val_prc: 0.9693\n","Epoch 22/100\n","996/996 [==============================] - 9s 9ms/step - loss: 0.4859 - precision: 0.9445 - recall: 0.9336 - auc: 0.9892 - prc: 0.9810 - val_loss: 0.5258 - val_precision: 0.9206 - val_recall: 0.9040 - val_auc: 0.9830 - val_prc: 0.9698\n","Epoch 23/100\n","996/996 [==============================] - 9s 9ms/step - loss: 0.4540 - precision: 0.9432 - recall: 0.9341 - auc: 0.9907 - prc: 0.9837 - val_loss: 0.5287 - val_precision: 0.9063 - val_recall: 0.8960 - val_auc: 0.9807 - val_prc: 0.9658\n","Epoch 24/100\n","996/996 [==============================] - 11s 11ms/step - loss: 0.4294 - precision: 0.9502 - recall: 0.9397 - auc: 0.9916 - prc: 0.9850 - val_loss: 0.4780 - val_precision: 0.9224 - val_recall: 0.9130 - val_auc: 0.9854 - val_prc: 0.9742\n","Epoch 25/100\n","996/996 [==============================] - 11s 11ms/step - loss: 0.4151 - precision: 0.9489 - recall: 0.9371 - auc: 0.9921 - prc: 0.9855 - val_loss: 0.4748 - val_precision: 0.9238 - val_recall: 0.9040 - val_auc: 0.9842 - val_prc: 0.9720\n","Epoch 26/100\n","996/996 [==============================] - 11s 11ms/step - loss: 0.3977 - precision: 0.9527 - recall: 0.9439 - auc: 0.9921 - prc: 0.9857 - val_loss: 0.4528 - val_precision: 0.9233 - val_recall: 0.9107 - val_auc: 0.9857 - val_prc: 0.9750\n","Epoch 27/100\n","996/996 [==============================] - 11s 11ms/step - loss: 0.3772 - precision: 0.9515 - recall: 0.9444 - auc: 0.9928 - prc: 0.9871 - val_loss: 0.4478 - val_precision: 0.9253 - val_recall: 0.9096 - val_auc: 0.9845 - val_prc: 0.9714\n","Epoch 28/100\n","996/996 [==============================] - 10s 10ms/step - loss: 0.3577 - precision: 0.9576 - recall: 0.9491 - auc: 0.9935 - prc: 0.9878 - val_loss: 0.4314 - val_precision: 0.9223 - val_recall: 0.9119 - val_auc: 0.9857 - val_prc: 0.9736\n","Epoch 29/100\n","996/996 [==============================] - 10s 10ms/step - loss: 0.3450 - precision: 0.9592 - recall: 0.9524 - auc: 0.9938 - prc: 0.9891 - val_loss: 0.4265 - val_precision: 0.9189 - val_recall: 0.9085 - val_auc: 0.9855 - val_prc: 0.9739\n","Epoch 30/100\n","996/996 [==============================] - 9s 10ms/step - loss: 0.3357 - precision: 0.9598 - recall: 0.9529 - auc: 0.9935 - prc: 0.9882 - val_loss: 0.4185 - val_precision: 0.9245 - val_recall: 0.9130 - val_auc: 0.9847 - val_prc: 0.9725\n","Epoch 31/100\n","996/996 [==============================] - 10s 10ms/step - loss: 0.3207 - precision: 0.9590 - recall: 0.9529 - auc: 0.9943 - prc: 0.9897 - val_loss: 0.4032 - val_precision: 0.9254 - val_recall: 0.9107 - val_auc: 0.9858 - val_prc: 0.9740\n","Epoch 32/100\n","996/996 [==============================] - 9s 9ms/step - loss: 0.3019 - precision: 0.9644 - recall: 0.9588 - auc: 0.9949 - prc: 0.9906 - val_loss: 0.4128 - val_precision: 0.9233 - val_recall: 0.9119 - val_auc: 0.9833 - val_prc: 0.9695\n","Epoch 33/100\n","996/996 [==============================] - 9s 9ms/step - loss: 0.2985 - precision: 0.9650 - recall: 0.9586 - auc: 0.9947 - prc: 0.9902 - val_loss: 0.3898 - val_precision: 0.9290 - val_recall: 0.9164 - val_auc: 0.9860 - val_prc: 0.9743\n","Epoch 34/100\n","996/996 [==============================] - 11s 11ms/step - loss: 0.2877 - precision: 0.9630 - recall: 0.9569 - auc: 0.9952 - prc: 0.9909 - val_loss: 0.3755 - val_precision: 0.9282 - val_recall: 0.9198 - val_auc: 0.9868 - val_prc: 0.9764\n","Epoch 35/100\n","996/996 [==============================] - 11s 11ms/step - loss: 0.2693 - precision: 0.9657 - recall: 0.9608 - auc: 0.9956 - prc: 0.9918 - val_loss: 0.3935 - val_precision: 0.9258 - val_recall: 0.9164 - val_auc: 0.9836 - val_prc: 0.9704\n","Epoch 36/100\n","996/996 [==============================] - 9s 9ms/step - loss: 0.2682 - precision: 0.9648 - recall: 0.9593 - auc: 0.9952 - prc: 0.9912 - val_loss: 0.3987 - val_precision: 0.9206 - val_recall: 0.9175 - val_auc: 0.9825 - val_prc: 0.9675\n","Epoch 37/100\n","996/996 [==============================] - 9s 9ms/step - loss: 0.2548 - precision: 0.9668 - recall: 0.9626 - auc: 0.9958 - prc: 0.9923 - val_loss: 0.3694 - val_precision: 0.9247 - val_recall: 0.9153 - val_auc: 0.9847 - val_prc: 0.9721\n","Epoch 38/100\n","996/996 [==============================] - 9s 9ms/step - loss: 0.2436 - precision: 0.9665 - recall: 0.9631 - auc: 0.9963 - prc: 0.9931 - val_loss: 0.3634 - val_precision: 0.9292 - val_recall: 0.9198 - val_auc: 0.9845 - val_prc: 0.9718\n","Epoch 39/100\n","996/996 [==============================] - 9s 10ms/step - loss: 0.2341 - precision: 0.9706 - recall: 0.9660 - auc: 0.9965 - prc: 0.9936 - val_loss: 0.3515 - val_precision: 0.9315 - val_recall: 0.9220 - val_auc: 0.9851 - val_prc: 0.9727\n","Epoch 40/100\n","996/996 [==============================] - 11s 11ms/step - loss: 0.2215 - precision: 0.9739 - recall: 0.9695 - auc: 0.9967 - prc: 0.9938 - val_loss: 0.3586 - val_precision: 0.9305 - val_recall: 0.9232 - val_auc: 0.9841 - val_prc: 0.9702\n","Epoch 41/100\n","996/996 [==============================] - 10s 10ms/step - loss: 0.2162 - precision: 0.9748 - recall: 0.9699 - auc: 0.9967 - prc: 0.9939 - val_loss: 0.3443 - val_precision: 0.9317 - val_recall: 0.9254 - val_auc: 0.9853 - val_prc: 0.9733\n","Epoch 42/100\n","996/996 [==============================] - 9s 9ms/step - loss: 0.2107 - precision: 0.9742 - recall: 0.9710 - auc: 0.9970 - prc: 0.9943 - val_loss: 0.3417 - val_precision: 0.9305 - val_recall: 0.9232 - val_auc: 0.9850 - val_prc: 0.9732\n","Epoch 43/100\n","996/996 [==============================] - 9s 9ms/step - loss: 0.2000 - precision: 0.9767 - recall: 0.9727 - auc: 0.9973 - prc: 0.9950 - val_loss: 0.3528 - val_precision: 0.9326 - val_recall: 0.9220 - val_auc: 0.9828 - val_prc: 0.9683\n","Epoch 44/100\n","996/996 [==============================] - 9s 9ms/step - loss: 0.1936 - precision: 0.9757 - recall: 0.9726 - auc: 0.9975 - prc: 0.9953 - val_loss: 0.3486 - val_precision: 0.9282 - val_recall: 0.9209 - val_auc: 0.9836 - val_prc: 0.9696\n"]}],"source":["model = build_lstm_model(\n","    input_shape = (X_train_strat_vies.shape[1], X_train_strat_vies.shape[2]),\n","    output_shape = 3,\n","    metrics = METRICS\n","    )\n","\n","history = model.fit(x=X_train_strat_vies, y=y_train_strat_vies, \n","                    epochs=100,\n","                    batch_size=8,\n","                    class_weight=class_weight,\n","                    validation_data=(X_val_strat_vies, y_val_strat_vies),\n","                    callbacks=[\n","                        EarlyStopping(monitor='val_prc', patience=10, mode='max', restore_best_weights=True)],\n","                    verbose=True)"]},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","           0       0.88      0.86      0.87       474\n","           1       0.89      0.91      0.90       704\n","           2       0.97      0.97      0.97      1035\n","\n","    accuracy                           0.93      2213\n","   macro avg       0.91      0.91      0.91      2213\n","weighted avg       0.93      0.93      0.93      2213\n","\n"]}],"source":["y_pred_proba = model.predict(X_test_strat_vies, batch_size=8)\n","y_pred = y_pred_proba.argmax(axis =1)\n","print(classification_report(y_test_strat_vies.argmax(axis=1), y_pred))"]},{"cell_type":"markdown","metadata":{},"source":["#### Strat part "]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[],"source":["index_strat_part = eval(indexes.loc[2,'value'])\n","train_strat_part_index, val_strat_part_index,test_strat_part_index  = index_strat_part\n","\n","X_train_strat_part = X[train_strat_part_index]\n","y_train_strat_part = y[train_strat_part_index]\n","\n","X_val_strat_part = X[val_strat_part_index]\n","y_val_strat_part = y[val_strat_part_index]\n","\n","X_test_strat_part = X[test_strat_part_index]\n","y_test_strat_part = y[test_strat_part_index]"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["2023-12-03 15:44:50.199242: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 2446233600 exceeds 10% of free system memory.\n","2023-12-03 15:45:14.086699: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 2446233600 exceeds 10% of free system memory.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 1/100\n"]},{"name":"stderr","output_type":"stream","text":["2023-12-03 15:45:18.574866: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n","2023-12-03 15:45:18.852233: W external/local_tsl/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.82GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n","2023-12-03 15:45:18.878061: W external/local_tsl/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.82GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n","2023-12-03 15:45:20.317746: I external/local_xla/xla/service/service.cc:168] XLA service 0x7fbf486f30d0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n","2023-12-03 15:45:20.317764: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce GTX 1660 Ti, Compute Capability 7.5\n","2023-12-03 15:45:20.337323: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n","WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n","I0000 00:00:1701629120.474309    9971 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"]},{"name":"stdout","output_type":"stream","text":["  6/996 [..............................] - ETA: 10s - loss: 6.4181 - precision: 0.4545 - recall: 0.1042 - auc: 0.4890 - prc: 0.3515            "]},{"name":"stderr","output_type":"stream","text":["2023-12-03 15:45:21.877117: W external/local_tsl/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.06GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n","2023-12-03 15:45:21.877170: W external/local_tsl/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.06GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n","2023-12-03 15:45:21.890876: W external/local_tsl/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.06GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n","2023-12-03 15:45:21.890937: W external/local_tsl/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.06GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n"]},{"name":"stdout","output_type":"stream","text":["996/996 [==============================] - ETA: 0s - loss: 5.3868 - precision: 0.7638 - recall: 0.4211 - auc: 0.8135 - prc: 0.7071"]},{"name":"stderr","output_type":"stream","text":["2023-12-03 15:45:31.886633: W external/local_tsl/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.35GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n","2023-12-03 15:45:31.902570: W external/local_tsl/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.35GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n","2023-12-03 15:45:31.920645: W external/local_tsl/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.06GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n","2023-12-03 15:45:31.928680: W external/local_tsl/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.06GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n","2023-12-03 15:45:34.399739: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 271872000 exceeds 10% of free system memory.\n","2023-12-03 15:45:34.600879: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 271872000 exceeds 10% of free system memory.\n"]},{"name":"stdout","output_type":"stream","text":["996/996 [==============================] - 20s 14ms/step - loss: 5.3868 - precision: 0.7638 - recall: 0.4211 - auc: 0.8135 - prc: 0.7071 - val_loss: 4.4785 - val_precision: 0.8570 - val_recall: 0.7582 - val_auc: 0.9352 - val_prc: 0.8952\n","Epoch 2/100\n","996/996 [==============================] - 10s 11ms/step - loss: 4.0005 - precision: 0.8447 - recall: 0.7844 - auc: 0.9332 - prc: 0.8888 - val_loss: 3.4701 - val_precision: 0.8528 - val_recall: 0.8181 - val_auc: 0.9493 - val_prc: 0.9153\n","Epoch 3/100\n","996/996 [==============================] - 11s 11ms/step - loss: 3.1350 - precision: 0.8617 - recall: 0.8246 - auc: 0.9481 - prc: 0.9132 - val_loss: 2.7476 - val_precision: 0.8634 - val_recall: 0.8215 - val_auc: 0.9574 - val_prc: 0.9287\n","Epoch 4/100\n","996/996 [==============================] - 11s 11ms/step - loss: 2.4961 - precision: 0.8711 - recall: 0.8381 - auc: 0.9564 - prc: 0.9259 - val_loss: 2.1945 - val_precision: 0.8672 - val_recall: 0.8339 - val_auc: 0.9633 - val_prc: 0.9375\n","Epoch 5/100\n","996/996 [==============================] - 10s 10ms/step - loss: 2.0224 - precision: 0.8788 - recall: 0.8526 - auc: 0.9618 - prc: 0.9355 - val_loss: 1.7998 - val_precision: 0.8803 - val_recall: 0.8395 - val_auc: 0.9687 - val_prc: 0.9467\n","Epoch 6/100\n","996/996 [==============================] - 11s 11ms/step - loss: 1.6716 - precision: 0.8860 - recall: 0.8622 - auc: 0.9673 - prc: 0.9443 - val_loss: 1.5022 - val_precision: 0.8910 - val_recall: 0.8588 - val_auc: 0.9726 - val_prc: 0.9529\n","Epoch 7/100\n","996/996 [==============================] - 11s 11ms/step - loss: 1.4248 - precision: 0.8925 - recall: 0.8728 - auc: 0.9707 - prc: 0.9493 - val_loss: 1.3275 - val_precision: 0.8882 - val_recall: 0.8531 - val_auc: 0.9704 - val_prc: 0.9496\n","Epoch 8/100\n","996/996 [==============================] - 11s 11ms/step - loss: 1.2494 - precision: 0.8985 - recall: 0.8787 - auc: 0.9730 - prc: 0.9532 - val_loss: 1.1681 - val_precision: 0.8983 - val_recall: 0.8588 - val_auc: 0.9740 - val_prc: 0.9552\n","Epoch 9/100\n","996/996 [==============================] - 11s 11ms/step - loss: 1.1113 - precision: 0.9064 - recall: 0.8899 - auc: 0.9764 - prc: 0.9590 - val_loss: 1.0538 - val_precision: 0.8942 - val_recall: 0.8689 - val_auc: 0.9765 - val_prc: 0.9591\n","Epoch 10/100\n","996/996 [==============================] - 11s 11ms/step - loss: 1.0236 - precision: 0.9081 - recall: 0.8911 - auc: 0.9757 - prc: 0.9575 - val_loss: 1.0071 - val_precision: 0.8859 - val_recall: 0.8599 - val_auc: 0.9713 - val_prc: 0.9508\n","Epoch 11/100\n","996/996 [==============================] - 11s 11ms/step - loss: 0.9398 - precision: 0.9119 - recall: 0.8965 - auc: 0.9783 - prc: 0.9618 - val_loss: 0.8999 - val_precision: 0.9100 - val_recall: 0.8802 - val_auc: 0.9780 - val_prc: 0.9617\n","Epoch 12/100\n","996/996 [==============================] - 11s 11ms/step - loss: 0.8662 - precision: 0.9138 - recall: 0.8988 - auc: 0.9806 - prc: 0.9661 - val_loss: 0.8504 - val_precision: 0.9096 - val_recall: 0.8757 - val_auc: 0.9773 - val_prc: 0.9594\n","Epoch 13/100\n","996/996 [==============================] - 11s 11ms/step - loss: 0.8101 - precision: 0.9179 - recall: 0.9038 - auc: 0.9820 - prc: 0.9680 - val_loss: 0.8027 - val_precision: 0.9144 - val_recall: 0.8814 - val_auc: 0.9784 - val_prc: 0.9621\n","Epoch 14/100\n","996/996 [==============================] - 11s 11ms/step - loss: 0.7530 - precision: 0.9227 - recall: 0.9078 - auc: 0.9832 - prc: 0.9710 - val_loss: 0.7536 - val_precision: 0.9091 - val_recall: 0.8814 - val_auc: 0.9799 - val_prc: 0.9638\n","Epoch 15/100\n","996/996 [==============================] - 11s 11ms/step - loss: 0.7063 - precision: 0.9246 - recall: 0.9137 - auc: 0.9848 - prc: 0.9732 - val_loss: 0.7263 - val_precision: 0.9057 - val_recall: 0.8791 - val_auc: 0.9787 - val_prc: 0.9627\n","Epoch 16/100\n","996/996 [==============================] - 11s 11ms/step - loss: 0.6598 - precision: 0.9288 - recall: 0.9191 - auc: 0.9863 - prc: 0.9754 - val_loss: 0.6923 - val_precision: 0.9098 - val_recall: 0.8780 - val_auc: 0.9796 - val_prc: 0.9642\n","Epoch 17/100\n","996/996 [==============================] - 11s 11ms/step - loss: 0.6266 - precision: 0.9320 - recall: 0.9201 - auc: 0.9865 - prc: 0.9760 - val_loss: 0.6413 - val_precision: 0.9220 - val_recall: 0.8949 - val_auc: 0.9824 - val_prc: 0.9682\n","Epoch 18/100\n","996/996 [==============================] - 11s 11ms/step - loss: 0.5996 - precision: 0.9284 - recall: 0.9170 - auc: 0.9867 - prc: 0.9762 - val_loss: 0.6223 - val_precision: 0.9189 - val_recall: 0.8836 - val_auc: 0.9809 - val_prc: 0.9660\n","Epoch 19/100\n","996/996 [==============================] - 11s 11ms/step - loss: 0.5542 - precision: 0.9368 - recall: 0.9264 - auc: 0.9890 - prc: 0.9805 - val_loss: 0.6012 - val_precision: 0.9066 - val_recall: 0.8881 - val_auc: 0.9808 - val_prc: 0.9652\n","Epoch 20/100\n","996/996 [==============================] - 10s 10ms/step - loss: 0.5278 - precision: 0.9372 - recall: 0.9273 - auc: 0.9895 - prc: 0.9815 - val_loss: 0.5650 - val_precision: 0.9223 - val_recall: 0.8983 - val_auc: 0.9829 - val_prc: 0.9690\n","Epoch 21/100\n","996/996 [==============================] - 10s 11ms/step - loss: 0.5037 - precision: 0.9393 - recall: 0.9309 - auc: 0.9895 - prc: 0.9816 - val_loss: 0.5485 - val_precision: 0.9136 - val_recall: 0.8960 - val_auc: 0.9824 - val_prc: 0.9684\n","Epoch 22/100\n","996/996 [==============================] - 10s 11ms/step - loss: 0.4770 - precision: 0.9435 - recall: 0.9339 - auc: 0.9906 - prc: 0.9834 - val_loss: 0.5271 - val_precision: 0.9167 - val_recall: 0.8949 - val_auc: 0.9828 - val_prc: 0.9694\n","Epoch 23/100\n","996/996 [==============================] - 11s 11ms/step - loss: 0.4539 - precision: 0.9456 - recall: 0.9386 - auc: 0.9913 - prc: 0.9845 - val_loss: 0.5209 - val_precision: 0.9104 - val_recall: 0.8960 - val_auc: 0.9820 - val_prc: 0.9675\n","Epoch 24/100\n","996/996 [==============================] - 11s 11ms/step - loss: 0.4291 - precision: 0.9493 - recall: 0.9414 - auc: 0.9924 - prc: 0.9862 - val_loss: 0.4879 - val_precision: 0.9236 - val_recall: 0.9017 - val_auc: 0.9844 - val_prc: 0.9719\n","Epoch 25/100\n","996/996 [==============================] - 11s 11ms/step - loss: 0.4061 - precision: 0.9518 - recall: 0.9447 - auc: 0.9922 - prc: 0.9867 - val_loss: 0.4778 - val_precision: 0.9172 - val_recall: 0.9017 - val_auc: 0.9837 - val_prc: 0.9708\n","Epoch 26/100\n","996/996 [==============================] - 11s 11ms/step - loss: 0.3924 - precision: 0.9478 - recall: 0.9417 - auc: 0.9926 - prc: 0.9867 - val_loss: 0.4592 - val_precision: 0.9228 - val_recall: 0.9051 - val_auc: 0.9843 - val_prc: 0.9722\n","Epoch 27/100\n","996/996 [==============================] - 11s 11ms/step - loss: 0.3728 - precision: 0.9523 - recall: 0.9468 - auc: 0.9934 - prc: 0.9881 - val_loss: 0.4515 - val_precision: 0.9217 - val_recall: 0.9051 - val_auc: 0.9841 - val_prc: 0.9717\n","Epoch 28/100\n","996/996 [==============================] - 10s 10ms/step - loss: 0.3603 - precision: 0.9546 - recall: 0.9485 - auc: 0.9935 - prc: 0.9881 - val_loss: 0.4346 - val_precision: 0.9274 - val_recall: 0.9096 - val_auc: 0.9846 - val_prc: 0.9734\n","Epoch 29/100\n","996/996 [==============================] - 11s 11ms/step - loss: 0.3346 - precision: 0.9581 - recall: 0.9540 - auc: 0.9951 - prc: 0.9912 - val_loss: 0.4369 - val_precision: 0.9144 - val_recall: 0.9051 - val_auc: 0.9836 - val_prc: 0.9708\n","Epoch 30/100\n","996/996 [==============================] - 11s 11ms/step - loss: 0.3290 - precision: 0.9576 - recall: 0.9524 - auc: 0.9944 - prc: 0.9903 - val_loss: 0.4200 - val_precision: 0.9222 - val_recall: 0.9107 - val_auc: 0.9846 - val_prc: 0.9729\n","Epoch 31/100\n","996/996 [==============================] - 11s 11ms/step - loss: 0.3060 - precision: 0.9615 - recall: 0.9565 - auc: 0.9956 - prc: 0.9921 - val_loss: 0.4164 - val_precision: 0.9232 - val_recall: 0.9096 - val_auc: 0.9838 - val_prc: 0.9720\n","Epoch 32/100\n","996/996 [==============================] - 11s 11ms/step - loss: 0.2992 - precision: 0.9618 - recall: 0.9591 - auc: 0.9953 - prc: 0.9913 - val_loss: 0.4143 - val_precision: 0.9164 - val_recall: 0.9040 - val_auc: 0.9836 - val_prc: 0.9710\n","Epoch 33/100\n","996/996 [==============================] - 11s 11ms/step - loss: 0.2809 - precision: 0.9657 - recall: 0.9621 - auc: 0.9963 - prc: 0.9931 - val_loss: 0.4020 - val_precision: 0.9211 - val_recall: 0.9096 - val_auc: 0.9849 - val_prc: 0.9736\n","Epoch 34/100\n","996/996 [==============================] - 10s 10ms/step - loss: 0.2797 - precision: 0.9642 - recall: 0.9603 - auc: 0.9960 - prc: 0.9925 - val_loss: 0.4015 - val_precision: 0.9219 - val_recall: 0.9073 - val_auc: 0.9837 - val_prc: 0.9711\n","Epoch 35/100\n","996/996 [==============================] - 10s 11ms/step - loss: 0.2667 - precision: 0.9681 - recall: 0.9647 - auc: 0.9961 - prc: 0.9928 - val_loss: 0.3877 - val_precision: 0.9211 - val_recall: 0.9107 - val_auc: 0.9841 - val_prc: 0.9725\n","Epoch 36/100\n","996/996 [==============================] - 10s 11ms/step - loss: 0.2509 - precision: 0.9708 - recall: 0.9680 - auc: 0.9967 - prc: 0.9940 - val_loss: 0.3947 - val_precision: 0.9190 - val_recall: 0.9107 - val_auc: 0.9834 - val_prc: 0.9695\n","Epoch 37/100\n","996/996 [==============================] - 10s 11ms/step - loss: 0.2408 - precision: 0.9724 - recall: 0.9694 - auc: 0.9969 - prc: 0.9943 - val_loss: 0.3869 - val_precision: 0.9281 - val_recall: 0.9186 - val_auc: 0.9826 - val_prc: 0.9702\n","Epoch 38/100\n","996/996 [==============================] - 10s 11ms/step - loss: 0.2347 - precision: 0.9714 - recall: 0.9686 - auc: 0.9966 - prc: 0.9939 - val_loss: 0.3728 - val_precision: 0.9269 - val_recall: 0.9164 - val_auc: 0.9838 - val_prc: 0.9725\n","Epoch 39/100\n","996/996 [==============================] - 10s 11ms/step - loss: 0.2274 - precision: 0.9704 - recall: 0.9667 - auc: 0.9974 - prc: 0.9953 - val_loss: 0.3779 - val_precision: 0.9224 - val_recall: 0.9130 - val_auc: 0.9828 - val_prc: 0.9698\n","Epoch 40/100\n","996/996 [==============================] - 10s 11ms/step - loss: 0.2201 - precision: 0.9738 - recall: 0.9717 - auc: 0.9973 - prc: 0.9950 - val_loss: 0.3719 - val_precision: 0.9214 - val_recall: 0.9141 - val_auc: 0.9834 - val_prc: 0.9701\n","Epoch 41/100\n","996/996 [==============================] - 11s 11ms/step - loss: 0.2086 - precision: 0.9748 - recall: 0.9725 - auc: 0.9977 - prc: 0.9956 - val_loss: 0.3686 - val_precision: 0.9244 - val_recall: 0.9119 - val_auc: 0.9834 - val_prc: 0.9716\n","Epoch 42/100\n","996/996 [==============================] - 11s 11ms/step - loss: 0.2051 - precision: 0.9756 - recall: 0.9730 - auc: 0.9975 - prc: 0.9954 - val_loss: 0.3981 - val_precision: 0.9135 - val_recall: 0.9073 - val_auc: 0.9790 - val_prc: 0.9644\n","Epoch 43/100\n","996/996 [==============================] - 11s 11ms/step - loss: 0.1948 - precision: 0.9756 - recall: 0.9731 - auc: 0.9979 - prc: 0.9963 - val_loss: 0.3737 - val_precision: 0.9159 - val_recall: 0.9107 - val_auc: 0.9820 - val_prc: 0.9668\n"]}],"source":["model = build_lstm_model(\n","    input_shape = (X_train_strat_part.shape[1], X_train_strat_part.shape[2]),\n","    output_shape = 3,\n","    metrics = METRICS\n","    )\n","\n","history = model.fit(x=X_train_strat_part, y=y_train_strat_part, \n","                    epochs=100,\n","                    batch_size=8,\n","                    class_weight=class_weight,\n","                    validation_data=(X_val_strat_part, y_val_strat_part),\n","                    callbacks=[\n","                        EarlyStopping(monitor='val_prc', patience=10, mode='max', restore_best_weights=True)],\n","                    verbose=True)"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["2023-12-03 15:53:18.285178: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 679833600 exceeds 10% of free system memory.\n"]},{"name":"stdout","output_type":"stream","text":["277/277 [==============================] - 2s 4ms/step\n","              precision    recall  f1-score   support\n","\n","           0       0.87      0.86      0.86       474\n","           1       0.88      0.90      0.89       705\n","           2       0.97      0.96      0.97      1034\n","\n","    accuracy                           0.92      2213\n","   macro avg       0.91      0.91      0.91      2213\n","weighted avg       0.92      0.92      0.92      2213\n","\n"]}],"source":["y_pred_proba = model.predict(X_test_strat_part, batch_size=8)\n","y_pred = y_pred_proba.argmax(axis =1)\n","print(classification_report(y_test_strat_part.argmax(axis=1), y_pred))"]},{"cell_type":"markdown","metadata":{},"source":["#### Part novos "]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[],"source":["index_part_novos = eval(indexes.loc[3,'value'])\n","train_part_novos_index, val_part_novos_index, test_part_novos_index = index_part_novos\n","\n","X_train_part_novos = X[train_part_novos_index]\n","y_train_part_novos = y[train_part_novos_index]\n","\n","X_val_part_novos = X[val_part_novos_index]\n","y_val_part_novos = y[val_part_novos_index]\n","\n","X_test_part_novos = X[test_part_novos_index]\n","y_test_part_novos = y[test_part_novos_index]"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[{"data":{"text/plain":["2    1161\n","1     814\n","0     622\n","Name: count, dtype: int64"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["pd.DataFrame(y_test_part_novos.argmax(axis = 1)).value_counts()"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["2023-12-03 16:31:45.203039: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 2339942400 exceeds 10% of free system memory.\n","2023-12-03 16:32:03.023255: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 2339942400 exceeds 10% of free system memory.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 1/100\n"]},{"name":"stderr","output_type":"stream","text":["2023-12-03 16:32:07.200349: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n","2023-12-03 16:32:07.482764: W external/local_tsl/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.82GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n","2023-12-03 16:32:07.508374: W external/local_tsl/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.82GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n","2023-12-03 16:32:08.921606: I external/local_xla/xla/service/service.cc:168] XLA service 0x7f27a815b820 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n","2023-12-03 16:32:08.921660: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce GTX 1660 Ti, Compute Capability 7.5\n","2023-12-03 16:32:08.945723: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n","WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n","I0000 00:00:1701631929.087471    4597 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"]},{"name":"stdout","output_type":"stream","text":["  6/953 [..............................] - ETA: 10s - loss: 6.3140 - precision: 0.6667 - recall: 0.0833 - auc: 0.5664 - prc: 0.4170            "]},{"name":"stderr","output_type":"stream","text":["2023-12-03 16:32:10.463034: W external/local_tsl/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.06GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n","2023-12-03 16:32:10.463081: W external/local_tsl/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.06GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n","2023-12-03 16:32:10.476504: W external/local_tsl/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.06GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n","2023-12-03 16:32:10.476548: W external/local_tsl/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.06GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n"]},{"name":"stdout","output_type":"stream","text":["953/953 [==============================] - ETA: 0s - loss: 5.4411 - precision: 0.7611 - recall: 0.3379 - auc: 0.7941 - prc: 0.6815"]},{"name":"stderr","output_type":"stream","text":["2023-12-03 16:32:19.964141: W external/local_tsl/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.16GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n","2023-12-03 16:32:19.976894: W external/local_tsl/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.16GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n","2023-12-03 16:32:20.006733: W external/local_tsl/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.06GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n","2023-12-03 16:32:20.014635: W external/local_tsl/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.06GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n","2023-12-03 16:32:22.164259: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 260198400 exceeds 10% of free system memory.\n","2023-12-03 16:32:22.359299: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 260198400 exceeds 10% of free system memory.\n"]},{"name":"stdout","output_type":"stream","text":["953/953 [==============================] - 19s 14ms/step - loss: 5.4411 - precision: 0.7611 - recall: 0.3379 - auc: 0.7941 - prc: 0.6815 - val_loss: 4.5265 - val_precision: 0.8934 - val_recall: 0.7521 - val_auc: 0.9481 - val_prc: 0.9181\n","Epoch 2/100\n","953/953 [==============================] - 10s 10ms/step - loss: 4.0489 - precision: 0.8220 - recall: 0.7491 - auc: 0.9282 - prc: 0.8798 - val_loss: 3.4740 - val_precision: 0.8702 - val_recall: 0.8312 - val_auc: 0.9595 - val_prc: 0.9347\n","Epoch 3/100\n","953/953 [==============================] - 10s 10ms/step - loss: 3.1645 - precision: 0.8499 - recall: 0.8153 - auc: 0.9483 - prc: 0.9119 - val_loss: 2.7581 - val_precision: 0.8735 - val_recall: 0.8394 - val_auc: 0.9643 - val_prc: 0.9413\n","Epoch 4/100\n","953/953 [==============================] - 10s 10ms/step - loss: 2.5301 - precision: 0.8651 - recall: 0.8368 - auc: 0.9570 - prc: 0.9272 - val_loss: 2.2133 - val_precision: 0.8954 - val_recall: 0.8595 - val_auc: 0.9715 - val_prc: 0.9517\n","Epoch 5/100\n","953/953 [==============================] - 10s 10ms/step - loss: 2.0573 - precision: 0.8774 - recall: 0.8524 - auc: 0.9641 - prc: 0.9393 - val_loss: 1.7996 - val_precision: 0.9045 - val_recall: 0.8831 - val_auc: 0.9775 - val_prc: 0.9625\n","Epoch 6/100\n","953/953 [==============================] - 10s 10ms/step - loss: 1.7050 - precision: 0.8933 - recall: 0.8745 - auc: 0.9695 - prc: 0.9478 - val_loss: 1.5240 - val_precision: 0.9117 - val_recall: 0.8902 - val_auc: 0.9789 - val_prc: 0.9647\n","Epoch 7/100\n","953/953 [==============================] - 10s 10ms/step - loss: 1.4573 - precision: 0.9013 - recall: 0.8804 - auc: 0.9722 - prc: 0.9518 - val_loss: 1.3127 - val_precision: 0.9097 - val_recall: 0.8926 - val_auc: 0.9801 - val_prc: 0.9663\n","Epoch 8/100\n","953/953 [==============================] - 10s 10ms/step - loss: 1.2726 - precision: 0.9028 - recall: 0.8866 - auc: 0.9747 - prc: 0.9564 - val_loss: 1.1573 - val_precision: 0.9113 - val_recall: 0.8973 - val_auc: 0.9823 - val_prc: 0.9701\n","Epoch 9/100\n","953/953 [==============================] - 10s 10ms/step - loss: 1.1238 - precision: 0.9133 - recall: 0.8976 - auc: 0.9787 - prc: 0.9630 - val_loss: 1.0433 - val_precision: 0.9122 - val_recall: 0.8949 - val_auc: 0.9828 - val_prc: 0.9713\n","Epoch 10/100\n","953/953 [==============================] - 10s 10ms/step - loss: 1.0130 - precision: 0.9157 - recall: 0.9010 - auc: 0.9806 - prc: 0.9655 - val_loss: 0.9545 - val_precision: 0.9212 - val_recall: 0.8973 - val_auc: 0.9832 - val_prc: 0.9717\n","Epoch 11/100\n","953/953 [==============================] - 10s 10ms/step - loss: 0.9194 - precision: 0.9210 - recall: 0.9089 - auc: 0.9831 - prc: 0.9701 - val_loss: 0.8809 - val_precision: 0.9168 - val_recall: 0.8973 - val_auc: 0.9834 - val_prc: 0.9724\n","Epoch 12/100\n","953/953 [==============================] - 10s 10ms/step - loss: 0.8489 - precision: 0.9257 - recall: 0.9131 - auc: 0.9837 - prc: 0.9714 - val_loss: 0.7959 - val_precision: 0.9315 - val_recall: 0.9150 - val_auc: 0.9876 - val_prc: 0.9789\n","Epoch 13/100\n","953/953 [==============================] - 10s 10ms/step - loss: 0.7750 - precision: 0.9321 - recall: 0.9212 - auc: 0.9863 - prc: 0.9759 - val_loss: 0.7533 - val_precision: 0.9168 - val_recall: 0.9103 - val_auc: 0.9858 - val_prc: 0.9761\n","Epoch 14/100\n","953/953 [==============================] - 10s 10ms/step - loss: 0.7240 - precision: 0.9328 - recall: 0.9227 - auc: 0.9868 - prc: 0.9770 - val_loss: 0.7132 - val_precision: 0.9257 - val_recall: 0.9126 - val_auc: 0.9860 - val_prc: 0.9768\n","Epoch 15/100\n","953/953 [==============================] - 10s 10ms/step - loss: 0.6755 - precision: 0.9376 - recall: 0.9299 - auc: 0.9878 - prc: 0.9786 - val_loss: 0.6545 - val_precision: 0.9305 - val_recall: 0.9162 - val_auc: 0.9887 - val_prc: 0.9807\n","Epoch 16/100\n","953/953 [==============================] - 10s 10ms/step - loss: 0.6291 - precision: 0.9433 - recall: 0.9341 - auc: 0.9891 - prc: 0.9813 - val_loss: 0.6053 - val_precision: 0.9368 - val_recall: 0.9280 - val_auc: 0.9901 - val_prc: 0.9827\n","Epoch 17/100\n","953/953 [==============================] - 10s 10ms/step - loss: 0.5815 - precision: 0.9481 - recall: 0.9416 - auc: 0.9907 - prc: 0.9842 - val_loss: 0.5753 - val_precision: 0.9356 - val_recall: 0.9256 - val_auc: 0.9902 - val_prc: 0.9832\n","Epoch 18/100\n","953/953 [==============================] - 10s 10ms/step - loss: 0.5511 - precision: 0.9454 - recall: 0.9386 - auc: 0.9909 - prc: 0.9840 - val_loss: 0.5601 - val_precision: 0.9271 - val_recall: 0.9162 - val_auc: 0.9890 - val_prc: 0.9810\n","Epoch 19/100\n","953/953 [==============================] - 10s 10ms/step - loss: 0.5134 - precision: 0.9507 - recall: 0.9437 - auc: 0.9917 - prc: 0.9857 - val_loss: 0.5256 - val_precision: 0.9353 - val_recall: 0.9221 - val_auc: 0.9900 - val_prc: 0.9828\n","Epoch 20/100\n","953/953 [==============================] - 10s 10ms/step - loss: 0.4860 - precision: 0.9528 - recall: 0.9456 - auc: 0.9921 - prc: 0.9859 - val_loss: 0.4926 - val_precision: 0.9347 - val_recall: 0.9292 - val_auc: 0.9910 - val_prc: 0.9842\n","Epoch 21/100\n","953/953 [==============================] - 10s 10ms/step - loss: 0.4532 - precision: 0.9563 - recall: 0.9491 - auc: 0.9928 - prc: 0.9881 - val_loss: 0.4740 - val_precision: 0.9403 - val_recall: 0.9292 - val_auc: 0.9907 - val_prc: 0.9837\n","Epoch 22/100\n","953/953 [==============================] - 10s 10ms/step - loss: 0.4397 - precision: 0.9535 - recall: 0.9450 - auc: 0.9930 - prc: 0.9875 - val_loss: 0.4431 - val_precision: 0.9395 - val_recall: 0.9351 - val_auc: 0.9922 - val_prc: 0.9863\n","Epoch 23/100\n","953/953 [==============================] - 10s 10ms/step - loss: 0.4095 - precision: 0.9567 - recall: 0.9516 - auc: 0.9944 - prc: 0.9902 - val_loss: 0.4259 - val_precision: 0.9429 - val_recall: 0.9351 - val_auc: 0.9923 - val_prc: 0.9865\n","Epoch 24/100\n","953/953 [==============================] - 10s 10ms/step - loss: 0.3772 - precision: 0.9636 - recall: 0.9589 - auc: 0.9950 - prc: 0.9917 - val_loss: 0.4380 - val_precision: 0.9274 - val_recall: 0.9197 - val_auc: 0.9898 - val_prc: 0.9822\n","Epoch 25/100\n","953/953 [==============================] - 10s 10ms/step - loss: 0.3669 - precision: 0.9624 - recall: 0.9579 - auc: 0.9947 - prc: 0.9904 - val_loss: 0.3924 - val_precision: 0.9430 - val_recall: 0.9374 - val_auc: 0.9929 - val_prc: 0.9873\n","Epoch 26/100\n","953/953 [==============================] - 10s 10ms/step - loss: 0.3456 - precision: 0.9643 - recall: 0.9602 - auc: 0.9959 - prc: 0.9927 - val_loss: 0.3815 - val_precision: 0.9405 - val_recall: 0.9339 - val_auc: 0.9926 - val_prc: 0.9871\n","Epoch 27/100\n","953/953 [==============================] - 10s 10ms/step - loss: 0.3214 - precision: 0.9671 - recall: 0.9622 - auc: 0.9963 - prc: 0.9932 - val_loss: 0.3886 - val_precision: 0.9347 - val_recall: 0.9292 - val_auc: 0.9911 - val_prc: 0.9843\n","Epoch 28/100\n","953/953 [==============================] - 10s 10ms/step - loss: 0.3053 - precision: 0.9704 - recall: 0.9655 - auc: 0.9967 - prc: 0.9939 - val_loss: 0.3581 - val_precision: 0.9407 - val_recall: 0.9362 - val_auc: 0.9926 - val_prc: 0.9875\n","Epoch 29/100\n","953/953 [==============================] - 10s 10ms/step - loss: 0.2999 - precision: 0.9677 - recall: 0.9630 - auc: 0.9962 - prc: 0.9933 - val_loss: 0.3504 - val_precision: 0.9429 - val_recall: 0.9351 - val_auc: 0.9922 - val_prc: 0.9867\n","Epoch 30/100\n","953/953 [==============================] - 10s 10ms/step - loss: 0.2782 - precision: 0.9735 - recall: 0.9691 - auc: 0.9973 - prc: 0.9951 - val_loss: 0.3348 - val_precision: 0.9370 - val_recall: 0.9303 - val_auc: 0.9934 - val_prc: 0.9881\n","Epoch 31/100\n","953/953 [==============================] - 10s 10ms/step - loss: 0.2694 - precision: 0.9719 - recall: 0.9677 - auc: 0.9970 - prc: 0.9948 - val_loss: 0.3354 - val_precision: 0.9405 - val_recall: 0.9339 - val_auc: 0.9924 - val_prc: 0.9867\n","Epoch 32/100\n","953/953 [==============================] - 10s 10ms/step - loss: 0.2549 - precision: 0.9758 - recall: 0.9723 - auc: 0.9977 - prc: 0.9958 - val_loss: 0.3226 - val_precision: 0.9426 - val_recall: 0.9303 - val_auc: 0.9929 - val_prc: 0.9876\n","Epoch 33/100\n","953/953 [==============================] - 10s 10ms/step - loss: 0.2528 - precision: 0.9722 - recall: 0.9677 - auc: 0.9976 - prc: 0.9955 - val_loss: 0.3124 - val_precision: 0.9498 - val_recall: 0.9386 - val_auc: 0.9935 - val_prc: 0.9883\n","Epoch 34/100\n","953/953 [==============================] - 10s 10ms/step - loss: 0.2403 - precision: 0.9755 - recall: 0.9723 - auc: 0.9975 - prc: 0.9955 - val_loss: 0.2980 - val_precision: 0.9466 - val_recall: 0.9410 - val_auc: 0.9942 - val_prc: 0.9895\n","Epoch 35/100\n","953/953 [==============================] - 10s 10ms/step - loss: 0.2253 - precision: 0.9755 - recall: 0.9724 - auc: 0.9978 - prc: 0.9958 - val_loss: 0.2938 - val_precision: 0.9453 - val_recall: 0.9386 - val_auc: 0.9936 - val_prc: 0.9880\n","Epoch 36/100\n","953/953 [==============================] - 10s 10ms/step - loss: 0.2259 - precision: 0.9753 - recall: 0.9735 - auc: 0.9979 - prc: 0.9962 - val_loss: 0.2861 - val_precision: 0.9442 - val_recall: 0.9398 - val_auc: 0.9943 - val_prc: 0.9897\n","Epoch 37/100\n","953/953 [==============================] - 10s 10ms/step - loss: 0.2146 - precision: 0.9777 - recall: 0.9748 - auc: 0.9982 - prc: 0.9966 - val_loss: 0.2823 - val_precision: 0.9431 - val_recall: 0.9398 - val_auc: 0.9939 - val_prc: 0.9894\n","Epoch 38/100\n","953/953 [==============================] - 10s 10ms/step - loss: 0.2042 - precision: 0.9788 - recall: 0.9754 - auc: 0.9982 - prc: 0.9966 - val_loss: 0.2801 - val_precision: 0.9419 - val_recall: 0.9374 - val_auc: 0.9928 - val_prc: 0.9870\n","Epoch 39/100\n","953/953 [==============================] - 10s 10ms/step - loss: 0.1911 - precision: 0.9822 - recall: 0.9800 - auc: 0.9982 - prc: 0.9967 - val_loss: 0.2775 - val_precision: 0.9409 - val_recall: 0.9398 - val_auc: 0.9927 - val_prc: 0.9869\n","Epoch 40/100\n","953/953 [==============================] - 10s 10ms/step - loss: 0.1881 - precision: 0.9817 - recall: 0.9804 - auc: 0.9985 - prc: 0.9971 - val_loss: 0.2803 - val_precision: 0.9455 - val_recall: 0.9421 - val_auc: 0.9933 - val_prc: 0.9876\n","Epoch 41/100\n","953/953 [==============================] - 10s 10ms/step - loss: 0.1790 - precision: 0.9828 - recall: 0.9807 - auc: 0.9990 - prc: 0.9980 - val_loss: 0.2501 - val_precision: 0.9501 - val_recall: 0.9433 - val_auc: 0.9948 - val_prc: 0.9902\n","Epoch 42/100\n","953/953 [==============================] - 10s 10ms/step - loss: 0.1727 - precision: 0.9826 - recall: 0.9814 - auc: 0.9987 - prc: 0.9976 - val_loss: 0.2570 - val_precision: 0.9524 - val_recall: 0.9457 - val_auc: 0.9934 - val_prc: 0.9888\n","Epoch 43/100\n","953/953 [==============================] - 10s 10ms/step - loss: 0.1676 - precision: 0.9838 - recall: 0.9821 - auc: 0.9989 - prc: 0.9981 - val_loss: 0.2798 - val_precision: 0.9407 - val_recall: 0.9362 - val_auc: 0.9920 - val_prc: 0.9854\n","Epoch 44/100\n","953/953 [==============================] - 10s 10ms/step - loss: 0.1652 - precision: 0.9847 - recall: 0.9825 - auc: 0.9984 - prc: 0.9970 - val_loss: 0.2545 - val_precision: 0.9454 - val_recall: 0.9410 - val_auc: 0.9930 - val_prc: 0.9874\n","Epoch 45/100\n","953/953 [==============================] - 10s 10ms/step - loss: 0.1586 - precision: 0.9838 - recall: 0.9816 - auc: 0.9989 - prc: 0.9980 - val_loss: 0.2403 - val_precision: 0.9433 - val_recall: 0.9421 - val_auc: 0.9941 - val_prc: 0.9887\n","Epoch 46/100\n","953/953 [==============================] - 10s 10ms/step - loss: 0.1562 - precision: 0.9854 - recall: 0.9835 - auc: 0.9987 - prc: 0.9976 - val_loss: 0.2487 - val_precision: 0.9454 - val_recall: 0.9410 - val_auc: 0.9939 - val_prc: 0.9892\n","Epoch 47/100\n","953/953 [==============================] - 10s 10ms/step - loss: 0.1494 - precision: 0.9867 - recall: 0.9850 - auc: 0.9989 - prc: 0.9979 - val_loss: 0.2310 - val_precision: 0.9512 - val_recall: 0.9445 - val_auc: 0.9947 - val_prc: 0.9905\n","Epoch 48/100\n","953/953 [==============================] - 10s 10ms/step - loss: 0.1395 - precision: 0.9867 - recall: 0.9850 - auc: 0.9994 - prc: 0.9988 - val_loss: 0.2412 - val_precision: 0.9514 - val_recall: 0.9481 - val_auc: 0.9937 - val_prc: 0.9886\n","Epoch 49/100\n","953/953 [==============================] - 10s 10ms/step - loss: 0.1383 - precision: 0.9888 - recall: 0.9877 - auc: 0.9991 - prc: 0.9982 - val_loss: 0.2439 - val_precision: 0.9479 - val_recall: 0.9445 - val_auc: 0.9927 - val_prc: 0.9872\n","Epoch 50/100\n","953/953 [==============================] - 10s 10ms/step - loss: 0.1315 - precision: 0.9878 - recall: 0.9866 - auc: 0.9994 - prc: 0.9990 - val_loss: 0.2522 - val_precision: 0.9467 - val_recall: 0.9433 - val_auc: 0.9915 - val_prc: 0.9863\n","Epoch 51/100\n","953/953 [==============================] - 10s 10ms/step - loss: 0.1352 - precision: 0.9866 - recall: 0.9858 - auc: 0.9989 - prc: 0.9980 - val_loss: 0.2343 - val_precision: 0.9479 - val_recall: 0.9457 - val_auc: 0.9930 - val_prc: 0.9880\n","Epoch 52/100\n","953/953 [==============================] - 10s 10ms/step - loss: 0.1256 - precision: 0.9899 - recall: 0.9891 - auc: 0.9994 - prc: 0.9987 - val_loss: 0.2461 - val_precision: 0.9502 - val_recall: 0.9469 - val_auc: 0.9922 - val_prc: 0.9865\n","Epoch 53/100\n","953/953 [==============================] - 10s 10ms/step - loss: 0.1229 - precision: 0.9897 - recall: 0.9886 - auc: 0.9996 - prc: 0.9994 - val_loss: 0.2278 - val_precision: 0.9491 - val_recall: 0.9457 - val_auc: 0.9934 - val_prc: 0.9887\n","Epoch 54/100\n","953/953 [==============================] - 10s 10ms/step - loss: 0.1219 - precision: 0.9892 - recall: 0.9878 - auc: 0.9992 - prc: 0.9985 - val_loss: 0.2619 - val_precision: 0.9396 - val_recall: 0.9362 - val_auc: 0.9913 - val_prc: 0.9841\n","Epoch 55/100\n","953/953 [==============================] - 10s 10ms/step - loss: 0.1160 - precision: 0.9913 - recall: 0.9907 - auc: 0.9994 - prc: 0.9989 - val_loss: 0.2852 - val_precision: 0.9469 - val_recall: 0.9469 - val_auc: 0.9862 - val_prc: 0.9744\n","Epoch 56/100\n","953/953 [==============================] - 10s 10ms/step - loss: 0.1129 - precision: 0.9907 - recall: 0.9896 - auc: 0.9995 - prc: 0.9991 - val_loss: 0.2110 - val_precision: 0.9536 - val_recall: 0.9469 - val_auc: 0.9943 - val_prc: 0.9897\n","Epoch 57/100\n","953/953 [==============================] - 10s 10ms/step - loss: 0.1132 - precision: 0.9904 - recall: 0.9896 - auc: 0.9993 - prc: 0.9988 - val_loss: 0.2121 - val_precision: 0.9504 - val_recall: 0.9492 - val_auc: 0.9942 - val_prc: 0.9894\n"]}],"source":["model = build_lstm_model(\n","    input_shape = (X_train_part_novos.shape[1], X_train_part_novos.shape[2]),\n","    output_shape = 3,\n","    metrics = METRICS\n","    )\n","\n","history = model.fit(x=X_train_part_novos, y=y_train_part_novos, \n","                    epochs=100,\n","                    batch_size=8,\n","                    class_weight=class_weight,\n","                    validation_data=(X_val_part_novos, y_val_part_novos),\n","                    callbacks=[\n","                        EarlyStopping(monitor='val_prc', patience=10, mode='max', restore_best_weights=True)],\n","                    verbose=True)"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["2023-12-03 16:42:39.315374: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 797798400 exceeds 10% of free system memory.\n"]},{"name":"stdout","output_type":"stream","text":["325/325 [==============================] - 2s 4ms/step\n","              precision    recall  f1-score   support\n","\n","           0       0.51      0.60      0.55       622\n","           1       0.63      0.54      0.58       814\n","           2       0.92      0.93      0.93      1161\n","\n","    accuracy                           0.73      2597\n","   macro avg       0.69      0.69      0.69      2597\n","weighted avg       0.73      0.73      0.73      2597\n","\n"]}],"source":["y_pred_proba = model.predict(X_test_part_novos, batch_size=8)\n","y_pred = y_pred_proba.argmax(axis =1)\n","print(classification_report(y_test_part_novos.argmax(axis=1), y_pred))"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":4}
