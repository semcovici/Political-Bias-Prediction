{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/semcovici/projetos_pesquisa/Political-Bias-Prediction/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer  # Or BertTokenizer\n",
    "from transformers import AutoTokenizer  # Or BertTokenizer\n",
    "from transformers import BertModel\n",
    "import torch\n",
    "import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 100\n",
    "# Data Paths\n",
    "data_input_path = '../../dataset/processed/artigos_tratados/artigos_tratados.parquet'\n",
    "data_output_path = f'../../dataset/processed/artigos_tratados/bertimbau/bertimbau_full__max_lenght={max_length}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start of Embedding. Datetime: 2023-12-03 00:20:52.810226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Batches: 100%|██████████| 176/176 [17:53<00:00,  6.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of Embedding. Datetime: 2023-12-03 00:38:46.381177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer, BertModel\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "\n",
    "# Auxiliary Functions\n",
    "def bert_text_preparation_batch(texts, tokenizer):\n",
    "    marked_texts = [\"[CLS] \" + t + \" [SEP]\" for t in texts]\n",
    "    tokenized_texts = tokenizer.batch_encode_plus(marked_texts, truncation=True, max_length=max_length, padding='max_length', return_tensors='pt', return_attention_mask=True)\n",
    "    return tokenized_texts\n",
    "\n",
    "def get_bert_embeddings_batch(tokens_tensors, attention_mask, model):\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids=tokens_tensors, attention_mask=attention_mask)\n",
    "        hidden_states = outputs[2][1:]\n",
    "\n",
    "    token_embeddings = hidden_states[-1]\n",
    "    token_embeddings = torch.squeeze(token_embeddings, dim=0)\n",
    "    return token_embeddings.tolist()\n",
    "\n",
    "# Import Models\n",
    "tokenizer = AutoTokenizer.from_pretrained('neuralmind/bert-base-portuguese-cased', do_lower_case=True)\n",
    "model = BertModel.from_pretrained('neuralmind/bert-base-portuguese-cased', output_hidden_states=True)\n",
    "\n",
    "# Get Data\n",
    "data = pd.read_parquet(data_input_path)\n",
    "data_bert = data.copy()\n",
    "emb_vector = []\n",
    "\n",
    "# Parameters for Batch Processing\n",
    "batch_size = 64\n",
    "num_batches = (len(data_bert) + batch_size - 1) // batch_size\n",
    "\n",
    "# Processing in Batches with tqdm\n",
    "print(f'Start of Embedding. Datetime: {datetime.datetime.today()}')\n",
    "for batch_num in tqdm(range(num_batches), desc=\"Processing Batches\"):\n",
    "    start_idx = batch_num * batch_size\n",
    "    end_idx = min((batch_num + 1) * batch_size, len(data_bert))\n",
    "    \n",
    "    batch_data = data_bert.iloc[start_idx:end_idx]\n",
    "    texts = batch_data['Conteudo'].tolist()\n",
    "    \n",
    "    tokenized_texts = bert_text_preparation_batch(texts, tokenizer)\n",
    "    tokens_tensor = tokenized_texts['input_ids']\n",
    "    attention_mask = tokenized_texts['attention_mask']\n",
    "\n",
    "    del tokenized_texts\n",
    "\n",
    "    list_token_embeddings = get_bert_embeddings_batch(tokens_tensor, attention_mask, model)\n",
    "    \n",
    "    list_token_embeddings = np.array(list_token_embeddings)\n",
    "        \n",
    "    if len(emb_vector) == 0:\n",
    "        emb_vector = list_token_embeddings\n",
    "    else:\n",
    "        emb_vector = np.concatenate([emb_vector, list_token_embeddings])\n",
    "        \n",
    "    del list_token_embeddings, tokens_tensor, attention_mask\n",
    "\n",
    "print(f'End of Embedding. Datetime: {datetime.datetime.today()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(data_output_path, emb_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11241, 100, 768)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 100, 768)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_token_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'list_token_embeddings' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/semcovici/projetos_pesquisa/Political-Bias-Prediction/src/features/bertimbau_embedding_full.ipynb Cell 3\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/semcovici/projetos_pesquisa/Political-Bias-Prediction/src/features/bertimbau_embedding_full.ipynb#X12sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m list_token_embeddings\n",
      "\u001b[0;31mNameError\u001b[0m: name 'list_token_embeddings' is not defined"
     ]
    }
   ],
   "source": [
    "list_token_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9, 8, 100, 768)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "96"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################ Data Path #################################\n",
    "data_input_path = '../../dataset/processed/artigos_tratados/artigos_tratados.parquet'\n",
    "data_output_path = '../../dataset/processed/artigos_tratados/bertimbau/bertimbau_full_parts/'\n",
    "max_length = 150\n",
    "############################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################ Aux Functions #############################\n",
    "\"\"\"\n",
    "ref: https://towardsdatascience.com/3-types-of-contextualized-word-embeddings-from-bert-using-transfer-learning-81fcefe3fe6d\n",
    "\"\"\"\n",
    "def bert_text_preparation(text, tokenizer):\n",
    "    marked_text = \"[CLS] \" + text + \" [SEP]\"\n",
    "    tokenized_text = tokenizer.tokenize(marked_text, truncation=True, max_length=max_length, padding = 'max_length')\n",
    "    indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "    segments_ids = [1]*len(indexed_tokens)\n",
    "\n",
    "    tokens_tensor = torch.tensor([indexed_tokens])\n",
    "    segments_tensors = torch.tensor([segments_ids])\n",
    "\n",
    "    return tokenized_text, tokens_tensor, segments_tensors\n",
    "\n",
    "def get_bert_embeddings(tokens_tensor, segments_tensors, model):\n",
    "    with torch.no_grad():\n",
    "        outputs = model(tokens_tensor, segments_tensors)\n",
    "        hidden_states = outputs[2][1:]\n",
    "\n",
    "    token_embeddings = hidden_states[-1]\n",
    "    token_embeddings = torch.squeeze(token_embeddings, dim=0)\n",
    "    list_token_embeddings = [token_embed.tolist() for token_embed in token_embeddings]\n",
    "\n",
    "    return list_token_embeddings\n",
    "############################################################\n",
    "\n",
    "\n",
    "# import of models \n",
    "tokenizer = AutoTokenizer.from_pretrained('neuralmind/bert-base-portuguese-cased', do_lower_case=True)\n",
    "model = BertModel.from_pretrained('neuralmind/bert-base-portuguese-cased', output_hidden_states = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer, BertModel\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Data Paths\n",
    "data_input_path = '../../dataset/processed/artigos_tratados/artigos_tratados.parquet'\n",
    "data_output_path = '../../dataset/processed/artigos_tratados/bertimbau/bertimbau_full_parts/'\n",
    "max_length = 150\n",
    "\n",
    "# Auxiliary Functions\n",
    "def bert_text_preparation_batch(texts, tokenizer):\n",
    "    marked_texts = [\"[CLS] \" + t + \" [SEP]\" for t in texts]\n",
    "    tokenized_texts = tokenizer.batch_encode_plus(marked_texts, truncation=True, max_length=max_length, padding='max_length', return_tensors='pt')\n",
    "    return tokenized_texts\n",
    "\n",
    "def get_bert_embeddings_batch(tokens_tensors, model):\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**tokens_tensors)\n",
    "        hidden_states = outputs[2][1:]\n",
    "\n",
    "    token_embeddings = hidden_states[-1]\n",
    "    token_embeddings = torch.squeeze(token_embeddings, dim=0)\n",
    "    return token_embeddings.tolist()\n",
    "\n",
    "# Import Models\n",
    "tokenizer = AutoTokenizer.from_pretrained('neuralmind/bert-base-portuguese-cased', do_lower_case=True)\n",
    "model = BertModel.from_pretrained('neuralmind/bert-base-portuguese-cased', output_hidden_states=True)\n",
    "\n",
    "# Get Data\n",
    "data = pd.read_parquet(data_input_path)\n",
    "data_bert = data.copy()\n",
    "emb_vector = []\n",
    "\n",
    "# Parameters for Batch Processing\n",
    "batch_size = 256\n",
    "num_batches = (len(data_bert) + batch_size - 1) // batch_size\n",
    "\n",
    "# Processing in Batches\n",
    "print(f'Start of Embedding. Datetime: {datetime.datetime.today()}')\n",
    "for batch_num in range(num_batches):\n",
    "    start_idx = batch_num * batch_size\n",
    "    end_idx = min((batch_num + 1) * batch_size, len(data_bert))\n",
    "    \n",
    "    batch_data = data_bert.iloc[start_idx:end_idx]\n",
    "    texts = batch_data['Conteudo'].tolist()\n",
    "    \n",
    "    tokenized_texts = bert_text_preparation_batch(texts, tokenizer)\n",
    "    tokens_tensor = tokenized_texts['input_ids']\n",
    "\n",
    "    del tokenized_texts\n",
    "\n",
    "    list_token_embeddings = get_bert_embeddings_batch({'input_ids': tokens_tensor}, model)\n",
    "    \n",
    "    emb_vector.extend(list_token_embeddings)\n",
    "\n",
    "    del list_token_embeddings, tokens_tensor\n",
    "\n",
    "    print(f'Progress: {end_idx}/{len(data_bert)}. Datetime: {datetime.datetime.today()}')\n",
    "\n",
    "print(f'End of Embedding. Datetime: {datetime.datetime.today()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# get data\n",
    "data = pd.read_parquet(data_input_path)\n",
    "data_bert = data.copy()\n",
    "emb_vector = None\n",
    "j = 0\n",
    "len_df = data_bert.shape[0]\n",
    "print(f'Start of Embeddding. Datetime: {datetime.datetime.today()}')\n",
    "for i, row in data_bert.iterrows():\n",
    "\n",
    "    text = row['Conteudo']\n",
    "    label = row['Vies']\n",
    "    \n",
    "    tokenized_text, tokens_tensor, segments_tensors = bert_text_preparation(text, tokenizer)\n",
    "    \n",
    "    list_token_embeddings = get_bert_embeddings(tokens_tensor, segments_tensors, model)\n",
    "    \n",
    "    del tokenized_text, tokens_tensor, segments_tensors\n",
    "    \n",
    "    bert_emb = np.array(list_token_embeddings)\n",
    "    bert_emb = np.expand_dims(bert_emb, axis = 0)\n",
    "    \n",
    "    del list_token_embeddings\n",
    "    if j== 0:\n",
    "        emb_vector = bert_emb\n",
    "    else:\n",
    "        emb_vector = np.concatenate([emb_vector, bert_emb])\n",
    "    \n",
    "    del bert_emb\n",
    "    if j % 100 == 0:\n",
    "        print(f'Progress: {j}/{len_df - 1}. Datetime: {datetime.datetime.today()}') \n",
    "    j += 1\n",
    "        \n",
    "print(f'End of Embedding. Datetime: {datetime.datetime.today()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "\n",
    "# Caminho para o arquivo HDF5 gerado\n",
    "output_file = 'merged_arrays.h5'\n",
    "\n",
    "# Leitura do array do arquivo HDF5\n",
    "with h5py.File(output_file, 'r') as h5f:\n",
    "    emb_vector = h5f['emb_vector'][:]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
