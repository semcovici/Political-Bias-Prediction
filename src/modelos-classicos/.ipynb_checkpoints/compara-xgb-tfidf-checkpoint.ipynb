{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce62debc-bf37-4d18-85a9-dbd1069ebb20",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Importação das bibliotecas necessárias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "22df3ca1-3dbe-4119-a257-9e8412799283",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "from sklearn.preprocessing import MinMaxScaler, QuantileTransformer\n",
    "from datetime import datetime\n",
    "from sklearn.feature_selection import SelectPercentile\n",
    "from scipy.stats import uniform\n",
    "\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "#from sklearn.pipeline import Pipeline\n",
    "from imblearn.pipeline import Pipeline\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn import set_config\n",
    "set_config(display='diagram')\n",
    "import datetime\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "726dd049-2914-4e15-aa97-41f875bc5e6d",
   "metadata": {},
   "source": [
    "# Importação dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f094c27-9803-45b7-927f-418b6a45133e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('../dataset/processed/artigos_de_partidos/artigos_partidos.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc4deccb-f6c2-445c-a9d7-1691d689946a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remocao de dados nulos\n",
    "data = data[data['Conteudo'] != '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "de347264-5549-4c2a-a7ec-c14725f4e53c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remocao de colunas desnecessarias\n",
    "rem_cols = ['URL']\n",
    "data.drop(rem_cols, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0b506f40-5b6f-47c4-9ed9-5def04c2904b",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Partido</th>\n",
       "      <th>Conteudo</th>\n",
       "      <th>Vies</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Novo</td>\n",
       "      <td>Multa imposta ao candidato na condenação foi...</td>\n",
       "      <td>direita</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Novo</td>\n",
       "      <td>Cadastro será usado como identificação junt...</td>\n",
       "      <td>direita</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Novo</td>\n",
       "      <td>A Bancada do NOVO na Câmara considera temerá...</td>\n",
       "      <td>direita</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Novo</td>\n",
       "      <td>Um ambiente com ausência de segurança juríd...</td>\n",
       "      <td>direita</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Novo</td>\n",
       "      <td>Segundo o MP, o estado do RJ sequer utiliza os...</td>\n",
       "      <td>direita</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Partido                                           Conteudo     Vies\n",
       "0    Novo  Multa imposta ao candidato na condenação foi...  direita\n",
       "1    Novo  Cadastro será usado como identificação junt...  direita\n",
       "2    Novo  A Bancada do NOVO na Câmara considera temerá...  direita\n",
       "3    Novo  Um ambiente com ausência de segurança juríd...  direita\n",
       "4    Novo  Segundo o MP, o estado do RJ sequer utiliza os...  direita"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head() # visualização das primeiras 5 linhas do dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f2ef30cb-c985-4221-b0fb-48e617b6732c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# conversao dos rotulos categoricos para numericos\n",
    "data['Vies'] = data['Vies'].map({'direita':2,\n",
    "                                'centro': 1,\n",
    "                                'esquerda': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4910bc1c-f52a-4bae-985f-a5282c1729a3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Partido</th>\n",
       "      <th>Conteudo</th>\n",
       "      <th>Vies</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Novo</td>\n",
       "      <td>Multa imposta ao candidato na condenação foi...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Novo</td>\n",
       "      <td>Cadastro será usado como identificação junt...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Novo</td>\n",
       "      <td>A Bancada do NOVO na Câmara considera temerá...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Novo</td>\n",
       "      <td>Um ambiente com ausência de segurança juríd...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Novo</td>\n",
       "      <td>Segundo o MP, o estado do RJ sequer utiliza os...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Partido                                           Conteudo  Vies\n",
       "0    Novo  Multa imposta ao candidato na condenação foi...     2\n",
       "1    Novo  Cadastro será usado como identificação junt...     2\n",
       "2    Novo  A Bancada do NOVO na Câmara considera temerá...     2\n",
       "3    Novo  Um ambiente com ausência de segurança juríd...     2\n",
       "4    Novo  Segundo o MP, o estado do RJ sequer utiliza os...     2"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "defb5652-63fb-4fb7-b59f-16c9fbe8699a",
   "metadata": {},
   "source": [
    "# Splits que serão avaliados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8c659419-4e04-45cc-88c3-dbbeec61d993",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Partido</th>\n",
       "      <th>Conteudo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Novo</td>\n",
       "      <td>Multa imposta ao candidato na condenação foi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Novo</td>\n",
       "      <td>Cadastro será usado como identificação junt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Novo</td>\n",
       "      <td>A Bancada do NOVO na Câmara considera temerá...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Novo</td>\n",
       "      <td>Um ambiente com ausência de segurança juríd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Novo</td>\n",
       "      <td>Segundo o MP, o estado do RJ sequer utiliza os...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Partido                                           Conteudo\n",
       "0    Novo  Multa imposta ao candidato na condenação foi...\n",
       "1    Novo  Cadastro será usado como identificação junt...\n",
       "2    Novo  A Bancada do NOVO na Câmara considera temerá...\n",
       "3    Novo  Um ambiente com ausência de segurança juríd...\n",
       "4    Novo  Segundo o MP, o estado do RJ sequer utiliza os..."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a seguir os dados serão divididos entre features (X) e label (y)\n",
    "\n",
    "X_columns = [column for column in data.columns if column != 'Vies']\n",
    "X = data[X_columns] # features\n",
    "X.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "56174d98-ac9b-4e9c-a9e1-784e917e8897",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2\n",
       "1    2\n",
       "2    2\n",
       "3    2\n",
       "4    2\n",
       "Name: Vies, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = data['Vies'] # label\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69274658-1e14-4b8c-956f-7ef25ca2e965",
   "metadata": {},
   "source": [
    "## Estratificação por viés"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2843a037-0eae-458f-bca9-296fb683a646",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train_strat_vies, X_test_strat_vies, y_train_strat_vies, y_test_strat_vies = train_test_split(X, y.to_numpy(),\n",
    "                                                                                                test_size=0.2,\n",
    "                                                                                                random_state=42,\n",
    "                                                                                                stratify=y)\n",
    "\n",
    "X_train_strat_vies = X_train_strat_vies.drop('Partido', axis=1).Conteudo # remocao da coluna partido\n",
    "X_test_strat_vies = X_test_strat_vies.drop('Partido', axis=1).Conteudo # remocao da coluna partido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "74c27026-47f0-438f-8457-933e7ab1ec05",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3285     Alagoas – O prefeito de Maceió, JHC (PL-AL), ...\n",
       "5772     Após Indicação e Ofício apresentados pelo ...\n",
       "2306     Brasília – “Você importa. Escolha a vida!”. ...\n",
       "1757     Nota do PCB Santa Catarina sobre a conquista d...\n",
       "690      O NOVO foi fundado em 2011 por pessoas comuns ...\n",
       "                               ...                        \n",
       "3568     Amazonas – A deputada estadual Therezinha Ruiz...\n",
       "4852     Brasília – O Ministério da Educação (MEC) ...\n",
       "6461     O povo paraguaio está se insurgindo contra um...\n",
       "10634    Na CCJ, governistas pedem vista e atrasam apre...\n",
       "10822    PV Pernambuco repudia as ofertas do governo fe...\n",
       "Name: Conteudo, Length: 9370, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_strat_vies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64baa7c6-aa90-4515-be5f-073b56c38f91",
   "metadata": {},
   "source": [
    "## Estratificação por partido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "89e506b6-8cff-4c9d-ab40-a54e75f4e1e6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train_strat_part, X_test_strat_part, y_train_strat_part, y_test_strat_part = train_test_split(X, y.to_numpy(),\n",
    "                                                                                                test_size=0.2,\n",
    "                                                                                                random_state=42,\n",
    "                                                                                                stratify=X['Partido'])\n",
    "\n",
    "X_train_strat_part = X_train_strat_part.drop('Partido', axis=1).Conteudo # remocao da coluna partido\n",
    "X_test_strat_part = X_test_strat_part.drop('Partido', axis=1).Conteudo # remocao da coluna partido"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaac8f73-05b1-4a09-9280-d682f2ef844c",
   "metadata": {},
   "source": [
    "## Teste com partidos fora do treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "16793304-1778-4e45-a7fb-6f4bfdd653c3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "direita = data[data['Vies'] == 2] # selecao apenas dos partidos de direita\n",
    "centro = data[data['Vies'] == 1] # selecao apenas dos partidos de centro\n",
    "esquerda = data[data['Vies'] == 0] # selecao apenas dos partidos de esquerda\n",
    "total = data.shape[0] # quantidade total de linhas no dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b63978e1-b919-46b3-a969-babca8e4226d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Porcentagem dos partidos de direita em relação ao dataset:\n",
      "porcentagem do partido Novo: 10.22%\n",
      "porcentagem do partido PL: 28.90%\n",
      "porcentagem do partido PP: 5.01%\n",
      "porcentagem do partido União Brasil: 2.42%\n"
     ]
    }
   ],
   "source": [
    "print('Porcentagem dos partidos de direita em relação ao dataset:')\n",
    "for part in direita['Partido'].unique():\n",
    "    \n",
    "    qnt_part = direita[direita['Partido'] == part].shape[0]\n",
    "    porc = qnt_part / total * 100\n",
    "    print(f'porcentagem do partido {part}: {porc:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3f81d5fc-5876-4ffc-b570-3d0d1c82ab2a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Porcentagem dos partidos de centro em relação ao dataset:\n",
      "porcentagem do partido PDT: 3.82%\n",
      "porcentagem do partido MDB: 5.13%\n",
      "porcentagem do partido PSB: 15.04%\n",
      "porcentagem do partido PV: 7.41%\n"
     ]
    }
   ],
   "source": [
    "print('Porcentagem dos partidos de centro em relação ao dataset:')\n",
    "for part in centro['Partido'].unique():\n",
    "    \n",
    "    qnt_part = centro[centro['Partido'] == part].shape[0]\n",
    "    porc = qnt_part / total * 100\n",
    "    print(f'porcentagem do partido {part}: {porc:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "56090a2e-c117-46f7-9c7f-cd58dc12c6d8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Porcentagem dos partidos de esquerda em relação ao dataset:\n",
      "porcentagem do partido PCB: 5.27%\n",
      "porcentagem do partido PSOL: 0.13%\n",
      "porcentagem do partido PSTU: 5.35%\n",
      "porcentagem do partido PCDoB: 5.14%\n",
      "porcentagem do partido PT: 5.10%\n",
      "porcentagem do partido Rede: 1.06%\n"
     ]
    }
   ],
   "source": [
    "print('Porcentagem dos partidos de esquerda em relação ao dataset:')\n",
    "for part in esquerda['Partido'].unique():\n",
    "    \n",
    "    qnt_part = esquerda[esquerda['Partido'] == part].shape[0]\n",
    "    porc = qnt_part / total * 100\n",
    "    print(f'porcentagem do partido {part}: {porc:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fd7f7c1-6170-43fb-bf4a-a10a94a9c198",
   "metadata": {},
   "source": [
    "Baseado nas porcentagens acima, o partido de esquerda, centro e direita que foram escolhidos para o conjunto de teste representam, respectivamente 5.53%, 7.35% e 10.34% do dataset. Dessa forma, o conjunto de teste será constituído por 5.53 + 7.35 + 10.34 = 23.22% do dataset original."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "25c3daf4-d8b4-4501-8c71-2a3f03da09ea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "part_teste = ['PSTU', 'PV', 'Novo'] # partidos do conjunto de teste\n",
    "\n",
    "test = data[data['Partido'].isin(part_teste)].copy() # selecao dos dados de teste\n",
    "test.drop('Partido', axis=1, inplace=True) # remocao da coluna partido\n",
    "\n",
    "train = data[~data['Partido'].isin(part_teste)].copy() # selecao dos dados de treino\n",
    "train.drop('Partido', axis=1, inplace=True) # remocao da coluna partido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bb6fe31d-ab8a-4564-8fb0-4a82df55852a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train_part_novos = train.drop('Vies', axis=1).Conteudo # X_train\n",
    "y_train_part_novos = train['Vies'].to_numpy() # y_train\n",
    "\n",
    "X_test_part_novos = test.drop('Vies', axis=1).Conteudo # X_test\n",
    "y_test_part_novos = test['Vies'].to_numpy() # y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "324d4728-aaa3-4fed-8495-6a2feacba516",
   "metadata": {},
   "source": [
    "# Seleção do modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "64ad7bae-85b7-4626-9b4c-6ca6c59cf22b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Defina a função para calcular a porcentagem com base no número total de features\n",
    "def percentage_features(percentage, total_features):\n",
    "    return int(np.ceil(percentage * total_features / 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "90e350f1-7b3f-45ac-a098-58be22ede652",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seleciona_grid_tfidf(model, split):\n",
    "\n",
    "    param_grid = None\n",
    "    \n",
    "    if split == 'strat_vies':\n",
    "        X_train = X_train_strat_vies.copy()\n",
    "        \n",
    "    elif split == 'strat_partido':\n",
    "        X_train = X_train_strat_part.copy()\n",
    "        \n",
    "    elif split == 'pred_partido_novo':\n",
    "        X_train = X_train_part_novos.copy()\n",
    "        \n",
    "\n",
    "    if isinstance(model, MultinomialNB):\n",
    "            param_grid = {\n",
    "            \"vect__ngram_range\": [(1,2), (1,3), (1,4), (2,3), (2,4), (3,4)],\n",
    "            \"vect__analyzer\": ['word','char'],\n",
    "            \"selection__percentile\": [33, 66, 100],\n",
    "            \"estimator__alpha\": [50, 15, 10, 5, 1, 0.5, 0.3, 0.1, 0.05, 0.03, 0.02, 0.01,  0.001],\n",
    "            \"estimator__fit_prior\": [True, False],\n",
    "            }\n",
    "\n",
    "    if isinstance(model, SVC):\n",
    "            param_grid = {\n",
    "            \"vect__ngram_range\": [(1,2), (1,3), (1,4), (2,3), (2,4), (3,4)],\n",
    "            \"vect__analyzer\": ['word','char'],\n",
    "            \"selection__k\": [200,400,600,800,1024],\n",
    "            \"estimator__gamma\": [1, 0.1, 0.01, 0.001],\n",
    "            \"estimator__kernel\": ['linear', 'sigmoid'],\n",
    "            \"estimator__C\": [0.1, 1, 10, 100]\n",
    "            }\n",
    "            \n",
    "    if isinstance(model, LinearSVC):\n",
    "        \n",
    "            param_grid = {\n",
    "            \"vect__ngram_range\": [(1,2), (1,3), (1,4), (2,3), (2,4), (3,4)],\n",
    "            \"vect__analyzer\": ['word','char'],\n",
    "            \"selection__percentile\": [33, 66, 100],\n",
    "            \"estimator__dual\": [True, False],\n",
    "            \"estimator__penalty\": ['l1', 'l2'],\n",
    "            \"estimator__fit_intercept\": [True, False],\n",
    "            \"estimator__C\": uniform(loc=0, scale=4)\n",
    "            }\n",
    "\n",
    "\n",
    "    if isinstance(model, RandomForestClassifier):\n",
    "        param_grid = {\n",
    "        \"vect__ngram_range\": [(1,2), (1,3), (1,4), (2,3), (2,4), (3,4)],\n",
    "        \"vect__analyzer\": ['word','char'],\n",
    "        \"selection__k\": [200,400,600,800,1024],\n",
    "        \"estimator__n_estimators\": np.arange(20,150), \n",
    "        \"estimator__max_features\": ['log2', 'sqrt'],\n",
    "        \"estimator__max_depth\": np.arange(10,110),\n",
    "        \"estimator__min_samples_split\": np.arange(2,11),\n",
    "        \"estimator__min_samples_leaf\": np.arange(1,5),\n",
    "        \"estimator__bootstrap\": [True, False]\n",
    "        }\n",
    "        \n",
    "    if isinstance(model, XGBClassifier):\n",
    "        param_grid = {\n",
    "        \"vect__ngram_range\": [(1,2), (1,3), (1,4), (2,3), (2,4), (3,4)],\n",
    "        \"vect__analyzer\": ['word','char'],\n",
    "        \"selection__percentile\": [33, 66, 100],\n",
    "        \"estimator__gamma\": np.linspace(0,9,100, dtype=np.int64),\n",
    "        \"estimator__alpha\": np.linspace(0,40,100, dtype=np.int64),\n",
    "        \"estimator__lambda\": np.linspace(0,3,10, dtype=np.int64),\n",
    "        \"estimator__colsample_bytree\": np.linspace(0.2,1,10, dtype=np.int64)\n",
    "        }\n",
    "\n",
    "    return param_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f7bf1992-6267-4e40-a4f6-2c352d7e90ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_e_avalia(split, random_search):\n",
    "    \n",
    "    inicio_random_search = datetime.datetime.now()\n",
    "    \n",
    "    if split == 'strat_vies': # estratificacao pela label\n",
    "        model_trained = random_search.fit(X_train_strat_vies, y_train_strat_vies) # fit\n",
    "\n",
    "        fim_random_search = datetime.datetime.now()\n",
    "        tempo_total = fim_random_search - inicio_random_search\n",
    "        print(f'Duração da Random Search: {tempo_total}')\n",
    "\n",
    "        y_pred = model_trained.predict(X_test_strat_vies) # predicao\n",
    "        f1 = f1_score(y_test_strat_vies, y_pred, average= 'macro') # f1\n",
    "        report = classification_report(y_test_strat_vies, y_pred, output_dict=True) # class report\n",
    "\n",
    "    elif split == 'strat_partido': # estratificacao pelos partidos \n",
    "        model_trained = random_search.fit(X_train_strat_part, y_train_strat_part) # fit\n",
    "\n",
    "        fim_random_search = datetime.datetime.now()\n",
    "        tempo_total = fim_random_search - inicio_random_search\n",
    "        print(f'Duração da Random Search: {tempo_total}')\n",
    "\n",
    "        y_pred = model_trained.predict(X_test_strat_part) # predicao\n",
    "        f1 = f1_score(y_test_strat_part, y_pred, average= 'macro') # f1\n",
    "        report = classification_report(y_test_strat_part, y_pred, output_dict=True) # class report\n",
    "\n",
    "    elif split == 'pred_partido_novo': # predicao de partidos nao vistos no teste\n",
    "        model_trained = random_search.fit(X_train_part_novos, y_train_part_novos) # fit\n",
    "\n",
    "        fim_random_search = datetime.datetime.now()\n",
    "        tempo_total = fim_random_search - inicio_random_search\n",
    "        print(f'Duração da Random Search: {tempo_total}')\n",
    "\n",
    "        y_pred = model_trained.predict(X_test_part_novos) # predicao\n",
    "        f1 = f1_score(y_test_part_novos, y_pred, average= 'macro') # f1\n",
    "        report = classification_report(y_test_part_novos, y_pred, output_dict=True) # class report\n",
    "    \n",
    "    return model_trained, tempo_total, f1, report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "31550b8e-4684-401b-b4ac-e1cb5f04ce1b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compara_tfidf(iteracoes, modelos, nome_arquivo):\n",
    "\n",
    "    # seletor de features\n",
    "    selection = SelectPercentile()\n",
    "\n",
    "    # possibilidades de oversampling ou nao\n",
    "    samplers = [RandomOverSampler(random_state=42), None]\n",
    "\n",
    "    # diferentes splits que serao avaliador\n",
    "    splits = ['strat_vies', 'strat_partido', 'pred_partido_novo'] \n",
    "    \n",
    "    # vetorizador do texto\n",
    "    vectorizer = TfidfVectorizer()\n",
    "\n",
    "    # dataframe em que sera inserido os dados do modelo testado \n",
    "    df_resultados = pd.DataFrame(columns=['modelo', 'split', 'sampler', 'scaling',\n",
    "                                          'duracao_random_search','qnt_iteracoes',\n",
    "                                          'f1_randsearch',\n",
    "                                          'melhores_parametros', 'f1_pred',\n",
    "                                          'class_report'])\n",
    "    \n",
    "    for model in modelos:\n",
    "\n",
    "        for sampler in samplers:\n",
    "\n",
    "            for split in splits:\n",
    "                \n",
    "                # seleciona grid de parametros\n",
    "                param_grid = seleciona_grid_tfidf(model, split)\n",
    "                \n",
    "                \n",
    "                scaler = MaxAbsScaler()\n",
    "        \n",
    "                # define o pipeline\n",
    "                pipeline = Pipeline([\n",
    "                        ('vect', vectorizer), \n",
    "                        ('scaling', scaler), \n",
    "                        ('selection', selection),\n",
    "                        ('ros', sampler),\n",
    "                        ('estimator', model)\n",
    "                        ])\n",
    "        \n",
    "                \n",
    "                #  --- Prints das configurações dessa iteracao ---\n",
    "                print(f'Modelo: {model}')\n",
    "                print(f'Split: {split}')\n",
    "                print(f'Scaler: {scaler}')\n",
    "                print(f'Sampler: {sampler}')\n",
    "                    \n",
    "        \n",
    "                # definicao da randomized search\n",
    "                random_search = RandomizedSearchCV(pipeline, param_distributions=param_grid,cv=StratifiedKFold(n_splits=5),\n",
    "                                                    n_iter=iteracoes, n_jobs=2, random_state=42, scoring='f1_macro')\n",
    "\n",
    "\n",
    "                # fit e avaliacao pela randomized search\n",
    "                model_trained, tempo_total, f1, report = fit_e_avalia(split, random_search)\n",
    "                \n",
    "                print('---')\n",
    "                resultados = model_trained.cv_results_\n",
    "\n",
    "                for params, score in zip(resultados['params'], resultados['mean_test_score']):\n",
    "                    print(f\"Parâmetros: {params}, Score: {score}\")\n",
    "                print('---')\n",
    "                    \n",
    "                # melhor metrica na random search\n",
    "                score_random_search = model_trained.best_score_\n",
    "                score_random_search *= 100\n",
    "                score_random_search = round(score_random_search,2)\n",
    "                print(f'Melhor F1 na Random Search: {score_random_search}%')\n",
    "                \n",
    "                # melhores parametros encontrados\n",
    "                print('Melhores parâmetros encontrados:')\n",
    "                print(model_trained.best_params_)\n",
    "\n",
    "                \n",
    "                # acuracia da predicao\n",
    "                f1 *= 100\n",
    "                f1 = round(f1,2)\n",
    "                print(f'F1 macro = {f1}%')\n",
    "        \n",
    "                # classification report\n",
    "                print(report)\n",
    "                        \n",
    "                \n",
    "                print('----------------------------------------------')\n",
    "                \n",
    "                # --- Escrita em memória secundária ---\n",
    "\n",
    "                # Nova linha que sera adicionada\n",
    "                nova_linha = {'modelo': model, 'split': split,\n",
    "                              'sampler': str(sampler), 'scaling': scaler,\n",
    "                              'duracao_random_search': tempo_total,\n",
    "                              'qnt_iteracoes': iteracoes,\n",
    "                              'f1_randsearch': f'{score_random_search}%',\n",
    "                              'melhores_parametros': str(model_trained.best_params_),\n",
    "                              'f1_pred': f'{f1}%', 'class_report': report}\n",
    "            \n",
    "                # Cria um novo DataFrame com a nova linha\n",
    "                nova_linha_resultados = pd.DataFrame([nova_linha])\n",
    "            \n",
    "                # Concatena o novo DataFrame com o DataFrame existente\n",
    "                df_resultados = pd.concat([df_resultados, nova_linha_resultados], ignore_index=True)\n",
    "                \n",
    "                # salvamento do dataframe de resultados apos os testes terem terminado\n",
    "                df_resultados.to_csv(nome_arquivo, index=False)\n",
    "    \n",
    "    \n",
    "    print('Fim dos testes')\n",
    "    \n",
    "    # salvamento do dataframe de resultados apos os testes terem terminado\n",
    "    #df_resultados.to_csv(nome_arquivo, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88c646da-ded2-42f1-91b6-6ecf392bddbf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo: XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=0, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...)\n",
      "Split: strat_vies\n",
      "Scaler: MaxAbsScaler()\n",
      "Sampler: RandomOverSampler(random_state=42)\n",
      "Duração da Random Search: 1:52:49.419438\n",
      "---\n",
      "Parâmetros: {'vect__ngram_range': (1, 4), 'vect__analyzer': 'char', 'selection__percentile': 33, 'estimator__lambda': 1, 'estimator__gamma': 5, 'estimator__colsample_bytree': 0, 'estimator__alpha': 23}, Score: 0.17008125866087404\n",
      "Parâmetros: {'vect__ngram_range': (1, 2), 'vect__analyzer': 'word', 'selection__percentile': 100, 'estimator__lambda': 1, 'estimator__gamma': 7, 'estimator__colsample_bytree': 1, 'estimator__alpha': 14}, Score: 0.3243187171354255\n",
      "Parâmetros: {'vect__ngram_range': (1, 3), 'vect__analyzer': 'word', 'selection__percentile': 100, 'estimator__lambda': 2, 'estimator__gamma': 1, 'estimator__colsample_bytree': 0, 'estimator__alpha': 40}, Score: 0.1519690006037\n",
      "Parâmetros: {'vect__ngram_range': (2, 4), 'vect__analyzer': 'char', 'selection__percentile': 100, 'estimator__lambda': 0, 'estimator__gamma': 6, 'estimator__colsample_bytree': 0, 'estimator__alpha': 29}, Score: 0.15558599493773478\n",
      "Parâmetros: {'vect__ngram_range': (2, 4), 'vect__analyzer': 'char', 'selection__percentile': 33, 'estimator__lambda': 2, 'estimator__gamma': 5, 'estimator__colsample_bytree': 0, 'estimator__alpha': 29}, Score: 0.20458386377035756\n",
      "Parâmetros: {'vect__ngram_range': (3, 4), 'vect__analyzer': 'char', 'selection__percentile': 66, 'estimator__lambda': 2, 'estimator__gamma': 3, 'estimator__colsample_bytree': 0, 'estimator__alpha': 32}, Score: 0.13592242665693885\n",
      "Parâmetros: {'vect__ngram_range': (2, 4), 'vect__analyzer': 'word', 'selection__percentile': 100, 'estimator__lambda': 0, 'estimator__gamma': 1, 'estimator__colsample_bytree': 0, 'estimator__alpha': 26}, Score: 0.13211573577107308\n",
      "Parâmetros: {'vect__ngram_range': (2, 3), 'vect__analyzer': 'word', 'selection__percentile': 33, 'estimator__lambda': 0, 'estimator__gamma': 6, 'estimator__colsample_bytree': 0, 'estimator__alpha': 35}, Score: 0.19592162552185777\n",
      "Parâmetros: {'vect__ngram_range': (1, 3), 'vect__analyzer': 'char', 'selection__percentile': 100, 'estimator__lambda': 2, 'estimator__gamma': 4, 'estimator__colsample_bytree': 0, 'estimator__alpha': 10}, Score: 0.2158588081929056\n",
      "Parâmetros: {'vect__ngram_range': (2, 3), 'vect__analyzer': 'word', 'selection__percentile': 33, 'estimator__lambda': 3, 'estimator__gamma': 2, 'estimator__colsample_bytree': 0, 'estimator__alpha': 23}, Score: 0.2095252380203268\n",
      "Parâmetros: {'vect__ngram_range': (2, 3), 'vect__analyzer': 'char', 'selection__percentile': 33, 'estimator__lambda': 0, 'estimator__gamma': 6, 'estimator__colsample_bytree': 0, 'estimator__alpha': 23}, Score: 0.18503360719468476\n",
      "Parâmetros: {'vect__ngram_range': (3, 4), 'vect__analyzer': 'word', 'selection__percentile': 33, 'estimator__lambda': 1, 'estimator__gamma': 3, 'estimator__colsample_bytree': 0, 'estimator__alpha': 5}, Score: 0.23630899053551419\n",
      "Parâmetros: {'vect__ngram_range': (1, 3), 'vect__analyzer': 'char', 'selection__percentile': 66, 'estimator__lambda': 1, 'estimator__gamma': 5, 'estimator__colsample_bytree': 0, 'estimator__alpha': 15}, Score: 0.17407942898385048\n",
      "Parâmetros: {'vect__ngram_range': (2, 3), 'vect__analyzer': 'word', 'selection__percentile': 33, 'estimator__lambda': 1, 'estimator__gamma': 1, 'estimator__colsample_bytree': 0, 'estimator__alpha': 20}, Score: 0.21166972109834226\n",
      "Parâmetros: {'vect__ngram_range': (1, 3), 'vect__analyzer': 'word', 'selection__percentile': 100, 'estimator__lambda': 1, 'estimator__gamma': 5, 'estimator__colsample_bytree': 0, 'estimator__alpha': 4}, Score: 0.21543397184221594\n",
      "Parâmetros: {'vect__ngram_range': (2, 3), 'vect__analyzer': 'char', 'selection__percentile': 33, 'estimator__lambda': 0, 'estimator__gamma': 8, 'estimator__colsample_bytree': 0, 'estimator__alpha': 3}, Score: 0.1899592033999124\n",
      "---\n",
      "Melhor F1 na Random Search: 32.43%\n",
      "Melhores parâmetros encontrados:\n",
      "{'vect__ngram_range': (1, 2), 'vect__analyzer': 'word', 'selection__percentile': 100, 'estimator__lambda': 1, 'estimator__gamma': 7, 'estimator__colsample_bytree': 1, 'estimator__alpha': 14}\n",
      "F1 macro = 23.29%\n",
      "{'0': {'precision': 0.22264875239923224, 'recall': 0.6744186046511628, 'f1-score': 0.3347763347763348, 'support': 516}, '1': {'precision': 0.12156862745098039, 'recall': 0.08423913043478261, 'f1-score': 0.09951845906902086, 'support': 736}, '2': {'precision': 0.6666666666666666, 'recall': 0.16498625114573787, 'f1-score': 0.2645113886847906, 'support': 1091}, 'accuracy': 0.25181391378574475, 'macro avg': {'precision': 0.33696134883895973, 'recall': 0.3078813287438944, 'f1-score': 0.2329353941767154, 'support': 2343}, 'weighted avg': {'precision': 0.3976502771554668, 'recall': 0.25181391378574475, 'f1-score': 0.22815710613508094, 'support': 2343}}\n",
      "----------------------------------------------\n",
      "Modelo: XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=0, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...)\n",
      "Split: strat_partido\n",
      "Scaler: MaxAbsScaler()\n",
      "Sampler: RandomOverSampler(random_state=42)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yagoa\\AppData\\Local\\Temp\\ipykernel_3716\\925276933.py:103: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_resultados = pd.concat([df_resultados, nova_linha_resultados], ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "modelos = [XGBClassifier(seed=42, tree_method='gpu_hist', gpu_id=0)]\n",
    "\n",
    "compara_tfidf(9, modelos, 'compara-xgb-tfidf-9-.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baaeef94-87bc-4056-b02a-99b2e264989e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
