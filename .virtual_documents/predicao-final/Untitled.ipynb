


import pandas as pd 

from sklearn.preprocessing import MaxAbsScaler
from sklearn.preprocessing import MinMaxScaler
from datetime import datetime
from scipy.stats import uniform

from sklearn.naive_bayes import MultinomialNB
from sklearn.svm import SVC
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import CountVectorizer
#from sklearn.pipeline import Pipeline
from imblearn.pipeline import Pipeline
from imblearn.over_sampling import RandomOverSampler
from sklearn.feature_selection import SelectKBest
from sklearn.model_selection import cross_val_score
from sklearn.metrics import classification_report
from sklearn.metrics import f1_score


from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import LinearSVC

from xgboost import XGBClassifier
from sklearn.model_selection import StratifiedKFold
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.compose import ColumnTransformer
from sklearn.metrics import accuracy_score
import numpy as np
from sklearn.model_selection import RandomizedSearchCV
from sklearn import set_config
set_config(display='diagram')
import datetime
import time


data = pd.read_parquet('../dataset/processed/artigos_tratados/bertimbau/artigos_tratados_bert_lg.parquet')


# remocao de dados nulos
data = data[data['Conteudo'] != '']


# remocao de colunas desnecessarias
rem_cols = ['Conteudo', 'URL']
data.drop(rem_cols, axis=1, inplace=True)


# conversao dos rotulos categoricos para numericos
data['Vies'] = data['Vies'].map({'direita':2,
                                'centro': 1,
                                'esquerda': 0})


# a seguir os dados ser√£o divididos entre features (X) e label (y)

X_columns = [column for column in data.columns if column != 'Vies']
X = data[X_columns] # features
X.head() 


y = data['Vies'] # label
y.head()


X_train_strat_vies, X_test_strat_vies, y_train_strat_vies, y_test_strat_vies = train_test_split(X, y,
                                                                                                test_size=0.2,
                                                                                                random_state=42,
                                                                                                stratify=y)

X_train_strat_vies.drop('Partido', axis=1, inplace=True) # remocao da coluna partido
X_test_strat_vies.drop('Partido', axis=1, inplace=True) # remocao da coluna partido


X_train_strat_part, X_test_strat_part, y_train_strat_part, y_test_strat_part = train_test_split(X, y,
                                                                                                test_size=0.2,
                                                                                                random_state=42,
                                                                                                stratify=data['Partido'])

X_train_strat_part.drop('Partido', axis=1, inplace=True) # remocao da coluna partido
X_test_strat_part.drop('Partido', axis=1, inplace=True) # remocao da coluna partido


part_teste = ['PSTU', 'PV', 'Novo'] # partidos do conjunto de teste

test = data[data['Partido'].isin(part_teste)].copy() # selecao dos dados de teste
test.drop('Partido', axis=1, inplace=True) # remocao da coluna partido

train = data[~data['Partido'].isin(part_teste)].copy() # selecao dos dados de treino
train.drop('Partido', axis=1, inplace=True) # remocao da coluna partido


X_train_part_novos = train.drop('Vies', axis=1) # X_train
y_train_part_novos = train['Vies'] # y_train

X_test_part_novos = test.drop('Vies', axis=1) # X_test
y_test_part_novos = test['Vies'] # y_test


best_params = {'selection__k': 800,
               'estimator__lambda': 0,
               'estimator__gamma': 0,
               'estimator__colsample_bytree': 1,
               'estimator__alpha': 22}


pipeline = Pipeline([
                        ('scaling', MaxAbsScaler()), 
                        ('selection', SelectKBest()),
                        ('ros', RandomOverSampler(random_state=42)),
                        ('estimator', XGBClassifier(seed=42, tree_method='gpu_hist', gpu_id=0))
                        ])
    
best_xgb = pipeline.set_params(**best_params)


best_xgb.get_params


best_xgb.fit(X.drop('Partido', axis=1), y)





novas_noticias = pd.read_csv('noticias-teste-embedding.csv')
novas_noticias.drop(['Unnamed: 0', 'Conteudo'], axis=1, inplace=True)
novas_noticias


import pandas as pd
novas_noticias_oeste_carta_capital = pd.read_csv('noticias-teste-oeste-cart_capital-tratado-embedding.csv')
novas_noticias_oeste_carta_capital.drop(['Unnamed: 0', 'Conteudo'], axis=1, inplace=True)
novas_noticias_oeste_carta_capital


pred = best_xgb.predict(novas_noticias)
pred


data['Vies'] = data['Vies'].map({'direita':2,
                                'centro': 1,
                                'esquerda': 0})


pred = best_xgb.predict(novas_noticias_oeste_carta_capital)
pred
