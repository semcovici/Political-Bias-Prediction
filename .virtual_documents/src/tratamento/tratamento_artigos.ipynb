# == importando bibliotecas == 

import pandas as pd
import numpy as np
import re

from IPython.core.interactiveshell import InteractiveShell
InteractiveShell.ast_node_interactivity = "all"
import warnings
warnings.filterwarnings('ignore')


# == ler a base de artigos == 

#artigos = pd.read_parquet('../../dataset/processed/artigos_de_partidos/artigos_partidos.parquet')
artigos = pd.read_csv('../../predicao-final/noticias-teste.csv')
artigos.head()


# == tornar os artigos em letras minúsculas == 

artigos.Conteudo = artigos.Conteudo.str.lower()


# == remover artigos contendo links == 

artigos[artigos.Conteudo.str.contains('http')].Partido.value_counts()
artigos = artigos[~artigos.Conteudo.str.contains('http')]


# == todas as sentenças após o penúltimo "." a fim de eliminar ruídos que não fazem parte do artigo == 

artigos.Conteudo = artigos.Conteudo.apply(
    lambda x : ''.join(x.split('.')[:-2])
)


# == mascarar nome de partido == 

partidos = ['novo', 'pcb', 'pdt', 'pl', 'pp', 'psol', 'pstu', 'mdb', 'pcdob', 'psb', 'pt', 'pv', 'rede', 'união brasil']
for partido in partidos:
    artigos.Conteudo = artigos.Conteudo.str.replace(f' {partido} ', ' ')


# == remover todas as palavras contendo caracteres especiais ==

artigos.Conteudo = artigos.Conteudo.apply(
    lambda x : ' '.join(word for word in x.split(' ') if word.isalnum())
)


# == normalização por unicode e encode ascii ==

artigos.Conteudo = artigos.Conteudo.str.lower()\
                                   .str.normalize('NFKD')\
                                   .str.encode('ascii', errors='ignore')\
                                   .str.decode('utf-8')


# == remover pontuações e números == 

artigos.Conteudo = artigos.Conteudo.str.replace('[^a-zA-Z]', ' ')


# == remover double space == 

for n in range(30):
    artigos.Conteudo = artigos.Conteudo.str.replace('  ', ' ')


# == analisar a contagem média de palavras por partido == 

copy = artigos.copy()
copy['Contagem'] = copy.Conteudo.str.count(' ')
copy.groupby(
    by=['Vies', 'Partido'],
).agg(
    ContagemPalavras = ('Contagem', 'mean'), 
    ContagemArtigos = ('Contagem', 'count')
)


# == salvar o df tratado == 

#artigos.to_parquet('../../dataset/processed/artigos_tratados/artigos_tratados.parquet')
artigos.to_csv('../../predicao-final/noticias-teste.csv')
